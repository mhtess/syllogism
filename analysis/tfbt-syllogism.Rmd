---
title: "syll-tfbt"
author: "mht"
date: "October 31, 2014"
output: html_document
---

# The Full Bayesian Thing for syllogisms


```{r dataload, echo=FALSE}
library(reshape2)
library(ggplot2)
library(plyr)

library(R2jags)
library(gridExtra)

library(bootstrap)

theta <- function(x,xdata,na.rm=T) {mean(xdata[x],na.rm=na.rm)}
ci.low <- function(x,na.rm=T) {
  mean(x,na.rm=na.rm) - quantile(bootstrap(1:length(x),1000,theta,x,na.rm=na.rm)$thetastar,.025,na.rm=na.rm)}
ci.high <- function(x,na.rm=T) {
  quantile(bootstrap(1:length(x),1000,theta,x,na.rm=na.rm)$thetastar,.975,na.rm=na.rm) - mean(x,na.rm=na.rm)}

agr.ci.collapsed <- function(x){
  agr = aggregate(value ~ domain + syll + variable + experiment, data=x, FUN=mean)
  agr$CILow = aggregate(value ~ domain + syll + variable + experiment, data=x, FUN=ci.low)$value
  agr$CIHigh = aggregate(value ~ domain + syll + variable + experiment, data=x, FUN=ci.high)$value
  agr$YMin = agr$value - agr$CILow
  agr$YMax = agr$value + agr$CIHigh
  return(agr)
}
map_radio_to_continuous <- function(rad,cts){50+(2*rad-1)*(cts/2)}


exp_domains = c('_ crackers that have lots of flavor are soggy',
                '_ knives that cut well are sharp',
                '_ lightbulbs that are hot are on',
                '_ strawberries that are warm are in the freezer')

# Load data from 2 experiments
fpath = '/Users/mht/Documents/research/syllogism/data/03syllogism_reasoning/'
fpath2 = '/Users/mht/Documents/research/syllogism/data/04syllogism_reasoning/'

df<-read.csv((paste(fpath,'syllbelief-exp-mturk_all_n250.csv',sep="")))
df$experiment <- factor(1)

df2<-read.csv((paste(fpath2,'syllbelief-exp2-mturk.csv',sep="")))
df2$condition<-paste(df2$condition,'2',sep='.')
df2$experiment <- factor(2)

exp1sylls<-levels(df$syll)
exp2sylls<-levels(df2$syll)
resp_labels<-c("Q_A","Q_E","Q_I","Q_O")
domains<- c('cracker', 'knife', 'lightbulb', 'strawberry')



df<-subset(df,rt<mean(df$rt)+2*sqrt(var(df$rt)))
df2<-subset(df2,rt<mean(df2$rt)+2*sqrt(var(df2$rt)))

df2$subj<- factor(df2$subj, labels=as.integer(substring(levels(df2$subj),2,4))+length(levels(df$subj)))

df.c <- rbind(df,df2)
df.c$condition<-factor(df.c$condition,levels=c('slide','radio','radio.2'))

# map radio + slider to just radio
for (i in 1:length(df.c$subj)){
  if (substring(df.c[i,]$condition,1,5)=='radio'){
    df.c[i,]$Q_A <- map_radio_to_continuous(df.c[i,]$radio_A,df.c[i,]$Q_A)
    df.c[i,]$Q_E <- map_radio_to_continuous(df.c[i,]$radio_E,df.c[i,]$Q_E)
    df.c[i,]$Q_I <- map_radio_to_continuous(df.c[i,]$radio_I,df.c[i,]$Q_I)
    df.c[i,]$Q_O <- map_radio_to_continuous(df.c[i,]$radio_O,df.c[i,]$Q_O)
  }
}

df.norm = ddply(df.c, .(domain,condition,syll,experiment), 
  function(x) {resp = x[,resp_labels]
  resp / rowSums(resp)})




```





# 0. Frequentist easy stuff

## Experiment 1

### $H_3$ = empirical prior (literal)

```{r h3exp1,echo=FALSE}

EP = 0

collapsed.bs <- subset(agr.ci.collapsed(melt(df.norm)),experiment==1)
collapsed.bs$conclusion = factor(collapsed.bs$variable, labels=c('all.C.A','none.C.A','some.C.A','not.all.C.A'))
collapsed.bs$domain = factor(collapsed.bs$domain, labels=domains)


# Load model predictions, for different parameter (n_object) values
model.dir<-'/Users/mht/Documents/research/syllogism/models/modeldata/LATTICE_4_tfbt/'
syllogisms = c('AO2', 'EA3', 'IE1', 'OA1')
n_obj = 4
corrs = c()
if (exists('models')){remove(models)}

total_objs = seq(3,9,2)
for (n_obj in total_objs){
  model.domains = data.frame()
  for (d in domains){
    model.all<-read.csv(paste(model.dir,d,'/00/csv/lis_N0_M0_tfbt',
                   d,'_qud1figFull_AIEOc4CAEP',EP,'_n',n_obj,
                   '_base0.00_s100k_alphQ1_alphR1_bsmean.csv',sep=''))[c(1,6:9)]
    model.sub<-model.all[model.all$X..syll%in%syllogisms,]
    model.sub$domain <- d
    model.m<-melt(model.sub,
                  id.vars=c('X..syll','domain'))
    model.domains<-rbind(model.domains, model.m)
  }
  #rename for merging
  names(model.domains)<-c('syll','domain','conclusion',paste('n',n_obj,sep=''))
  if (exists('models')){
    models = merge(models,model.domains)
  } else {
    models = model.domains
  }
}

models$syll <- factor(models$syll)
models$domain <- factor(models$domain)

cncl_labels = levels(models$conclusion)

m.models<-melt(models, id.vars=c('syll','domain','conclusion'))

all.stuff<-merge(m.models,collapsed.bs[c('domain','syll','value','conclusion')], 
      by=c('syll','domain','conclusion'))

model.fits<-ddply(all.stuff, .(variable), summarise, cor(value.x, value.y))
names(model.fits)<-c('n','correlation')
model.fits$n<-as.integer(substring(model.fits$n,2,3))
max.loc<-which.max(model.fits$correlation)

ggplot(model.fits, aes(x=n,y=factor(1)))+
  geom_tile(aes(fill = correlation), colour = "white") + 
  geom_tile(data=model.fits[max.loc,], aes(x=n,y=1, fill=correlation),
            size=2,colour='black')+
  geom_text(aes(x=n,y=1, label=round(correlation,2)),size=5,colour='black')+
  scale_fill_gradient(low = "white", high = "steelblue",limits=c(0.6,0.85))+
  theme_bw()+
  scale_x_continuous(breaks=3:11)+
  scale_y_discrete()

```

### $H_{4}$ = empirical prior with pragmatics

```{r h4exp1, echo=FALSE}
# Load model predictions, for different parameter (n_object) values               
# H4: n_objects, alpha (empirical prior + pragmatics)

model.dir<-'/Users/mht/Documents/research/syllogism/models/modeldata/LATTICE_4_tfbt/'
domains<- c('cracker', 'knife', 'lightbulb', 'strawberry')
syllogisms = c('AO2', 'EA3', 'IE1', 'OA1')
n_obj = 4
corrs = c()
if (exists('models')){remove(models)}

# this code relies upon the same parameter values being explored for all
# e.g. same range of alpha values for all levels of n_obj

total_objs = seq(3,9,2)
for (n_obj in total_objs){
  model.domains = data.frame()
  for (d in domains){
    dom.path = paste(model.dir,d,'/10/csv/',sep='')
    model.files <- list.files(dom.path)
    model.files <- model.files[!(grepl("CLonly",model.files))]
    model.files <- model.files[!(grepl("1000k",model.files))]
    model.files <- model.files[grepl(paste('EP',EP,"_n",n_obj,'_base',sep=''),model.files)]
    for (m.file in model.files){
      model.all<-read.csv(paste(dom.path,m.file,sep=''))[c(1,6:9)]
      model.sub<-model.all[model.all$X..syll%in%syllogisms,]
      model.sub$domain <- as.factor(d)
      model.sub$alpha <- as.numeric(substring(strsplit(m.file,'alphQ')[[1]][2],1,3))
      model.m<-melt(model.sub,id.vars=c('X..syll','domain','alpha'))
      model.domains<-rbind(model.domains, model.m)
    }
  }
  #rename for merging
  print(n_obj)
  names(model.domains)<-c('syll','domain','alpha','conclusion',paste('n',n_obj,sep=''))
  if (exists('models')){
    models = merge(models,model.domains)
  } else {
    models = model.domains
  }
}

models$syll <- factor(models$syll)

m.models<-melt(models, id.vars=c('syll','domain','alpha','conclusion'))

all.stuff<-merge(m.models,collapsed.bs[c('domain','syll','value','conclusion')], 
      by=c('syll','domain','conclusion'))

model.fits<-ddply(all.stuff, .(alpha, variable), summarise, cor(value.x, value.y))
names(model.fits)<-c('alpha','n','correlation')
model.fits$n<-as.integer(substring(model.fits$n,2,3))
model.fits$alpha<-factor(model.fits$alpha)
max.loc<-which.max(model.fits$correlation)

ggplot(model.fits, aes(x=n,y=alpha))+
  geom_tile(aes(fill = correlation), colour = "white") + 
  geom_tile(data=model.fits[max.loc,], aes(x=n,y=alpha, fill=correlation),
            size=2,colour='black')+
  geom_text(data=model.fits[max.loc,], aes(x=n,y=alpha, label=round(correlation,2)),
            size=5,colour='black')+
  scale_fill_gradient(low = "white", high = "steelblue",limits=c(0.6,0.85))+
  theme_bw()+
  scale_x_continuous(breaks=3:11)

```

## Experiment 2

```{r syllabels}
sylllabels = c('all / all', 'some / all', 'all / none', 'some / none')
```


### $H_3$ = empirical prior (literal)

```{r h3exp2, echo=FALSE}

collapsed.bs <- subset(agr.ci.collapsed(melt(df.norm)),experiment==2)
collapsed.bs$conclusion = factor(collapsed.bs$variable, labels=c('all.C.A','none.C.A','some.C.A','not.all.C.A'))
collapsed.bs$domain = factor(collapsed.bs$domain, labels=domains)


# Load model predictions, for different parameter (n_object) values
model.dir<-'/Users/mht/Documents/research/syllogism/models/modeldata/LATTICE_4_tfbt/'
syllogisms = c("AA1", "AI1", "EA1", "EI1")

if (exists('models')){remove(models)}


total_objs = seq(3,9,2)
for (n_obj in total_objs){
  model.domains = data.frame()
  for (d in domains){
    model.all<-read.csv(paste(model.dir,'/00/csv/lis_N0_M0_tfbt',
                   d,'_qud1figFull_AIEOc4CAEP',EP,'_n',n_obj,
                   '_base0.00_s100k_alphQ1_alphR1_bsmean.csv',sep=''))[c(1,6:9)]
    model.sub<-model.all[model.all$X..syll%in%syllogisms,]
    model.sub$domain <- d
    model.m<-melt(model.sub,id.vars=c('X..syll','domain'))
    model.domains<-rbind(model.domains, model.m)
  }
  #rename for merging
  names(model.domains)<-c('syll','domain','conclusion',paste('n',n_obj,sep=''))
  if (exists('models')){
    models = merge(models,model.domains)
  } else {
    models = model.domains
  }
}

models$syll <- factor(models$syll)
models$domain <- factor(models$domain)

cncl_labels = levels(models$conclusion)

m.models<-melt(models, id.vars=c('syll','domain','conclusion'))

all.stuff<-merge(m.models,collapsed.bs[c('domain','syll','value','conclusion')], 
      by=c('syll','domain','conclusion'))

model.fits<-ddply(all.stuff, .(variable), summarise, cor(value.x, value.y))
names(model.fits)<-c('n','correlation')
model.fits$n<-as.integer(substring(model.fits$n,2,3))
max.loc<-which.max(model.fits$correlation)

ggplot(model.fits, aes(x=n,y=factor(1)))+
  geom_tile(aes(fill = correlation), colour = "white") + 
  geom_tile(data=model.fits[max.loc,], aes(x=n,y=1, fill=correlation),
            size=2,colour='black')+
  geom_text(aes(x=n,y=1, label=round(correlation,2)),size=5,colour='black')+
  scale_fill_gradient(low = "white", high = "steelblue",limits=c(0.8,0.95))+
  theme_bw()+
  scale_x_continuous(breaks=3:11)+
  scale_y_discrete()

models$syll <- factor(models$syll, labels = sylllabels)
models$domain <- factor(models$domain, labels = exp_domains)
models$conclusion<-factor(models$conclusion, labels = c('all','none','some','some...not'))

ggplot(subset(models), aes(x=conclusion,y=n7,fill=conclusion))+
  geom_bar(stat='identity')+
  facet_grid(domain~syll)+
  #theme_bw()+
  theme_blackDisplay()+
  ylim(0,0.7)+
  guides(fill=F)+
    theme(axis.text.x=element_text(
    angle=90,hjust=1,vjust=.5,colour='gray50'),
    strip.text.x = element_text(),
    strip.text.y = element_text(angle=0, size=20),
    title = element_text(size=30))+
  xlab('')+
  ylab('posterior probability\n')+
  ggtitle('q1 of the A B \nq2 of the B C\n q3 of the A C\n')

```

### $H_{4}$ = empirical prior with pragmatics

```{r h4exp2, echo=FALSE}
# Load model predictions, for different parameter (n_object) values               
# H4: n_objects, alpha (empirical prior + pragmatics)

model.dir<-'/Users/mht/Documents/research/syllogism/models/modeldata/LATTICE_4_tfbt/'
domains<- c('cracker', 'knife', 'lightbulb', 'strawberry')
syllogisms = c("AA1", "AI1", "EA1", "EI1")

if (exists('models')){remove(models)}

# this code relies upon the same parameter values being explored for all
# e.g. same range of alpha values for all levels of n_obj
total_objs = seq(3,9,2)
for (n_obj in total_objs){
  model.domains = data.frame()
  for (d in domains){
    dom.path = paste(model.dir,d,'/10/csv/',sep='')
    model.files <- list.files(dom.path)
    model.files <- model.files[!(grepl("CLonly",model.files))]
    model.files <- model.files[!(grepl("1000k",model.files))]
    model.files <- model.files[grepl(paste('EP',EP,"_n",n_obj,'_base',sep=''),model.files)]
    for (m.file in model.files){
      model.all<-read.csv(paste(dom.path,m.file,sep=''))[c(1,6:9)]
      model.sub<-model.all[model.all$X..syll%in%syllogisms,]
      model.sub$domain <- as.factor(d)
      model.sub$alpha <- as.numeric(substring(strsplit(m.file,'alphQ')[[1]][2],1,3))
      model.m<-melt(model.sub,id.vars=c('X..syll','domain','alpha'))
      model.domains<-rbind(model.domains, model.m)
    }
  }
  #rename for merging
  print(n_obj)
  names(model.domains)<-c('syll','domain','alpha','conclusion',paste('n',n_obj,sep=''))
  if (exists('models')){
    models = merge(models,model.domains)
  } else {
    models = model.domains
  }
}

models$syll <- factor(models$syll)

m.models<-melt(models, id.vars=c('syll','domain','alpha','conclusion'))

all.stuff<-merge(m.models,collapsed.bs[c('domain','syll','value','conclusion')], 
      by=c('syll','domain','conclusion'))

model.fits<-ddply(all.stuff, .(alpha, variable), summarise, cor(value.x, value.y))
names(model.fits)<-c('alpha','n','correlation')
model.fits$n<-as.integer(substring(model.fits$n,2,3))
model.fits$alpha<-factor(model.fits$alpha)
max.loc<-which.max(model.fits$correlation)

ggplot(model.fits, aes(x=n,y=alpha))+
  geom_tile(aes(fill = correlation), colour = "white") + 
  geom_tile(data=model.fits[max.loc,], aes(x=n,y=alpha, fill=correlation),
            size=2,colour='black')+
  geom_text(data=model.fits[max.loc,], aes(x=n,y=alpha, label=round(correlation,2)),
            size=5,colour='black')+
  scale_fill_gradient(low = "white", high = "steelblue",limits=c(0.6,0.99))+
  theme_bw()+
  scale_x_continuous(breaks=3:11)


ggplot(subset(models, alpha==5.5), aes(x=conclusion,y=n7,fill=conclusion))+
  geom_bar(stat='identity')+
  facet_grid(domain~syll)+
  theme_bw()+
  ylim(0,1)
```

# 1. Outline

The full Bayesian thing can take a variety of forms. To do this properly, we must consider the generative process behind the data. This requires taking a careful look at the dependent measure and how it can be related to probability distributions. It also requires careful consideration of the cogntive model, and especially, the *query statement*. 

## The cognitive model

Let's start with the cognitive model. Grossly, the model samples a situation from a binomial mixture and applies the quantifier premises to that situations. The model will reject the situation is it is inconsistent with the premises. If it is consistent with the premises, the model samples a conclusion which is true of the situation.

The model does this infinite times and returns a posterior distribution over conclusions (this is $P(conclusion | premises)$, or argument strength). 

## The experimental paradigm

For Experiment 1, I used 2 different dependent measures (let's call them R and S). For Experiment 2, I used only dependent measure R. Dependent Measure R was a 2AFC ("Follows"/"Doesn't follow") judgment accompanied with a confidence rating in the form of a slider bar (ranging form "Certain" to "Don't know"). Dependent Measure S was a combined judgment and confidence rating in the form of a slider bar ranging from "Certainly follows" to "Certainly doesn't follow". 

An analysis of R comparing the proportion of "Follows" judgments to the mean combined rating (radio + slider) revealed a strikingly high correlation (r>0.99), strongly suggesting no information gain from the confidence rating (see `belief-syll-exp.Rmd` for the analysis). Part of Experiment 1 was designed to look at the relationship between dependent measure R & S. The two dependent measures were highly, though not perfectly, correlated (r=0.91).

### Relating dependent measures to probability distributions

To do the full Bayesian thing, we must first imagine that data collected are samples from some probability distribution. 

#### Considering each conclusion independently.

**R**: if each conclusion is considered independently, then it is natural to think of a subject's response of a 2AFC as the result of a Bernoulli trial. 

Then, we can consider the responses of the experimental sample to be coming from a Binomial distribution, with success parameter $\theta_{ij}$, with $i \in \{all,some,none,not.all\}$ and $j \in \{syllogisms\}$. We can have at least two models of $\theta_{ij}$, corresponding to two different linking function assumptions.

1. $\theta_{ij}$ is $p_{ij}$. This is saying that responses are generated by flipping a coin and that coin weight is exactly the posterior probability of that conclusion (the output of the cognitive model). 
2. $\theta_{ij} \sim Beta$ with mean $= p_{ij}$ and some variance. This is saying that again the responses are generated by flipping a coin but that the coin weight is a random variable given by the mean of a Beta distribution. [Can we also get an estimate on the variance from the cognitive model? Perhaps by doing the bootstrap thing, or mcmc?].

```{r} 
estBetaParams <- function(mu, var) {
  alpha <- ((1 - mu) / var - 1 / mu) * mu ^ 2
  beta <- alpha * (1 / mu - 1)
  return(params = list(alpha = alpha, beta = beta))
}
```

##### Guessing

We will run into trouble with either of these approaches because there are conclusions with posterior probability = 1 (and others, = 0). This will yield poor estimates of the marginal probability of the data given the model. We may get around this problem in a number of ways:

A. The subjects' responses come from a mixture model. $\phi$ proportion of subjects' responses are imagined to be a result of random guessing. This will soak up some of the probabiltity mass and make non-zero outcomes to 0-probability conclusions at least somewhat plausible. 
B. The cognitive model might include some probability of random guessing, with the expression `(if (flip phi) true)` in the conditioning statement. I'm pretty sure this is equivalent to (1), though the interpretation of $phi$ is less transparent in this version.
C. Revise the cognitive model to take some number of samples. This will still have the problem of 0 probability events. 

Let's try to write down the model (2A).

```{r model2A}
library(abind)
# Load model predictions, for different parameter (n_object) values
model.dir<-'/Users/mht/Documents/research/syllogism/models/modeldata/LATTICE_4_tfbt/'

experiment='Both'

if (experiment==1){
  syllogisms = c('AO2', 'EA3', 'IE1', 'OA1')
  target.buttons = c('radio')}
if (experiment==2){
  syllogisms = c('AA1','AI1','EA1','EI1')
  target.buttons = c('radio.2')}
if (experiment=='Both'){
  syllogisms = c('AO2', 'EA3', 'IE1', 'OA1','AA1','AI1','EA1','EI1')
  target.buttons = c('radio','radio.2')}

corrs = c()
if (exists('models')){remove(models)}


for (n_obj in 3:11){
  model.domains = data.frame()
  for (d in domains){
    model.all<-read.csv(paste(model.dir,'/00/csv/lis_N0_M0_tfbt',
                   d,'_qud1figFull_AIEOc4CAEP1_n',n_obj,
                   '_base0.00_s100k_alphQ1_alphR1_bsmean.csv',sep=''))[c(1,6:9)]
    model.sub<-model.all[model.all$X..syll%in%syllogisms,]
    model.sub$domain <- d
    model.m<-melt(model.sub,id.vars=c('X..syll','domain'))
    model.domains<-rbind(model.domains, model.m)
  }
  #rename for merging
  names(model.domains)<-c('syll','domain','conclusion',paste('n',n_obj,sep=''))
  if (exists('models')){
    models = merge(models,model.domains)
  } else {
    models = model.domains
  }
}

models$syll <- factor(models$syll)
models$domain <- factor(models$domain)

cncl_labels = levels(models$conclusion)

setwd("/Users/mht/Documents/research/syllogism/analysis/")
models.c<-dcast(melt(models, id.vars=c('syll','domain','conclusion')), ... ~ conclusion)

model.preds = subset(models.c)
data.obs = subset(df.c, (condition%in%target.buttons))[,c("subj","syll","domain","radio_A","radio_E","radio_I","radio_O")] # subset data condition==radio and take only radio button vals
data.obs = data.obs[order(data.obs[,1]),]
data.obs$subj<- factor(data.obs$subj)
data.obs$syll<- factor(data.obs$syll)
data.obs$domain<- factor(data.obs$domain)


tot.subj <- length(levels(data.obs$subj))
tot.syll <- length(levels(model.preds$syll)) #number of syllogisms
tot.resp <- length(levels(models$conclusion)) # number of responses
tot.dom <- length(levels(models$domain)) # number of domains
tot.n <- length(levels(model.preds$variable))

# # data is organized,  syll X response X domain X subj [i,j,u,k]
data.array<-abind(
      Map(
        function(x){          
          sb = subset(data.obs,subj==x)
          list.of.sb.arrays <- Map(function(d) {
            syll.data <- subset(sb,domain==d)
            a = syll.data$syll
            blank = array(NA,c(tot.syll,tot.resp))
            if (nrow(syll.data)!=0){
              j = Position(function(y){a==y},levels(data.obs$syll))
              blank[j,1:4] = syll.data[,c('radio_A','radio_E','radio_I','radio_O')]
              }
            b = matrix(blank,nrow=tot.syll)
            return(b)
          }, 
          levels(data.obs$domain))
          return(abind(list.of.sb.arrays,along=3))
          },
         levels(data.obs$subj)),along=4)

# model is organized,  syll X response X domain X subj [i,j,u,k]
model.array<-abind(
      Map(
        function(x){          
          sb = subset(model.preds,variable==x)
          list.of.sb.arrays <- Map(function(d) {
            syll.data <- subset(sb,domain==d)
            a = syll.data$syll
            blank = array(NA,c(tot.syll,tot.resp))
            j = match(levels(data.obs$syll),a)
            blank = syll.data[j,c('all.C.A','none.C.A','some.C.A','not.all.C.A')]
            b = array(blank)
            return(b)
          }, 
          levels(model.preds$domain))
          return(abind(list.of.sb.arrays,along=3))
          },
         levels(model.preds$variable)),along=4)

# data is organized,  syll X response X subj [i,j,k]
# data.array<-abind(
#       Map(
#         function(x){          
#           sb = subset(data.obs,subj==x)
#             a = sb$syll
#             blank = array(NA,c(4,4))
#             if (nrow(sb)!=0){
#               j = Position(function(y){a==y},levels(data.obs$syll))
#               blank[j,1:4] = sb[,c('radio_A','radio_E','radio_I','radio_O')]
#               }
#             b = matrix(blank,nrow=4)
#             return(b)
#           },
#          levels(data.obs$subj)),along=3)
# 
# 
# 
# # model to be organized,  syll X response X n_objects [i,j,k]
# model.array<-abind(
#       Map(
#         function(x){
#           sb = subset(model.preds,variable==x)
#           a = sb$syll
#           j = match(a,levels(model.preds$syll))
#           blank = array(NA,c(4,4))
#           blank = sb[j,c('all.C.A','none.C.A','some.C.A','not.all.C.A')]
#           b = array(blank)
#           return(b)
#           },
#          levels(model.preds$variable)),along=3)
# cat('model{
#   # cogntive model predictions
#   n ~ dcat(prior_on_objects[])
# 
#   # base rate of guessing, globally
#   phi  ~ dbeta(1,1)
#     for (i in 1:tot.syll){
#       for (j in 1:tot.resp){
#         for (k in 1:tot.subj){
#         # Each response Belongs To One Of Two Latent Groups (reasoning or guessing)
#         x[i,j,k] ~ dbern(phi)
#         # Data are Bernoulli With Rate Given either cogmod or guess
#         theta[i,j,k] <- equals(x[i,j,k],0)*churchmod[i,j,n]+equals(x[i,j,k],1)*0.5
#         d[i,j,k] ~ dbern(theta[i,j,k])
#   }}}
# 
# }', file={f<-tempfile()})


cat('model{
  # cogntive model predictions
  n ~ dcat(prior_on_objects[])

  # base rate of guessing, globally
  phi  ~ dbeta(1,1)
  for (u in 1:tot.dom){
    for (i in 1:tot.syll){
      for (j in 1:tot.resp){
        for (k in 1:tot.subj){
        # Each response Belongs To One Of Two Latent Groups (reasoning or guessing)
        x[i,j,u,k] ~ dbern(phi)
        # Data are Bernoulli With Rate Given either cogmod or guess
        theta[i,j,u,k] <- equals(x[i,j,u,k],0)*churchmod[i,j,u,n]+equals(x[i,j,u,k],1)*0.5
        d[i,j,u,k] ~ dbern(theta[i,j,u,k])
  }}}}

}', file={f<-tempfile()})

# cat('model{
#   # cogntive model predictions
#   n ~ dcat(prior_on_objects[])
# 
# 
# for (i in 1:tot.syll){
#   # base rate of guessing, by syll
#   phi[i]  ~ dbeta(1,1)
#   for (u in 1:tot.dom){
#     for (j in 1:tot.resp){
#         for (k in 1:tot.subj){
#         # Each response Belongs To One Of Two Latent Groups (reasoning or guessing)
#         x[i,j,u,k] ~ dbern(phi[i])
#         # Data are Bernoulli With Rate Given either cogmod or guess
#         theta[i,j,u,k] <- equals(x[i,j,u,k],0)*churchmod[i,j,u,n]+equals(x[i,j,u,k],1)*0.5
#         d[i,j,u,k] ~ dbern(theta[i,j,u,k])
#   }}}}
# 
# }', file={f<-tempfile()})

emprior <- 1
depth <- 0
prior_on_objects <- rep(1/tot.obj,tot.obj) # uniform prior on objects
d<- data.array
churchmod <- model.array
#sapply(model.preds[1,cncl_labels], estBetaParams, var=0.01)
# 
# data <- list("tot.subj", "tot.syll", "tot.resp",
#              "d","prior_on_objects","churchmod") # to be passed on to JAGS
# #initial values for guessing
# x.init = array(round(runif(tot.subj*tot.syll*tot.resp)),
#                  c(tot.syll,tot.resp,tot.subj))
# postz = which(churchmod==0,arr.ind=TRUE)
# for (pz in 1:length(postz[,1])){
#   x.init[postz[pz,c('dim1')],postz[pz,c('dim2')],]=1
# }
# x.init2 = array(round(runif(tot.subj*tot.syll*tot.resp)),
#                  c(tot.syll,tot.resp,tot.subj))
# for (pz in 1:length(postz[,1])){
#   x.init2[postz[pz,c('dim1')],postz[pz,c('dim2')],]=1
# }



data <- list("tot.subj", "tot.syll", "tot.resp","tot.dom",
             "d","prior_on_objects","churchmod") # to be passed on to JAGS
#initial values for guessing
x.init = array(round(runif(tot.subj*tot.syll*tot.resp*tot.dom)),
                 c(tot.syll,tot.resp,tot.dom,tot.subj))

postz = which(churchmod==0,arr.ind=TRUE)
for (pz in 1:length(postz[,1])){
  x.init[postz[pz,c('dim1')],postz[pz,c('dim2')],postz[pz,c('dim3')],]=1
}

x.init2 = array(round(runif(tot.subj*tot.syll*tot.resp*tot.dom)),
                 c(tot.syll,tot.resp,tot.dom,tot.subj))
for (pz in 1:length(postz[,1])){
  x.init2[postz[pz,c('dim1')],postz[pz,c('dim2')],postz[pz,c('dim3')],]=1
}

myinits <-  list(
  list(phi = 0.5, 
       x = x.init,
      n = 4
       ),
    list(phi = 0.5, 
       x = x.init2,
      n = 4
       ))

# myinits <-  list(
#   list(
#        x = x.init,
#       n = 4
#        ),
#     list(
#        x = x.init2,
#       n = 4
#        ))



# parameters to be monitored:  
parameters <- c("n","phi")

samples <- jags(data, inits=myinits, parameters,
   			 model.file =f, n.chains=2, n.iter=1000, 
         n.burnin=100, n.thin=1, DIC=T)


df <-data.frame(n=samples$BUGSoutput$sims.list$n,
                phi=samples$BUGSoutput$sims.list$phi)



setwd("~/Documents/research/syllogism/presentations/labmtg-111914")

plot1<-ggplot(df, aes(x=2+n))+
  geom_histogram(fill='white')+
  theme_blackDisplay()+
  scale_x_continuous(breaks=seq(3,11))+
  guides(fill=F)+
  xlab("\n n_objects")

ggsave(filename = paste('literalEP',EP,'_posteriorN_exp',experiment,'.png',sep=''),plot1, width=16, height=12)



plot2<-ggplot(df, aes(x=phi))+
  geom_density(fill='white')+
  theme_blackDisplay()+
  xlab("\n phi")+
    guides(fill=F)+
    coord_cartesian(xlim=c(0, 1)) + 
  scale_x_continuous(breaks=c(0.25,0.5,0.75))

ggsave(filename = paste('literalEP',EP,'_posteriorPhi_exp',experiment,'retest.png',sep=''),plot2, width=16, height=12)


# df.m=melt(df[,2:9])
# df.m$syll<-factor(df.m$variable,labels=levels(data.obs$syll))

# df.m$syllogism <- factor(df.m$syll, levels = c('AO2', 'EA3', 'IE1', 'OA1','AA1','AI1','EA1','EI1'),
#                            labels=c("Some of the As are not Bs\n All of the Cs are Bs",
#                                     "All of the Bs are As\n None of Bs are Cs",
#                                     "None of the As are Bs\n Some of the Bs are Cs",
#                                     "All of the As are Bs\n Some of the Bs are not Cs",
#                                     "All of the As are Bs\n All of the Bs are Cs",
#                                     "Some of the As are Bs\n All of the Bs are Cs",
#                                     "All of the As are Bs\n None of the Bs are Cs",
#                                     "Some of the As are Bs\n None of the Bs are Cs"
#                            ))
# 
# plot1<-ggplot(df.m, aes(x=value,fill=syllogism))+
#   geom_histogram()+
#   theme_blackDisplay()+
#   facet_wrap(~syllogism,nrow=2)+
#     coord_cartesian(xlim=c(0, 1)) + 
#   scale_x_continuous(breaks=c(0.5))+
#   guides(fill=F)+
#   xlab("\n phi")
# 
# ggsave(filename = paste('literalEP',EP,'_posteriorPhi_exp',experiment,'_facetSyll.png',sep=''),plot1, width=24, height=18)
# 

# plot2<-ggplot(df, aes(x=2+n))+
#   geom_histogram(fill='white')+
#   theme_blackDisplay()+
#   scale_x_continuous(breaks=seq(3,11))+
#   guides(fill=F)+
#   xlab("\n n_objects")
# 
# ggsave(filename = paste('literalEP',EP,'_posteriorN_exp',experiment,'_facetSyll.png',sep=''),plot2, width=16, height=12)







# more complex; not complete

# cat('model{
#   # cogntive model predictions, mu known, lambda maybe known
#   lambda[j,k] ~ dgamma(0.001,0.001)
#   sigma[j,k] <- 1/sqrt(lambda[j,k])
#   alpha[j,k] <- (((1 - mu[j,k]) / (sigma[j,k]^2)) - (1 / mu[j,k])) * mu[j,k] ^ 2
#   beta[j,k] <- alpha[j,k] * (1 / mu[j,k] - 1)
#   phi[j,k] ~ dbeta(alpha[j,k],beta[j,k])
# 
# 
#   # Each response Belongs To One Of Two Latent Groups (reasoning or guessing)
#     x[i,j] ~ dbern(psi)
#   # Guesses
#   psi <- 0.5
#   # base rate of guessing, for a particular syllogism
#   psi[j] ~ dbeta(1,1)
#   
#   # Rate Of Success -- posterior of model
#   
#   # Data are Bernoulli With Rate Given either cogmod or guess
#     theta[i,j,k] <- equals(x[i,j],0)*phi[j,k]+equals(x[i,j],1)*0.5
#     d[i,j,k] ~ dbern(theta[i,j,k])
# 
# }', file={f<-tempfile()})



```

Let's try analyzing the 4 domains independently, 


```{r model2A}
library(abind)
# Load model predictions, for different parameter (n_object) values
model.dir<-'/Users/mht/Documents/research/syllogism/models/modeldata/LATTICE_4_tfbt/'
#syllogisms = c('AO2', 'EA3', 'IE1', 'OA1')
syllogisms = c('AA1','AI1','EA1','EI1')


corrs = c()
if (exists('models')){remove(models)}

df<-data.frame()
for (n_obj in 3:11){
  model.domains = data.frame()
  for (d in domains){
    model.all<-read.csv(paste(model.dir,'/00/csv/lis_N0_M0_tfbt',
                   d,'_qud1figFull_AIEOc4CAEP1_n',n_obj,
                   '_base0.00_s100k_alphQ1_alphR1_bsmean.csv',sep=''))[c(1,6:9)]
    model.sub<-model.all[model.all$X..syll%in%syllogisms,]
    model.sub$domain <- d
    model.m<-melt(model.sub,id.vars=c('X..syll','domain'))
    model.domains<-rbind(model.domains, model.m)
  }
  #rename for merging
  names(model.domains)<-c('syll','domain','conclusion',paste('n',n_obj,sep=''))
  if (exists('models')){
    models = merge(models,model.domains)
  } else {
    models = model.domains
  }
}

models$syll <- factor(models$syll)
models$domain <- factor(models$domain)

cncl_labels = levels(models$conclusion)

setwd("/Users/mht/Documents/research/syllogism/analysis/")
models.c<-dcast(melt(models, id.vars=c('syll','domain','conclusion')), ... ~ conclusion)

plurd<- levels(df.c$domain)
names(plurd)<-levels(models$domain)
for (dom.index in levels(models$domain)){

  model.preds = subset(models.c, domain==dom.index)
  data.obs = subset(df.c, (condition=='radio.2' & domain==plurd[[dom.index]]))[,c("subj","syll","domain","radio_A","radio_E","radio_I","radio_O")] # subset data condition==radio and take only radio button vals
  data.obs = data.obs[order(data.obs[,1]),]
  data.obs$subj<- factor(data.obs$subj)
  data.obs$syll<- factor(data.obs$syll)
  data.obs$domain<- factor(data.obs$domain)
  
  
  tot.subj <- length(levels(data.obs$subj))
  tot.syll <- length(levels(model.preds$syll)) #number of syllogisms
  tot.resp <- length(levels(models$conclusion)) # number of responses
  tot.dom <- length(levels(models$domain)) # number of domains
  tot.n <- length(levels(model.preds$variable))

# # data is organized,  syll X response X domain X subj [i,j,u,k]
# data.array<-abind(
#       Map(
#         function(x){          
#           sb = subset(data.obs,subj==x)
#           list.of.sb.arrays <- Map(function(d) {
#             syll.data <- subset(sb,domain==d)
#             a = syll.data$syll
#             blank = array(NA,c(4,4))
#             if (nrow(syll.data)!=0){
#               j = Position(function(y){a==y},levels(data.obs$syll))
#               blank[j,1:4] = syll.data[,c('radio_A','radio_E','radio_I','radio_O')]
#               }
#             b = matrix(blank,nrow=4)
#             return(b)
#           }, 
#           levels(data.obs$domain))
#           return(abind(list.of.sb.arrays,along=3))
#           },
#          levels(data.obs$subj)),along=4)
# 
# # model is organized,  syll X response X domain X subj [i,j,u,k]
# model.array<-abind(
#       Map(
#         function(x){          
#           sb = subset(model.preds,variable==x)
#           list.of.sb.arrays <- Map(function(d) {
#             syll.data <- subset(sb,domain==d)
#             a = syll.data$syll
#             blank = array(NA,c(4,4))
#             j = match(a,levels(model.preds$syll))
#             blank = syll.data[j,c('all.C.A','none.C.A','some.C.A','not.all.C.A')]
#             b = array(blank)
#             return(b)
#           }, 
#           levels(model.preds$domain))
#           return(abind(list.of.sb.arrays,along=3))
#           },
#          levels(model.preds$variable)),along=4)

  # data is organized,  syll X response X subj [i,j,k]
  data.array<-abind(
        Map(
          function(x){          
            sb = subset(data.obs,subj==x)
              a = sb$syll
              blank = array(NA,c(4,4))
              if (nrow(sb)!=0){
                j = Position(function(y){a==y},levels(data.obs$syll))
                blank[j,1:4] = sb[,c('radio_A','radio_E','radio_I','radio_O')]
                }
              b = matrix(blank,nrow=4)
              return(b)
            },
           levels(data.obs$subj)),along=3)



  # model to be organized,  syll X response X n_objects [i,j,k]
  model.array<-abind(
        Map(
          function(x){
            sb = subset(model.preds,variable==x)
            a = sb$syll
            j = match(a,levels(model.preds$syll))
            blank = array(NA,c(4,4))
            blank = sb[j,c('all.C.A','none.C.A','some.C.A','not.all.C.A')]
            b = array(blank)
            return(b)
            },
           levels(model.preds$variable)),along=3)

  cat('model{
    # cogntive model predictions
    n ~ dcat(prior_on_objects[])
  
    # base rate of guessing, globally
    phi  ~ dbeta(1,1)
      for (i in 1:tot.syll){
        for (j in 1:tot.resp){
          for (k in 1:tot.subj){
          # Each response Belongs To One Of Two Latent Groups (reasoning or guessing)
          x[i,j,k] ~ dbern(phi)
          # Data are Bernoulli With Rate Given either cogmod or guess
          theta[i,j,k] <- equals(x[i,j,k],0)*churchmod[i,j,n]+equals(x[i,j,k],1)*0.5
          d[i,j,k] ~ dbern(theta[i,j,k])
    }}}
  
  }', file={f<-tempfile()})


# cat('model{
#   # cogntive model predictions
#   n ~ dcat(prior_on_objects[])
# 
#   # base rate of guessing, globally
#   phi  ~ dbeta(1,1)
#   for (u in 1:tot.dom){
#     for (i in 1:tot.syll){
#       for (j in 1:tot.resp){
#         for (k in 1:tot.subj){
#         # Each response Belongs To One Of Two Latent Groups (reasoning or guessing)
#         x[i,j,u,k] ~ dbern(phi)
#         # Data are Bernoulli With Rate Given either cogmod or guess
#         theta[i,j,u,k] <- equals(x[i,j,u,k],0)*churchmod[i,j,u,n]+equals(x[i,j,u,k],1)*0.5
#         d[i,j,u,k] ~ dbern(theta[i,j,u,k])
#   }}}}
# 
# }', file={f<-tempfile()})

  emprior <- 1
  depth <- 0
  prior_on_objects <- rep(1/tot.obj,tot.obj) # uniform prior on objects
  d<- data.array
  churchmod <- model.array
#sapply(model.preds[1,cncl_labels], estBetaParams, var=0.01)

  data <- list("tot.subj", "tot.syll", "tot.resp",
               "d","prior_on_objects","churchmod") # to be passed on to JAGS
  #initial values for guessing
  x.init = array(round(runif(tot.subj*tot.syll*tot.resp)),
                   c(tot.syll,tot.resp,tot.subj))
  postz = which(churchmod==0,arr.ind=TRUE)
  for (pz in 1:length(postz[,1])){
    x.init[postz[pz,c('dim1')],postz[pz,c('dim2')],]=1
  }
  x.init2 = array(round(runif(tot.subj*tot.syll*tot.resp)),
                   c(tot.syll,tot.resp,tot.subj))
  for (pz in 1:length(postz[,1])){
    x.init2[postz[pz,c('dim1')],postz[pz,c('dim2')],]=1
  }



# data <- list("tot.subj", "tot.syll", "tot.resp","tot.dom",
#              "d","prior_on_objects","churchmod") # to be passed on to JAGS
# #initial values for guessing
# x.init = array(round(runif(tot.subj*tot.syll*tot.resp*tot.dom)),
#                  c(tot.syll,tot.resp,tot.dom,tot.subj))
# 
# postz = which(churchmod==0,arr.ind=TRUE)
# for (pz in 1:length(postz[,1])){
#   x.init[postz[pz,c('dim1')],postz[pz,c('dim2')],postz[pz,c('dim3')],]=1
# }
# 
# x.init2 = array(round(runif(tot.subj*tot.syll*tot.resp*tot.dom)),
#                  c(tot.syll,tot.resp,tot.dom,tot.subj))
# for (pz in 1:length(postz[,1])){
#   x.init2[postz[pz,c('dim1')],postz[pz,c('dim2')],postz[pz,c('dim3')],]=1
# }

  myinits <-  list(
    list(phi = 0.1, 
         x = x.init,
        n = 1
         ),
      list(phi = 0.2, 
         x = x.init2,
        n = 4
         ))
  
  # parameters to be monitored:  
  parameters <- c("n","phi")

  samples <- jags(data, inits=myinits, parameters,
       		 model.file =f, n.chains=2, n.iter=1000, 
           n.burnin=100, n.thin=1, DIC=T)


df.temp <-data.frame(n=samples$BUGSoutput$sims.list$n,
                phi=samples$BUGSoutput$sims.list$phi,
                domain=dom.index)

df<-rbind(df,df.temp)
}

# PLOT

setwd("~/Documents/research/syllogism/presentations/labmtg-111914")

plot1<-ggplot(df, aes(x=2+n,fill=domain))+
  geom_histogram()+
  theme_blackDisplay()+
  facet_wrap(~domain)+
  scale_x_continuous(breaks=seq(3,11))+
  guides(fill=F)+
  xlab("\n n_objects")

ggsave(filename = paste('literalEP',EP,'_posteriorN_exp2_facetDomain.png',sep=''),plot1, width=16, height=12)



plot2<-ggplot(df, aes(x=phi,fill=domain))+
  geom_density()+
  theme_blackDisplay()+
  facet_wrap(~domain)+
  xlab("\n phi")+
    guides(fill=F)+
    coord_cartesian(xlim=c(0, 1)) + 
  scale_x_continuous(breaks=c(0.25,0.5,0.75))


ggsave(filename = paste('literalEP',EP,'_posteriorPhi_exp2_facetDomain.png',sep=''),plot2, width=16, height=12)


```