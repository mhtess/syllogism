{
 "metadata": {
  "name": "",
  "signature": "sha256:b2c5d616f435de66f1d621eb4f73ecd96c4f637022d6b1622243c95531cca4b5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Experiment 1: prior elicitation\n",
      "\n",
      "Experiment to elicit priors for 6 causal domains. This notebook takes the mturk data and writes the relevant data to a csv. It writes a second file with just the means. Further down, it looks at the priors in more detail; primarily, to see if the priors could have been generated from 3 independent coin flips (something like \"unstructured knowledge\")."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from scipy.optimize import minimize\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline \n",
      "import ast\n",
      "import glob"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "expname = '03syllogism_prior_psychjs'\n",
      "priorpath = ('/Users/mht/Documents/research/syllogism/experiments/%s' % (expname))\n",
      "datapath = ('/Users/mht/Documents/research/syllogism/data/%s' % (expname))\n",
      "priorfile = priorpath + '/prior-exp-mturk.tsv'\n",
      "priors = pd.read_csv(priorfile,sep='\\t')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = priors[\"Answer.2\"] # data for elicitation trials\n",
      "b = [ast.literal_eval(x) for x in a] #literalize the mturk data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_priors = pd.DataFrame() # start new data frame for all subjects data\n",
      "for i, subj_info in enumerate(b): # loop through subjects\n",
      "    temp = pd.DataFrame.from_dict(subj_info) # turn subj data into df\n",
      "    temp.insert(0,\"subj\",\"s\"+str(i)) # insert subject identifier\n",
      "    all_priors = pd.concat([all_priors,temp],ignore_index=True) # add subj df to all_subj df\n",
      "# convert \"trial_domain\" (obj) into \"domain\" (string)\n",
      "all_priors[\"domain\"] = pd.Series([item for sublist in all_priors.trial_domain for item in sublist])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 1. Normed means by domain and dependent measure"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# property labels\n",
      "property_labels = list(all_priors.columns.values[1:9])\n",
      "# New df for the means\n",
      "pr_means = pd.DataFrame(columns=(['domain','condition'] + property_labels))\n",
      "\n",
      "for j in range(2): # loop through condition (plausibility / frequency)\n",
      "    for i, dom in enumerate(list(set(all_priors[\"domain\"]))): # through domain\n",
      "        df0 = all_priors[((all_priors.domain == dom) & (all_priors.condition == j))][property_labels] # subset by domain\n",
      "        normed_means = df0.div(df0.sum(axis=1),axis=0).apply(np.mean) # Normalize each item, take means\n",
      "        pr_means.loc[i+6*j] = pd.Series([dom,j],[\"domain\",\"condition\"]).append(normed_means) # Load normed means\n",
      "        \n",
      "# reorder columns so that it's monotonic in number of present properties\n",
      "cols = pr_means.columns.tolist()\n",
      "cols = cols[0:5] + [cols[6]] + [cols[5]] + cols[7::]\n",
      "pr_means = pr_means[cols]\n",
      "pr_means.columns = [\"domain\",\"condition\",\"111\",\"110\",\"101\",\"011\",\"100\",\"010\",\"001\",\"000\"]\n",
      "pr_means.condition = pr_means.condition.replace(0,\"plausibility\")\n",
      "pr_means.condition = pr_means.condition.replace(1,\"frequency\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 2. Alternatively: collapse across dependent measures"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# property labels\n",
      "property_labels = list(all_priors.columns.values[1:9])\n",
      "# New df for the means\n",
      "pr_means = pd.DataFrame(columns=(['domain','condition'] + property_labels))\n",
      "\n",
      "for i, dom in enumerate(list(set(all_priors[\"domain\"]))): # through domain\n",
      "    df0 = all_priors[(all_priors.domain == dom)][property_labels] # subset by domain\n",
      "    normed_means = df0.div(df0.sum(axis=1),axis=0).apply(np.mean) # Normalize each item, take means\n",
      "    pr_means.loc[i] = pd.Series([dom,'tfbt'],[\"domain\",\"condition\"]).append(normed_means) # Load normed means\n",
      "        \n",
      "# reorder columns so that it's monotonic in number of present properties\n",
      "cols = pr_means.columns.tolist()\n",
      "cols = cols[0:5] + [cols[6]] + [cols[5]] + cols[7::]\n",
      "pr_means = pr_means[cols]\n",
      "pr_means.columns = [\"domain\",\"condition\",\"111\",\"110\",\"101\",\"011\",\"100\",\"010\",\"001\",\"000\"]\n",
      "\n",
      "pr_means.to_csv(datapath+'/prior-exp-mturk_collapsed_means_n71.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "pr_means.to_csv(datapath+'/prior-exp-mturk_means_n71.csv')\n",
      "all_priors.to_csv(datapath+'/prior-exp-mturk_all_n71.csv')"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Could these priors (means) have been generated by independent coin flips?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### A, B, C ~ Bernoulli ( <code>a, b, c</code>) i.d. (not identical)"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "# test case for code\n",
      "\n",
      "test_case = pd.DataFrame(columns=(['domain','condition'] + property_labels))\n",
      "a, b, c = 0.3, 0.4, 0.5\n",
      "tst = ['cats', 0, (a*b*c), (a*b*(1-c)), (a*(1-b)*c), (a*(1-b)*(1-c)), \\\n",
      "       ((1-a)*b*c), ((1-a)*b*(1-c)), ((1-a)*(1-b)*c), ((1-a)*(1-b)*(1-c))]\n",
      "test_case.loc[0] = tst\n",
      "\n",
      "a, b, c = 0.2, 0.1, 0.8\n",
      "tst = ['rats', 1, (a*b*c), (a*b*(1-c)), (a*(1-b)*c), (a*(1-b)*(1-c)), \\\n",
      "       ((1-a)*b*c), ((1-a)*b*(1-c)), ((1-a)*(1-b)*c), ((1-a)*(1-b)*(1-c))]\n",
      "\n",
      "test_case.loc[1] = tst\n",
      "\n",
      "pr_means = test_case\n",
      "pr_means"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# define objective function to minimize\n",
      "\n",
      "def fun1(a,b,c):\n",
      "    return a*b*c\n",
      "\n",
      "def fun2(a,b,c):\n",
      "    return a*b*(1-c)\n",
      "\n",
      "def fun3(a,b,c):\n",
      "    return a*(1-b)*(1-c)\n",
      "\n",
      "def fun4(a,b,c):\n",
      "    return (1-a)*(1-b)*(1-c)\n",
      "\n",
      "def objective(x,priors,plabels):\n",
      "    \n",
      "    p1dev = ((fun1(x[0],x[1],x[2])-priors[plabels[0]])**2).sum()\n",
      "    \n",
      "    p2dev = ((fun2(x[0],x[1],x[2])-priors[plabels[1]])**2).sum()+ \\\n",
      "            ((fun2(x[2],x[0],x[1])-priors[plabels[2]])**2).sum()+ \\\n",
      "            ((fun2(x[1],x[2],x[0])-priors[plabels[3]])**2).sum()\n",
      "    \n",
      "    p3dev = ((fun3(x[0],x[1],x[2])-priors[plabels[4]])**2).sum()+ \\\n",
      "            ((fun3(x[1],x[2],x[0])-priors[plabels[5]])**2).sum()+ \\\n",
      "            ((fun3(x[2],x[0],x[1])-priors[plabels[6]])**2).sum()\n",
      "            \n",
      "    p4dev = ((fun1(x[0],x[1],x[2])-priors[plabels[7]])**2).sum()\n",
      "    \n",
      "    return p1dev+p2dev+p3dev+p4dev"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x0 = np.array([0.3,0.45,0.5]) #starting guess\n",
      "opt_br = []\n",
      "param_labels = pr_means.columns.tolist()[2:10]\n",
      "\n",
      "for pr in pr_means.iterrows():\n",
      "    min_out = minimize(objective,x0,args=(pr[1],param_labels),method='nelder-mead')\n",
      "    opt_br.append(min_out.x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# use best fit (flips) to generate distribution over 3 properties\n",
      "bf_predall = pd.DataFrame(columns=pr_means.columns.values)\n",
      "\n",
      "for i, br in enumerate(opt_br):\n",
      "    bf_pred = []\n",
      "    bf_pred.append(pr_means.loc[i][0])\n",
      "    bf_pred.append(pr_means.loc[i][1])\n",
      "    bf_pred.append(fun1(br[0],br[1],br[2]))\n",
      "\n",
      "    bf_pred.append(fun2(br[0],br[1],br[2]))\n",
      "    bf_pred.append(fun2(br[2],br[0],br[1]))\n",
      "    bf_pred.append(fun2(br[0],br[1],br[0]))\n",
      "\n",
      "    bf_pred.append(fun3(br[0],br[1],br[2]))\n",
      "    bf_pred.append(fun3(br[1],br[2],br[0]))\n",
      "    bf_pred.append(fun3(br[2],br[0],br[1]))\n",
      "\n",
      "    bf_pred.append(fun4(br[0],br[1],br[2]))\n",
      "\n",
      "    bf_predall.loc[i] = bf_pred\n",
      "    \n",
      "pr_melt=pd.melt(pr_means,id_vars=['domain','condition'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# correlation between all elicited priors and best fit (flips)\n",
      "pr_melt=pd.melt(pr_means,id_vars=['domain','condition'])\n",
      "bf_melt=pd.melt(bf_predall,id_vars=['domain','condition'])\n",
      "a = pd.merge(bf_melt,pr_melt,on=['variable','domain','condition'])\n",
      "corr = a[\"value_x\"].corr(a[\"value_y\"])\n",
      "print corr\n",
      "print a.query('condition == \"plausibility\"').value_x.corr(a.query('condition == \"plausibility\"').value_y)\n",
      "print a.query('condition == \"frequency\"').value_x.corr(a.query('condition == \"frequency\"').value_y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.656490459903\n",
        "0.317658209065\n",
        "0.777893141422\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Seems that the frequency priors are more \"independent\" than the plausibility priors. I wonder if that actually translates into better model differentiation. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#plot (some of) that shit\n",
      "x = np.arange(len(bf_predall.columns.values[2::]))\n",
      "\n",
      "fig, ((ax, bx),(cx, dx), (ex, fx)) = plt.subplots(nrows=3, ncols=2)\n",
      "fig.set_size_inches(10,6)\n",
      "plt.setp(((ax, bx),(cx, dx), (ex, fx)), xticks=x+0.2, \n",
      "         xticklabels=('111','110','101','011','100','010','001','000'))\n",
      "\n",
      "\n",
      "#ax = plt.subplot(211)\n",
      "ax.bar(x+0.2, bf_predall.loc[0][2::], width=0.4,color='r',alpha=0.5)\n",
      "ax.bar(x-0.2, pr_means.iloc[0][2::],width=0.4,color='y',alpha=0.5)\n",
      "ax.set_ylim((0,0.200))\n",
      "\n",
      "#bx = plt.subplot(212)\n",
      "bx.bar(x+0.2, bf_predall.loc[1][2::], width=0.4,color='r',alpha=0.5)\n",
      "bx.bar(x-0.2, pr_means.iloc[1][2::],width=0.4,color='y',alpha=0.5)\n",
      "bx.set_ylim((0,0.200))\n",
      "\n",
      "#cx = plt.subplot(221)\n",
      "cx.bar(x+0.2, bf_predall.loc[2][2::], width=0.4,color='r',alpha=0.5)\n",
      "cx.bar(x-0.2, pr_means.iloc[2][2::],width=0.4,color='y',alpha=0.5)\n",
      "cx.set_ylim((0,0.200))\n",
      "\n",
      "#dx = plt.subplot(222)\n",
      "dx.bar(x+0.2, bf_predall.loc[3][2::], width=0.4,color='r',alpha=0.5)\n",
      "dx.bar(x-0.2, pr_means.iloc[3][2::],width=0.4,color='y',alpha=0.5)\n",
      "dx.set_ylim((0,0.200))\n",
      "\n",
      "#cx = plt.subplot(221)\n",
      "ex.bar(x+0.2, bf_predall.loc[4][2::], width=0.4,color='r',alpha=0.5)\n",
      "ex.bar(x-0.2, pr_means.iloc[4][2::],width=0.4,color='y',alpha=0.5)\n",
      "ex.set_ylim((0,0.200))\n",
      "\n",
      "#dx = plt.subplot(222)\n",
      "fx.bar(x+0.2, bf_predall.loc[5][2::], width=0.4,color='r',alpha=0.5)\n",
      "fx.bar(x-0.2, pr_means.iloc[5][2::],width=0.4,color='y',alpha=0.5)\n",
      "fx.set_ylim((0,0.200))\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAlUAAAFwCAYAAACRj46qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyub/A6cITh8Iawr+AAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x108228c10>"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Syllogism model with (mean) empirical priors"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "expname = 'prior-exp-mturk_means_n71'\n",
      "priorpath = ('/Users/mht/Documents/research/syllogism/data/03syllogism_prior_psychjs/')\n",
      "priorfile = priorpath + expname +'.csv'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "os.chdir(\"/Users/mht/Documents/research/syllogism/models\")\n",
      "from syll_model import syllogism_model\n",
      "\n",
      "n_obj, br, ndepth, mdepth, alphq, alphr = 4, 0, 0, 0, 1, 1\n",
      "serv, nvc, vc, vcord, exp, fig, lis, EPin = 0, 0, 4,'CA','AIEO', 'Full', 'lis', 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "allpriors = ['lightbulb','tomatoplant','cracker', \\\n",
      "             'strawberry','painting','knife'] \n",
      "alltypes = ['plausibility','frequency']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# OED for pragmatics, compare across a range of param vals\n",
      "n_objects = [7]\n",
      "alphas = [3]\n",
      "tested_priors = ['lightbulb','cracker','strawberry','knife']\n",
      "#tested_priors = ['cracker','strawberry','knife']\n",
      "at = 'frequency'\n",
      "for ap in tested_priors:\n",
      "    for n_obj in n_objects:\n",
      "        syllorder, model_data = syllogism_model(n_obj,br,0,0,1,1,domain=ap,priortype=at)\n",
      "        syllorder, model_data = syllogism_model(n_obj,br,1,0,3,1,domain=ap,priortype=at)\n",
      "        #syllorder, model_data = syllogism_model(n_obj,br,1,0,5,1,domain=ap,priortype=at)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sampling and featurizing 7 lightbulbs frequencySame\n",
        "7 = n balls"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "listening, reasoning, speaking... alpha1\n",
        "listening, reasoning, speaking... alpha0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "sampling and featurizing 7 lightbulbs frequencySame"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "listening, reasoning, speaking... alpha3\n",
        "listening, reasoning, speaking... alpha0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "sampling and featurizing 7 crackers frequencySame"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7 = n balls"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "listening, reasoning, speaking... alpha1\n",
        "listening, reasoning, speaking... alpha0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "sampling and featurizing 7 crackers frequencySame"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "listening, reasoning, speaking... alpha3\n",
        "listening, reasoning, speaking... alpha0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "sampling and featurizing 7 strawberrys frequencySame"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7 = n balls"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "listening, reasoning, speaking... alpha1\n",
        "listening, reasoning, speaking... alpha0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "sampling and featurizing 7 strawberrys frequencySame"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "listening, reasoning, speaking... alpha3\n",
        "listening, reasoning, speaking... alpha0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "sampling and featurizing 7 knifes frequencySame"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7 = n balls"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "listening, reasoning, speaking... alpha1\n",
        "listening, reasoning, speaking... alpha0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "sampling and featurizing 7 knifes frequencySame"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "listening, reasoning, speaking... alpha3\n",
        "listening, reasoning, speaking... alpha0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for ap in allpriors:\n",
      "    for at in alltypes:\n",
      "        syllorder, model_data = syllogism_model(n_obj,br,ndepth,mdepth,alphq,alphr,\\\n",
      "                                            domain=ap,\\\n",
      "                                            priortype=at)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "listening, reasoning, speaking... alpha5\n",
        "listening, reasoning, speaking... alpha5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "listening, reasoning, speaking... alpha5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "listening, reasoning, speaking... alpha5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "listening, reasoning, speaking... alpha5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "listening, reasoning, speaking... alpha5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "listening, reasoning, speaking... alpha5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "listening, reasoning, speaking... alpha5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "listening, reasoning, speaking... alpha5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "listening, reasoning, speaking... alpha5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "listening, reasoning, speaking... alpha5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "listening, reasoning, speaking... alpha5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "syllorder, model_data = syllogism_model(6,0.50,0,0,1,1,\\\n",
      "                                    domain='naive',\\\n",
      "                                    priortype='iid')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "listening, reasoning, speaking... alpha1\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_obj"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Syllogism model with {bootstrapped} empirical priors"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "expname = '/prior-exp-mturk_all_n71'\n",
      "priorpath = ('/Users/mht/Documents/research/syllogism/data/03syllogism_prior_psychjs/')\n",
      "priorfile = priorpath + expname +'.csv'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "os.chdir(\"/Users/mht/Documents/research/syllogism/models\")\n",
      "from syll_model import syllogism_model\n",
      "\n",
      "n_obj, br, ndepth, mdepth, alphq, alphr = 6, 0, 0, 0, 1, 1\n",
      "serv, nvc, vc, vcord, exp, fig, lis, EPin = 0, 0, 4,'CA','AIEO', 'Full', 'lis', 1\n",
      "prrs, prrt = 'MC_EE_ec', 'causal'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "allpriors = ['lightbulb','cracker', \\\n",
      "             'strawberry','knife'] \n",
      "alltypes = ['plausibility','frequency']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "# test case\n",
      "syllorder, model_data = syllogism_model(4,br,ndepth,mdepth,alphq,alphr,\\\n",
      "                                    domain='lightbulb',\\\n",
      "                                    priortype='bootstrap')"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for ap in allpriors:\n",
      "    syllorder, model_data = syllogism_model(n_obj,br,ndepth,mdepth,alphq,alphr,\\\n",
      "                                        domain=ap,\\\n",
      "                                        priortype='bootstrap')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sampling and featurizing 6 lightbulbs plausibility\n",
        "6 = n balls"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "listening, reasoning, speaking... alpha1\n",
        "listening, reasoning, speaking... alpha0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "sampling and featurizing 6 lightbulbs frequency"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6 = n balls"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "listening, reasoning, speaking... alpha1\n",
        "listening, reasoning, speaking... alpha0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "sampling and featurizing 6 tomatoplants plausibility"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6 = n balls"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "listening, reasoning, speaking... alpha1\n",
        "listening, reasoning, speaking... alpha0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "sampling and featurizing 6 tomatoplants frequency"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6 = n balls"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "listening, reasoning, speaking... alpha1\n",
        "listening, reasoning, speaking... alpha0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "sampling and featurizing 6 crackers plausibility"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6 = n balls"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "listening, reasoning, speaking... alpha1\n",
        "listening, reasoning, speaking... alpha0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "sampling and featurizing 6 crackers frequency"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6 = n balls"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "listening, reasoning, speaking... alpha1\n",
        "listening, reasoning, speaking... alpha0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "sampling and featurizing 6 strawberrys plausibility"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6 = n balls"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "listening, reasoning, speaking... alpha1\n",
        "listening, reasoning, speaking... alpha0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "listening, reasoning, speaking... alpha1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "sampling and featurizing 6 paintings plausibility"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6 = n balls"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "listening, reasoning, speaking... alpha1\n",
        "listening, reasoning, speaking... alpha0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "sampling and featurizing 6 paintings frequency"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6 = n balls"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "listening, reasoning, speaking... alpha1\n",
        "listening, reasoning, speaking... alpha0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "sampling and featurizing 6 knifes plausibility"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6 = n balls"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "listening, reasoning, speaking... alpha1\n",
        "listening, reasoning, speaking... alpha0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "sampling and featurizing 6 knifes frequency"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6 = n balls"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "listening, reasoning, speaking... alpha1\n",
        "listening, reasoning, speaking... alpha0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prior = 'painting'\n",
      "responses = ['all.C-A','none.C-A','some.C-A','not-all.C-A']\n",
      "bs_fpath = ('modeldata/LATTICE_4_bootstrap/00/csv/lis_N0_M0_bootstrap%s*.csv' % prior)\n",
      "bs_files = glob.glob(bs_fpath)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 96
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv(bs_files[0]) # get dimensions of one set of model predictions\n",
      "bs_data_all = pd.DataFrame(columns=(['sample'] + list(df.columns.values)))\n",
      "for i, bs_file in enumerate(bs_files):\n",
      "    bs_data = pd.read_csv(bs_file)\n",
      "    bs_data.insert(0,'sample',i)\n",
      "    bs_data_all = bs_data_all.append(bs_data,ignore_index=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bs_data_quantiles = pd.DataFrame(columns = (['syll','quantile']+responses))\n",
      "for a in bs_data_all['# syll'].unique():\n",
      "    syllq = bs_data_all[bs_data_all['# syll']==a][responses].quantile([0.025, 0.5, 0.975],axis=0)\n",
      "    syllq.index.name = 'quantile'\n",
      "    syllq.reset_index(inplace=True)\n",
      "    syllq.insert(0,'syll',a)\n",
      "    bs_data_quantiles = bs_data_quantiles.append(syllq,ignore_index=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bs_data_quantiles"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>syll</th>\n",
        "      <th>quantile</th>\n",
        "      <th>all.C-A</th>\n",
        "      <th>none.C-A</th>\n",
        "      <th>some.C-A</th>\n",
        "      <th>not-all.C-A</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0  </th>\n",
        "      <td> AA1</td>\n",
        "      <td> 0.025</td>\n",
        "      <td> 0.500000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.500000</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1  </th>\n",
        "      <td> AA1</td>\n",
        "      <td> 0.500</td>\n",
        "      <td> 0.500000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.500000</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2  </th>\n",
        "      <td> AA1</td>\n",
        "      <td> 0.975</td>\n",
        "      <td> 0.500000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.500000</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3  </th>\n",
        "      <td> AE1</td>\n",
        "      <td> 0.025</td>\n",
        "      <td> 0.121568</td>\n",
        "      <td> 0.079874</td>\n",
        "      <td> 0.397703</td>\n",
        "      <td> 0.336671</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4  </th>\n",
        "      <td> AE1</td>\n",
        "      <td> 0.500</td>\n",
        "      <td> 0.134570</td>\n",
        "      <td> 0.091850</td>\n",
        "      <td> 0.408150</td>\n",
        "      <td> 0.365430</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5  </th>\n",
        "      <td> AE1</td>\n",
        "      <td> 0.975</td>\n",
        "      <td> 0.163329</td>\n",
        "      <td> 0.102297</td>\n",
        "      <td> 0.420126</td>\n",
        "      <td> 0.378432</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6  </th>\n",
        "      <td> AI1</td>\n",
        "      <td> 0.025</td>\n",
        "      <td> 0.173147</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.500000</td>\n",
        "      <td> 0.285447</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7  </th>\n",
        "      <td> AI1</td>\n",
        "      <td> 0.500</td>\n",
        "      <td> 0.183231</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.500000</td>\n",
        "      <td> 0.316769</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8  </th>\n",
        "      <td> AI1</td>\n",
        "      <td> 0.975</td>\n",
        "      <td> 0.214553</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.500000</td>\n",
        "      <td> 0.326853</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9  </th>\n",
        "      <td> AO1</td>\n",
        "      <td> 0.025</td>\n",
        "      <td> 0.136995</td>\n",
        "      <td> 0.030255</td>\n",
        "      <td> 0.458221</td>\n",
        "      <td> 0.321553</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10 </th>\n",
        "      <td> AO1</td>\n",
        "      <td> 0.500</td>\n",
        "      <td> 0.146616</td>\n",
        "      <td> 0.036035</td>\n",
        "      <td> 0.463965</td>\n",
        "      <td> 0.353384</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11 </th>\n",
        "      <td> AO1</td>\n",
        "      <td> 0.975</td>\n",
        "      <td> 0.178447</td>\n",
        "      <td> 0.041779</td>\n",
        "      <td> 0.469745</td>\n",
        "      <td> 0.363005</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12 </th>\n",
        "      <td> EA1</td>\n",
        "      <td> 0.025</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.500000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.500000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13 </th>\n",
        "      <td> EA1</td>\n",
        "      <td> 0.500</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.500000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.500000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14 </th>\n",
        "      <td> EA1</td>\n",
        "      <td> 0.975</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.500000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.500000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>15 </th>\n",
        "      <td> EE1</td>\n",
        "      <td> 0.025</td>\n",
        "      <td> 0.149725</td>\n",
        "      <td> 0.046247</td>\n",
        "      <td> 0.430496</td>\n",
        "      <td> 0.313570</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16 </th>\n",
        "      <td> EE1</td>\n",
        "      <td> 0.500</td>\n",
        "      <td> 0.159570</td>\n",
        "      <td> 0.056117</td>\n",
        "      <td> 0.443883</td>\n",
        "      <td> 0.340430</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17 </th>\n",
        "      <td> EE1</td>\n",
        "      <td> 0.975</td>\n",
        "      <td> 0.186430</td>\n",
        "      <td> 0.069504</td>\n",
        "      <td> 0.453753</td>\n",
        "      <td> 0.350275</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>18 </th>\n",
        "      <td> EI1</td>\n",
        "      <td> 0.025</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.074594</td>\n",
        "      <td> 0.398608</td>\n",
        "      <td> 0.500000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19 </th>\n",
        "      <td> EI1</td>\n",
        "      <td> 0.500</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.086035</td>\n",
        "      <td> 0.413965</td>\n",
        "      <td> 0.500000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>20 </th>\n",
        "      <td> EI1</td>\n",
        "      <td> 0.975</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.101392</td>\n",
        "      <td> 0.425406</td>\n",
        "      <td> 0.500000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>21 </th>\n",
        "      <td> EO1</td>\n",
        "      <td> 0.025</td>\n",
        "      <td> 0.094386</td>\n",
        "      <td> 0.046724</td>\n",
        "      <td> 0.431118</td>\n",
        "      <td> 0.381184</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>22 </th>\n",
        "      <td> EO1</td>\n",
        "      <td> 0.500</td>\n",
        "      <td> 0.098697</td>\n",
        "      <td> 0.057500</td>\n",
        "      <td> 0.442500</td>\n",
        "      <td> 0.401303</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>23 </th>\n",
        "      <td> EO1</td>\n",
        "      <td> 0.975</td>\n",
        "      <td> 0.118816</td>\n",
        "      <td> 0.068882</td>\n",
        "      <td> 0.453276</td>\n",
        "      <td> 0.405614</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>24 </th>\n",
        "      <td> IA1</td>\n",
        "      <td> 0.025</td>\n",
        "      <td> 0.239357</td>\n",
        "      <td> 0.088204</td>\n",
        "      <td> 0.384583</td>\n",
        "      <td> 0.227334</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25 </th>\n",
        "      <td> IA1</td>\n",
        "      <td> 0.500</td>\n",
        "      <td> 0.258657</td>\n",
        "      <td> 0.096996</td>\n",
        "      <td> 0.403004</td>\n",
        "      <td> 0.241343</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>26 </th>\n",
        "      <td> IA1</td>\n",
        "      <td> 0.975</td>\n",
        "      <td> 0.272666</td>\n",
        "      <td> 0.115417</td>\n",
        "      <td> 0.411796</td>\n",
        "      <td> 0.260643</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>27 </th>\n",
        "      <td> IE1</td>\n",
        "      <td> 0.025</td>\n",
        "      <td> 0.163440</td>\n",
        "      <td> 0.106789</td>\n",
        "      <td> 0.364765</td>\n",
        "      <td> 0.301692</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>28 </th>\n",
        "      <td> IE1</td>\n",
        "      <td> 0.500</td>\n",
        "      <td> 0.169951</td>\n",
        "      <td> 0.128206</td>\n",
        "      <td> 0.371794</td>\n",
        "      <td> 0.330049</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>29 </th>\n",
        "      <td> IE1</td>\n",
        "      <td> 0.975</td>\n",
        "      <td> 0.198308</td>\n",
        "      <td> 0.135235</td>\n",
        "      <td> 0.393211</td>\n",
        "      <td> 0.336560</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>...</th>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>162</th>\n",
        "      <td> EI4</td>\n",
        "      <td> 0.025</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.074594</td>\n",
        "      <td> 0.398608</td>\n",
        "      <td> 0.500000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>163</th>\n",
        "      <td> EI4</td>\n",
        "      <td> 0.500</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.086035</td>\n",
        "      <td> 0.413965</td>\n",
        "      <td> 0.500000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>164</th>\n",
        "      <td> EI4</td>\n",
        "      <td> 0.975</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.101392</td>\n",
        "      <td> 0.425406</td>\n",
        "      <td> 0.500000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>165</th>\n",
        "      <td> EO4</td>\n",
        "      <td> 0.025</td>\n",
        "      <td> 0.099808</td>\n",
        "      <td> 0.058171</td>\n",
        "      <td> 0.415161</td>\n",
        "      <td> 0.372897</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>166</th>\n",
        "      <td> EO4</td>\n",
        "      <td> 0.500</td>\n",
        "      <td> 0.104897</td>\n",
        "      <td> 0.068293</td>\n",
        "      <td> 0.431707</td>\n",
        "      <td> 0.395103</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>167</th>\n",
        "      <td> EO4</td>\n",
        "      <td> 0.975</td>\n",
        "      <td> 0.127103</td>\n",
        "      <td> 0.084839</td>\n",
        "      <td> 0.441829</td>\n",
        "      <td> 0.400192</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>168</th>\n",
        "      <td> IA4</td>\n",
        "      <td> 0.025</td>\n",
        "      <td> 0.078842</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.500000</td>\n",
        "      <td> 0.392757</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>169</th>\n",
        "      <td> IA4</td>\n",
        "      <td> 0.500</td>\n",
        "      <td> 0.085106</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.500000</td>\n",
        "      <td> 0.414894</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>170</th>\n",
        "      <td> IA4</td>\n",
        "      <td> 0.975</td>\n",
        "      <td> 0.107243</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.500000</td>\n",
        "      <td> 0.421158</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>171</th>\n",
        "      <td> IE4</td>\n",
        "      <td> 0.025</td>\n",
        "      <td> 0.163440</td>\n",
        "      <td> 0.106789</td>\n",
        "      <td> 0.364765</td>\n",
        "      <td> 0.301692</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>172</th>\n",
        "      <td> IE4</td>\n",
        "      <td> 0.500</td>\n",
        "      <td> 0.169951</td>\n",
        "      <td> 0.128206</td>\n",
        "      <td> 0.371794</td>\n",
        "      <td> 0.330049</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>173</th>\n",
        "      <td> IE4</td>\n",
        "      <td> 0.975</td>\n",
        "      <td> 0.198308</td>\n",
        "      <td> 0.135235</td>\n",
        "      <td> 0.393211</td>\n",
        "      <td> 0.336560</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>174</th>\n",
        "      <td> II4</td>\n",
        "      <td> 0.025</td>\n",
        "      <td> 0.136383</td>\n",
        "      <td> 0.034259</td>\n",
        "      <td> 0.452016</td>\n",
        "      <td> 0.338827</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>175</th>\n",
        "      <td> II4</td>\n",
        "      <td> 0.500</td>\n",
        "      <td> 0.139093</td>\n",
        "      <td> 0.041252</td>\n",
        "      <td> 0.458748</td>\n",
        "      <td> 0.360907</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>176</th>\n",
        "      <td> II4</td>\n",
        "      <td> 0.975</td>\n",
        "      <td> 0.161173</td>\n",
        "      <td> 0.047984</td>\n",
        "      <td> 0.465741</td>\n",
        "      <td> 0.363617</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>177</th>\n",
        "      <td> IO4</td>\n",
        "      <td> 0.025</td>\n",
        "      <td> 0.149594</td>\n",
        "      <td> 0.059317</td>\n",
        "      <td> 0.423045</td>\n",
        "      <td> 0.323762</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>178</th>\n",
        "      <td> IO4</td>\n",
        "      <td> 0.500</td>\n",
        "      <td> 0.151867</td>\n",
        "      <td> 0.070959</td>\n",
        "      <td> 0.429041</td>\n",
        "      <td> 0.348133</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>179</th>\n",
        "      <td> IO4</td>\n",
        "      <td> 0.975</td>\n",
        "      <td> 0.176238</td>\n",
        "      <td> 0.076955</td>\n",
        "      <td> 0.440683</td>\n",
        "      <td> 0.350406</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>180</th>\n",
        "      <td> OA4</td>\n",
        "      <td> 0.025</td>\n",
        "      <td> 0.065133</td>\n",
        "      <td> 0.010442</td>\n",
        "      <td> 0.481655</td>\n",
        "      <td> 0.409687</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>181</th>\n",
        "      <td> OA4</td>\n",
        "      <td> 0.500</td>\n",
        "      <td> 0.069442</td>\n",
        "      <td> 0.014939</td>\n",
        "      <td> 0.485061</td>\n",
        "      <td> 0.430558</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>182</th>\n",
        "      <td> OA4</td>\n",
        "      <td> 0.975</td>\n",
        "      <td> 0.090313</td>\n",
        "      <td> 0.018345</td>\n",
        "      <td> 0.489558</td>\n",
        "      <td> 0.434867</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>183</th>\n",
        "      <td> OE4</td>\n",
        "      <td> 0.025</td>\n",
        "      <td> 0.179092</td>\n",
        "      <td> 0.048839</td>\n",
        "      <td> 0.430372</td>\n",
        "      <td> 0.285477</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>184</th>\n",
        "      <td> OE4</td>\n",
        "      <td> 0.500</td>\n",
        "      <td> 0.188794</td>\n",
        "      <td> 0.057021</td>\n",
        "      <td> 0.442979</td>\n",
        "      <td> 0.311206</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>185</th>\n",
        "      <td> OE4</td>\n",
        "      <td> 0.975</td>\n",
        "      <td> 0.214523</td>\n",
        "      <td> 0.069628</td>\n",
        "      <td> 0.451161</td>\n",
        "      <td> 0.320908</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>186</th>\n",
        "      <td> OI4</td>\n",
        "      <td> 0.025</td>\n",
        "      <td> 0.130167</td>\n",
        "      <td> 0.023125</td>\n",
        "      <td> 0.463516</td>\n",
        "      <td> 0.343270</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>187</th>\n",
        "      <td> OI4</td>\n",
        "      <td> 0.500</td>\n",
        "      <td> 0.134200</td>\n",
        "      <td> 0.030200</td>\n",
        "      <td> 0.469800</td>\n",
        "      <td> 0.365800</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>188</th>\n",
        "      <td> OI4</td>\n",
        "      <td> 0.975</td>\n",
        "      <td> 0.156730</td>\n",
        "      <td> 0.036484</td>\n",
        "      <td> 0.476875</td>\n",
        "      <td> 0.369833</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>189</th>\n",
        "      <td> OO4</td>\n",
        "      <td> 0.025</td>\n",
        "      <td> 0.157222</td>\n",
        "      <td> 0.034688</td>\n",
        "      <td> 0.449028</td>\n",
        "      <td> 0.314390</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>190</th>\n",
        "      <td> OO4</td>\n",
        "      <td> 0.500</td>\n",
        "      <td> 0.159986</td>\n",
        "      <td> 0.041553</td>\n",
        "      <td> 0.458447</td>\n",
        "      <td> 0.340014</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>191</th>\n",
        "      <td> OO4</td>\n",
        "      <td> 0.975</td>\n",
        "      <td> 0.185610</td>\n",
        "      <td> 0.050972</td>\n",
        "      <td> 0.465312</td>\n",
        "      <td> 0.342778</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>192 rows \u00d7 6 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 99,
       "text": [
        "    syll  quantile   all.C-A  none.C-A  some.C-A  not-all.C-A\n",
        "0    AA1     0.025  0.500000  0.000000  0.500000     0.000000\n",
        "1    AA1     0.500  0.500000  0.000000  0.500000     0.000000\n",
        "2    AA1     0.975  0.500000  0.000000  0.500000     0.000000\n",
        "3    AE1     0.025  0.121568  0.079874  0.397703     0.336671\n",
        "4    AE1     0.500  0.134570  0.091850  0.408150     0.365430\n",
        "5    AE1     0.975  0.163329  0.102297  0.420126     0.378432\n",
        "6    AI1     0.025  0.173147  0.000000  0.500000     0.285447\n",
        "7    AI1     0.500  0.183231  0.000000  0.500000     0.316769\n",
        "8    AI1     0.975  0.214553  0.000000  0.500000     0.326853\n",
        "9    AO1     0.025  0.136995  0.030255  0.458221     0.321553\n",
        "10   AO1     0.500  0.146616  0.036035  0.463965     0.353384\n",
        "11   AO1     0.975  0.178447  0.041779  0.469745     0.363005\n",
        "12   EA1     0.025  0.000000  0.500000  0.000000     0.500000\n",
        "13   EA1     0.500  0.000000  0.500000  0.000000     0.500000\n",
        "14   EA1     0.975  0.000000  0.500000  0.000000     0.500000\n",
        "15   EE1     0.025  0.149725  0.046247  0.430496     0.313570\n",
        "16   EE1     0.500  0.159570  0.056117  0.443883     0.340430\n",
        "17   EE1     0.975  0.186430  0.069504  0.453753     0.350275\n",
        "18   EI1     0.025  0.000000  0.074594  0.398608     0.500000\n",
        "19   EI1     0.500  0.000000  0.086035  0.413965     0.500000\n",
        "20   EI1     0.975  0.000000  0.101392  0.425406     0.500000\n",
        "21   EO1     0.025  0.094386  0.046724  0.431118     0.381184\n",
        "22   EO1     0.500  0.098697  0.057500  0.442500     0.401303\n",
        "23   EO1     0.975  0.118816  0.068882  0.453276     0.405614\n",
        "24   IA1     0.025  0.239357  0.088204  0.384583     0.227334\n",
        "25   IA1     0.500  0.258657  0.096996  0.403004     0.241343\n",
        "26   IA1     0.975  0.272666  0.115417  0.411796     0.260643\n",
        "27   IE1     0.025  0.163440  0.106789  0.364765     0.301692\n",
        "28   IE1     0.500  0.169951  0.128206  0.371794     0.330049\n",
        "29   IE1     0.975  0.198308  0.135235  0.393211     0.336560\n",
        "..   ...       ...       ...       ...       ...          ...\n",
        "162  EI4     0.025  0.000000  0.074594  0.398608     0.500000\n",
        "163  EI4     0.500  0.000000  0.086035  0.413965     0.500000\n",
        "164  EI4     0.975  0.000000  0.101392  0.425406     0.500000\n",
        "165  EO4     0.025  0.099808  0.058171  0.415161     0.372897\n",
        "166  EO4     0.500  0.104897  0.068293  0.431707     0.395103\n",
        "167  EO4     0.975  0.127103  0.084839  0.441829     0.400192\n",
        "168  IA4     0.025  0.078842  0.000000  0.500000     0.392757\n",
        "169  IA4     0.500  0.085106  0.000000  0.500000     0.414894\n",
        "170  IA4     0.975  0.107243  0.000000  0.500000     0.421158\n",
        "171  IE4     0.025  0.163440  0.106789  0.364765     0.301692\n",
        "172  IE4     0.500  0.169951  0.128206  0.371794     0.330049\n",
        "173  IE4     0.975  0.198308  0.135235  0.393211     0.336560\n",
        "174  II4     0.025  0.136383  0.034259  0.452016     0.338827\n",
        "175  II4     0.500  0.139093  0.041252  0.458748     0.360907\n",
        "176  II4     0.975  0.161173  0.047984  0.465741     0.363617\n",
        "177  IO4     0.025  0.149594  0.059317  0.423045     0.323762\n",
        "178  IO4     0.500  0.151867  0.070959  0.429041     0.348133\n",
        "179  IO4     0.975  0.176238  0.076955  0.440683     0.350406\n",
        "180  OA4     0.025  0.065133  0.010442  0.481655     0.409687\n",
        "181  OA4     0.500  0.069442  0.014939  0.485061     0.430558\n",
        "182  OA4     0.975  0.090313  0.018345  0.489558     0.434867\n",
        "183  OE4     0.025  0.179092  0.048839  0.430372     0.285477\n",
        "184  OE4     0.500  0.188794  0.057021  0.442979     0.311206\n",
        "185  OE4     0.975  0.214523  0.069628  0.451161     0.320908\n",
        "186  OI4     0.025  0.130167  0.023125  0.463516     0.343270\n",
        "187  OI4     0.500  0.134200  0.030200  0.469800     0.365800\n",
        "188  OI4     0.975  0.156730  0.036484  0.476875     0.369833\n",
        "189  OO4     0.025  0.157222  0.034688  0.449028     0.314390\n",
        "190  OO4     0.500  0.159986  0.041553  0.458447     0.340014\n",
        "191  OO4     0.975  0.185610  0.050972  0.465312     0.342778\n",
        "\n",
        "[192 rows x 6 columns]"
       ]
      }
     ],
     "prompt_number": 99
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## OED"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "sys.path.append('/Users/mht/Documents/research/oed_py/oed/')\n",
      "\n",
      "import oed\n",
      "import pmf\n",
      "import church\n",
      "\n",
      "import copy\n",
      "import csv\n",
      "\n",
      "import itertools \n",
      "\n",
      "fpath = '/Users/mht/Documents/research/syllogism/models/modeldata/'\n",
      "domains = ['lightbulb','tomatoplant','cracker','strawberry','painting','knife'] \n",
      "priors = ['plausibility','frequency']\n",
      "prior = priors[0]\n",
      "printout = False\n",
      "n_obj = 6\n",
      "fig = 'Full'\n",
      "best_fit_br = '0.50'\n",
      "ndepth = '0'\n",
      "alphq = '1'\n",
      "outfile = 'oed_'+prior+'_depth' + ndepth+'_alpha'+alphq+'iidArgStr_emprArgStr_emprCLonly'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f0 = fpath+('LATTICE_4_%s/00/csv/lis_N0_M0_%s%s_qud1fig%s_AIEOc4CAEP1_n%d_base0.00_s100k_alphQ1_alphR1.csv'\\\n",
      "          % (prior,prior,domains[0],fig, n_obj))\n",
      "df = pd.read_csv(f0)\n",
      "experiments = df[\"# syll\"]\n",
      "responses = df.columns.values[5:9]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# define church programs\n",
      "# -- models is a PMF of the belief distribution for all the mdoels\n",
      "# -- the first arguments are the filename of each church program\n",
      "# -- the second arguments are the prior belief distribution of each church program (which is uniform in this example)\n",
      "\n",
      "mnames = ['argstr_iid','argstr_empr','clonly_empr']\n",
      "\n",
      "models = pmf.PMF(3)\n",
      "models[0] = pmf.P(mnames[0]+\".church\", 1.0)\n",
      "models[1] = pmf.P(mnames[1]+\".church\", 1.0)\n",
      "models[2] = pmf.P(mnames[2]+\".church\", 1.0)\n",
      "models.normalize()\n",
      "\n",
      "alldata = np.zeros((len(models),\n",
      "                    len(experiments),\n",
      "                    len(responses)*len(domains))) # domains (empirical) vs naive\n",
      "\n",
      "alldata.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "(3, 64, 24)"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load data into alldata\n",
      "# alldata[0] will be for model 1 ('empirical priors')\n",
      "# alldata[1] will be for model 2 ('naive [best fit, iid] priors')\n",
      "\n",
      "for m, mod in enumerate(mnames):\n",
      "    \n",
      "    for d, dom in enumerate(domains):\n",
      "\n",
      "        if dom is 'naive': \n",
      "           # dom = ''\n",
      "            br = best_fit_br\n",
      "            nsamp = 100\n",
      "        else: \n",
      "            #dom = '_'+dom\n",
      "            br = '0.00'\n",
      "            nsamp = 100\n",
      "\n",
      "        if mod[0:6]=='clonly': \n",
      "            f1 = fpath + ('LATTICE_4_%s/%s0/csv/lis_N%s_M0_CLonly_%s%s_qud1fig%s_AIEOc4CAEP1_n%d_base%s_s%dk.csv'\\\n",
      "                          % (prior,ndepth,ndepth,prior,dom,\\\n",
      "                             fig,n_obj,br,nsamp))\n",
      "        elif mod[-3::]=='iid':\n",
      "            f1 = fpath+('LATTICE_4/00/csv/lis_N0_M0_iidnaive_qud1figFull_AIEOc4CAEP1_n6_base0.50_s100k_alphQ1_alphR1.csv')\n",
      "        else: \n",
      "            f1 = fpath+('LATTICE_4_%s/%s0/csv/lis_N%s_M0_%s%s_qud1fig%s_AIEOc4CAEP1_n%d_base%s_s%dk_alphQ%s_alphR1.csv'\\\n",
      "          % (prior,ndepth,ndepth,prior,dom,fig,n_obj,br,nsamp,alphq))\n",
      "\n",
      "        alldata[m,:,d*4:d*4+4] = pd.read_csv(f1,usecols=responses)\n",
      "\n",
      "# define space of possible outputs\n",
      "# -- output_pmf is a PMF to store the resulting distributions from the church programs\n",
      "# -- the first arguments are the possible output values\n",
      "# -- the second arguments will be overwritten and do not matter\n",
      "output_pmf = pmf.PMF(len(responses)*len(domains))\n",
      "for i, x in enumerate(itertools.product(domains,responses)):\n",
      "    outlabel = x[0]+'_'+x[1]\n",
      "    output_pmf[i] = pmf.P(outlabel, 1.0)\n",
      "\n",
      "output_pmf.normalize() "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/Users/mht/Documents/research/syllogism/models/modeldata/LATTICE_4/00/csv/lis_N0_M0_iidnaive_qud1figFull_AIEOc4CAEP1_n6_base0.50_s100k_alphQ1_alphR1.csv\n",
        "/Users/mht/Documents/research/syllogism/models/modeldata/LATTICE_4/00/csv/lis_N0_M0_iidnaive_qud1figFull_AIEOc4CAEP1_n6_base0.50_s100k_alphQ1_alphR1.csv\n",
        "/Users/mht/Documents/research/syllogism/models/modeldata/LATTICE_4/00/csv/lis_N0_M0_iidnaive_qud1figFull_AIEOc4CAEP1_n6_base0.50_s100k_alphQ1_alphR1.csv\n",
        "/Users/mht/Documents/research/syllogism/models/modeldata/LATTICE_4/00/csv/lis_N0_M0_iidnaive_qud1figFull_AIEOc4CAEP1_n6_base0.50_s100k_alphQ1_alphR1.csv\n",
        "/Users/mht/Documents/research/syllogism/models/modeldata/LATTICE_4/00/csv/lis_N0_M0_iidnaive_qud1figFull_AIEOc4CAEP1_n6_base0.50_s100k_alphQ1_alphR1.csv\n",
        "/Users/mht/Documents/research/syllogism/models/modeldata/LATTICE_4/00/csv/lis_N0_M0_iidnaive_qud1figFull_AIEOc4CAEP1_n6_base0.50_s100k_alphQ1_alphR1.csv\n",
        "/Users/mht/Documents/research/syllogism/models/modeldata/LATTICE_4_plausibility/00/csv/lis_N0_M0_plausibilitylightbulb_qud1figFull_AIEOc4CAEP1_n6_base0.00_s100k_alphQ1_alphR1.csv\n",
        "/Users/mht/Documents/research/syllogism/models/modeldata/LATTICE_4_plausibility/00/csv/lis_N0_M0_plausibilitytomatoplant_qud1figFull_AIEOc4CAEP1_n6_base0.00_s100k_alphQ1_alphR1.csv\n",
        "/Users/mht/Documents/research/syllogism/models/modeldata/LATTICE_4_plausibility/00/csv/lis_N0_M0_plausibilitycracker_qud1figFull_AIEOc4CAEP1_n6_base0.00_s100k_alphQ1_alphR1.csv\n",
        "/Users/mht/Documents/research/syllogism/models/modeldata/LATTICE_4_plausibility/00/csv/lis_N0_M0_plausibilitystrawberry_qud1figFull_AIEOc4CAEP1_n6_base0.00_s100k_alphQ1_alphR1.csv\n",
        "/Users/mht/Documents/research/syllogism/models/modeldata/LATTICE_4_plausibility/00/csv/lis_N0_M0_plausibilitypainting_qud1figFull_AIEOc4CAEP1_n6_base0.00_s100k_alphQ1_alphR1.csv\n",
        "/Users/mht/Documents/research/syllogism/models/modeldata/LATTICE_4_plausibility/00/csv/lis_N0_M0_plausibilityknife_qud1figFull_AIEOc4CAEP1_n6_base0.00_s100k_alphQ1_alphR1.csv\n",
        "/Users/mht/Documents/research/syllogism/models/modeldata/LATTICE_4_plausibility/00/csv/lis_N0_M0_CLonly_plausibilitylightbulb_qud1figFull_AIEOc4CAEP1_n6_base0.00_s100k.csv\n",
        "/Users/mht/Documents/research/syllogism/models/modeldata/LATTICE_4_plausibility/00/csv/lis_N0_M0_CLonly_plausibilitytomatoplant_qud1figFull_AIEOc4CAEP1_n6_base0.00_s100k.csv\n",
        "/Users/mht/Documents/research/syllogism/models/modeldata/LATTICE_4_plausibility/00/csv/lis_N0_M0_CLonly_plausibilitycracker_qud1figFull_AIEOc4CAEP1_n6_base0.00_s100k.csv\n",
        "/Users/mht/Documents/research/syllogism/models/modeldata/LATTICE_4_plausibility/00/csv/lis_N0_M0_CLonly_plausibilitystrawberry_qud1figFull_AIEOc4CAEP1_n6_base0.00_s100k.csv\n",
        "/Users/mht/Documents/research/syllogism/models/modeldata/LATTICE_4_plausibility/00/csv/lis_N0_M0_CLonly_plausibilitypainting_qud1figFull_AIEOc4CAEP1_n6_base0.00_s100k.csv\n",
        "/Users/mht/Documents/research/syllogism/models/modeldata/LATTICE_4_plausibility/00/csv/lis_N0_M0_CLonly_plausibilityknife_qud1figFull_AIEOc4CAEP1_n6_base0.00_s100k.csv\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print mnames[0],mnames[1],np.corrcoef(np.ravel(alldata[0]),np.ravel(alldata[1]))[1,0]\n",
      "print mnames[0],mnames[2],np.corrcoef(np.ravel(alldata[0]),np.ravel(alldata[2]))[1,0]\n",
      "print mnames[1],mnames[2],np.corrcoef(np.ravel(alldata[1]),np.ravel(alldata[2]))[1,0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "argstr_iid argstr_empr 0.869198690764\n",
        "argstr_iid clonly_empr 0.670270948883\n",
        "argstr_empr clonly_empr 0.789130783446\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# generate an array of output_pmfs for each church program\n",
      "outputs = [0]*len(models)\n",
      "for m in range(len(models)) :\n",
      "    outputs[m] = copy.deepcopy(output_pmf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "expected_kl = np.zeros((len(experiments)))\n",
      "# iterate over all possible inputs / syllogisms\n",
      "f = open(fpath+outfile+'.txt', 'w')\n",
      "\n",
      "for j,i in enumerate(experiments):\n",
      "\n",
      "    for m in range(len(models)) :\n",
      "        \n",
      "        for k, rsp in enumerate(itertools.product(domains,responses)):\n",
      "            outlabel = rsp[0]+'_'+rsp[1]\n",
      "            outputs[m].pmf[k] = pmf.P(outlabel,alldata[m,j,k])\n",
      "\n",
      "    # using the computed output distribution, compute and print the expected KL-divergence for each input\n",
      "    expected_kl[j] = oed.get_expected_kl(models, outputs)\n",
      "    f.write(i + ' ' + str(expected_kl[j]) + ' ' + str(outputs) + '\\n\\n')\n",
      "    \n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ekl = np.array([(experiments[i],kl) for i, kl in enumerate(expected_kl)])\n",
      "#    print experiments[i] + '   ' + str(kl)\n",
      "#print ekl\n",
      "ek_sort = ekl[np.argsort(ekl[:,1])]\n",
      "if printout: \n",
      "    f = open('/Users/mht/Documents/research/syllogism/data/03syllogism_prior_psychjs/'+outfile+'_sorted.txt', 'w')\n",
      "    \n",
      "    for k in ek_sort[::-1]:\n",
      "        f.write(k[0] + ' ' + k[1] +'\\n')\n",
      "\n",
      "    f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "allresp = [a[0]+'.'+a[1] for a in itertools.product(domains,responses)]\n",
      "# organize data into one data frame, wide format\n",
      "model_df = pd.DataFrame(columns=(['# syll','model'] + allresp))\n",
      "for a in range(len(alldata)):\n",
      "    d0 = pd.DataFrame(alldata[a],columns = allresp)\n",
      "    m_cat = pd.concat([experiments, d0],axis=1,ignore_index=False)\n",
      "    m_cat.insert(1,'model',mnames[a])\n",
      "    model_df = pd.concat([model_df,m_cat],axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_df.to_csv('/Users/mht/Documents/research/syllogism/data/03syllogism_prior_psychjs/3modeldata_'+outfile+'.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Pragmatics OED"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "sys.path.append('/Users/mht/Documents/research/oed_py/oed/')\n",
      "\n",
      "import oed\n",
      "import pmf\n",
      "import church\n",
      "\n",
      "import copy\n",
      "import csv\n",
      "\n",
      "import itertools \n",
      "\n",
      "fpath = '/Users/mht/Documents/research/syllogism/models/modeldata/'\n",
      "#domains = ['lightbulb','tomatoplant','cracker','strawberry','painting','knife'] \n",
      "priors = ['plausibility','frequency']\n",
      "n_objects = [7]\n",
      "alphas = [3]\n",
      "domains = ['lightbulb','cracker','strawberry','knife']\n",
      "prior = priors[1]\n",
      "printout = True\n",
      "n_obj = n_objects[0]\n",
      "fig = 'Full'\n",
      "best_fit_br = '0.50'\n",
      "ndepth = '1'\n",
      "alphq = str(alphas[0])\n",
      "outfile = 'oed_'+prior+'_nobj' + str(n_obj) +'_alpha'+alphq+'emprLit_emprPrag'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f0 = fpath+('LATTICE_4_%s/10/csv/lis_N1_M0_%s%s_qud1fig%s_AIEOc4CAEP1_n%d_base0.00_s100k_alphQ3_alphR1_bsmean.csv'\\\n",
      "          % (prior,prior,domains[0],fig, n_obj))\n",
      "df = pd.read_csv(f0)\n",
      "experiments = df[\"# syll\"]\n",
      "responses = df.columns.values[5:9]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# define church programs\n",
      "# -- models is a PMF of the belief distribution for all the mdoels\n",
      "# -- the first arguments are the filename of each church program\n",
      "# -- the second arguments are the prior belief distribution of each church program (which is uniform in this example)\n",
      "\n",
      "mnames = ['argstr_empr','prgmtc_empr']\n",
      "\n",
      "models = pmf.PMF(2)\n",
      "models[0] = pmf.P(mnames[0]+\".church\", 1.0)\n",
      "models[1] = pmf.P(mnames[1]+\".church\", 1.0)\n",
      "models.normalize()\n",
      "\n",
      "alldata = np.zeros((len(models),\n",
      "                    len(experiments),\n",
      "                    len(responses)*len(domains))) # domains (empirical) vs naive\n",
      "\n",
      "# load data into alldata\n",
      "# alldata[0] will be for model 1 ('empirical priors')\n",
      "# alldata[1] will be for model 2 ('naive [best fit, iid] priors')\n",
      "\n",
      "for m, mod in enumerate(mnames):\n",
      "    \n",
      "    for d, dom in enumerate(domains):\n",
      "\n",
      "        if dom is 'naive': \n",
      "           # dom = ''\n",
      "            br = best_fit_br\n",
      "            nsamp = 100\n",
      "        else: \n",
      "            #dom = '_'+dom\n",
      "            br = '0.00'\n",
      "            nsamp = 100\n",
      "\n",
      "        if mod[0:6]=='argstr': \n",
      "            f1 = fpath+('LATTICE_4_%s/%s0/csv/lis_N%s_M0_%s%s_qud1fig%s_AIEOc4CAEP1_n%d_base%s_s%dk_alphQ%s_alphR1_bsmean.csv'\\\n",
      "          % (prior,'0','0',prior,dom,fig,n_obj,br,nsamp,'1'))\n",
      "        elif mod[0:6]=='prgmtc':\n",
      "            f1 = fpath+('LATTICE_4_%s/%s0/csv/lis_N%s_M0_%s%s_qud1fig%s_AIEOc4CAEP1_n%d_base%s_s%dk_alphQ%s_alphR1_bsmean.csv'\\\n",
      "          % (prior,ndepth,ndepth,prior,dom,fig,n_obj,br,nsamp,alphq))\n",
      "        else: \n",
      "            f1 = ''\n",
      "\n",
      "        alldata[m,:,d*4:d*4+4] = pd.read_csv(f1,usecols=responses)\n",
      "\n",
      "# define space of possible outputs\n",
      "# -- output_pmf is a PMF to store the resulting distributions from the church programs\n",
      "# -- the first arguments are the possible output values\n",
      "# -- the second arguments will be overwritten and do not matter\n",
      "output_pmf = pmf.PMF(len(responses)*len(domains))\n",
      "for i, x in enumerate(itertools.product(domains,responses)):\n",
      "    outlabel = x[0]+'_'+x[1]\n",
      "    output_pmf[i] = pmf.P(outlabel, 1.0)\n",
      "\n",
      "output_pmf.normalize() "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print mnames[0],mnames[1],np.corrcoef(np.ravel(alldata[0]),np.ravel(alldata[1]))[1,0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "argstr_empr prgmtc_empr 0.91487073962\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# generate an array of output_pmfs for each church program\n",
      "outputs = [0]*len(models)\n",
      "for m in range(len(models)) :\n",
      "    outputs[m] = copy.deepcopy(output_pmf)\n",
      "    \n",
      "expected_kl = np.zeros((len(experiments)))\n",
      "# iterate over all possible inputs / syllogisms\n",
      "f = open(fpath+outfile+'.txt', 'w')\n",
      "\n",
      "for j,i in enumerate(experiments):\n",
      "\n",
      "    for m in range(len(models)) :\n",
      "        \n",
      "        for k, rsp in enumerate(itertools.product(domains,responses)):\n",
      "            outlabel = rsp[0]+'_'+rsp[1]\n",
      "            outputs[m].pmf[k] = pmf.P(outlabel,alldata[m,j,k])\n",
      "\n",
      "    # using the computed output distribution, compute and print the expected KL-divergence for each input\n",
      "    expected_kl[j] = oed.get_expected_kl(models, outputs)\n",
      "    f.write(i + ' ' + str(expected_kl[j]) + ' ' + str(outputs) + '\\n\\n')\n",
      "    \n",
      "f.close()\n",
      "\n",
      "ekl = np.array([(experiments[i],kl) for i, kl in enumerate(expected_kl)])\n",
      "#    print experiments[i] + '   ' + str(kl)\n",
      "#print ekl\n",
      "ek_sort = ekl[np.argsort(ekl[:,1])]\n",
      "if printout: \n",
      "    f = open('/Users/mht/Documents/research/syllogism/data/03syllogism_prior_psychjs/'+outfile+'_sorted.txt', 'w')\n",
      "    \n",
      "    for k in ek_sort[::-1]:\n",
      "        f.write(k[0] + ' ' + k[1] +'\\n')\n",
      "\n",
      "    f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "allresp = [a[0]+'.'+a[1] for a in itertools.product(domains,responses)]\n",
      "# organize data into one data frame, wide format\n",
      "model_df = pd.DataFrame(columns=(['# syll','model'] + allresp))\n",
      "for a in range(len(alldata)):\n",
      "    d0 = pd.DataFrame(alldata[a],columns = allresp)\n",
      "    m_cat = pd.concat([experiments, d0],axis=1,ignore_index=False)\n",
      "    m_cat.insert(1,'model',mnames[a])\n",
      "    model_df = pd.concat([model_df,m_cat],axis=0)\n",
      "    \n",
      "    \n",
      "model_df.to_csv('/Users/mht/Documents/research/syllogism/data/03syllogism_prior_psychjs/prgmtcOED_'+outfile+'.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}