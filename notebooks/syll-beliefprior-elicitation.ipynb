{
 "metadata": {
  "name": "",
  "signature": "sha256:0a8fdbdafe595121a7e784f6df09f9d84c236cfc890ac33ff440922761f41da3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 03 syll-prior elicitation\n",
      "\n",
      "#### Experiment to elicit priors for 6 causal domains. This notebook takes the mturk data and writes the relevant data to a csv. It writes a second file with just the means. Further down, it looks at the priors in more detail; primarily, to see if the priors could have been generated from 3 independent coin flips (something like \"unstructured knowledge\")."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from scipy.optimize import minimize\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline \n",
      "import ast\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "expname = '03syllogism_prior_psychjs'\n",
      "priorpath = ('/Users/mht/Documents/research/syllogism/experiments/%s' % (expname))\n",
      "datapath = ('/Users/mht/Documents/research/syllogism/data/%s' % (expname))\n",
      "priorfile = priorpath + '/prior-exp-mturk.tsv'\n",
      "priors = pd.read_csv(priorfile,sep='\\t')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = priors[\"Answer.2\"] # data for elicitation trials\n",
      "b = [ast.literal_eval(x) for x in a] #literalize the mturk data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_priors = pd.DataFrame() # start new data frame for all subjects data\n",
      "for i, subj_info in enumerate(b): # loop through subjects\n",
      "    temp = pd.DataFrame.from_dict(subj_info) # turn subj data into df\n",
      "    temp.insert(0,\"subj\",\"s\"+str(i)) # insert subject identifier\n",
      "    all_priors = pd.concat([all_priors,temp],ignore_index=True) # add subj df to all_subj df\n",
      "# convert \"trial_domain\" (obj) into \"domain\" (string)\n",
      "all_priors[\"domain\"] = pd.Series([item for sublist in all_priors.trial_domain for item in sublist])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# property labels\n",
      "property_labels = list(all_priors.columns.values[1:9])\n",
      "# New df for the means\n",
      "pr_means = pd.DataFrame(columns=(['domain','condition'] + property_labels))\n",
      "\n",
      "for j in range(2): # loop through condition (plausibility / frequency)\n",
      "    for i, dom in enumerate(list(set(all_priors[\"domain\"]))): # through domain\n",
      "        df0 = all_priors[((all_priors.domain == dom) & (all_priors.condition == j))][property_labels] # subset by domain\n",
      "        normed_means = df0.div(df0.sum(axis=1),axis=0).apply(np.mean) # Normalize each item, take means\n",
      "        pr_means.loc[i+6*j] = pd.Series([dom,j],[\"domain\",\"condition\"]).append(normed_means) # Load normed means\n",
      "        \n",
      "# reorder columns so that it's monotonic in number of present properties\n",
      "cols = pr_means.columns.tolist()\n",
      "cols = cols[0:5] + [cols[6]] + [cols[5]] + cols[7::]\n",
      "pr_means = pr_means[cols]\n",
      "pr_means.columns = [\"domain\",\"condition\",\"111\",\"110\",\"101\",\"011\",\"100\",\"010\",\"001\",\"000\"]\n",
      "pr_means.condition = pr_means.condition.replace(0,\"plausibility\")\n",
      "pr_means.condition = pr_means.condition.replace(1,\"frequency\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "pr_means.to_csv(datapath+'/prior-exp-mturk_means_n71.csv')\n",
      "all_priors.to_csv(datapath+'/prior-exp-mturk_all_n71.csv')"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Could these priors (means) have been generated by independent coin flips?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### A, B, C ~ Bernoulli ( <code>a, b, c</code>) i.d. (not identical)"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "# test case for code\n",
      "\n",
      "test_case = pd.DataFrame(columns=(['domain','condition'] + property_labels))\n",
      "a, b, c = 0.3, 0.4, 0.5\n",
      "tst = ['cats', 0, (a*b*c), (a*b*(1-c)), (a*(1-b)*c), (a*(1-b)*(1-c)), \\\n",
      "       ((1-a)*b*c), ((1-a)*b*(1-c)), ((1-a)*(1-b)*c), ((1-a)*(1-b)*(1-c))]\n",
      "test_case.loc[0] = tst\n",
      "\n",
      "a, b, c = 0.2, 0.1, 0.8\n",
      "tst = ['rats', 1, (a*b*c), (a*b*(1-c)), (a*(1-b)*c), (a*(1-b)*(1-c)), \\\n",
      "       ((1-a)*b*c), ((1-a)*b*(1-c)), ((1-a)*(1-b)*c), ((1-a)*(1-b)*(1-c))]\n",
      "\n",
      "test_case.loc[1] = tst\n",
      "\n",
      "pr_means = test_case\n",
      "pr_means"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# define objective function to minimize\n",
      "\n",
      "def fun1(a,b,c):\n",
      "    return a*b*c\n",
      "\n",
      "def fun2(a,b,c):\n",
      "    return a*b*(1-c)\n",
      "\n",
      "def fun3(a,b,c):\n",
      "    return a*(1-b)*(1-c)\n",
      "\n",
      "def fun4(a,b,c):\n",
      "    return (1-a)*(1-b)*(1-c)\n",
      "\n",
      "def objective(x,priors,plabels):\n",
      "    \n",
      "    p1dev = ((fun1(x[0],x[1],x[2])-priors[plabels[0]])**2).sum()\n",
      "    \n",
      "    p2dev = ((fun2(x[0],x[1],x[2])-priors[plabels[1]])**2).sum()+ \\\n",
      "            ((fun2(x[2],x[0],x[1])-priors[plabels[2]])**2).sum()+ \\\n",
      "            ((fun2(x[1],x[2],x[0])-priors[plabels[3]])**2).sum()\n",
      "    \n",
      "    p3dev = ((fun3(x[0],x[1],x[2])-priors[plabels[4]])**2).sum()+ \\\n",
      "            ((fun3(x[1],x[2],x[0])-priors[plabels[5]])**2).sum()+ \\\n",
      "            ((fun3(x[2],x[0],x[1])-priors[plabels[6]])**2).sum()\n",
      "            \n",
      "    p4dev = ((fun1(x[0],x[1],x[2])-priors[plabels[7]])**2).sum()\n",
      "    \n",
      "    return p1dev+p2dev+p3dev+p4dev"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x0 = np.array([0.3,0.45,0.5]) #starting guess\n",
      "opt_br = []\n",
      "param_labels = pr_means.columns.tolist()[2:10]\n",
      "\n",
      "for pr in pr_means.iterrows():\n",
      "    min_out = minimize(objective,x0,args=(pr[1],param_labels),method='nelder-mead')\n",
      "    opt_br.append(min_out.x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# use best fit (flips) to generate distribution over 3 properties\n",
      "bf_predall = pd.DataFrame(columns=pr_means.columns.values)\n",
      "\n",
      "for i, br in enumerate(opt_br):\n",
      "    bf_pred = []\n",
      "    bf_pred.append(pr_means.loc[i][0])\n",
      "    bf_pred.append(pr_means.loc[i][1])\n",
      "    bf_pred.append(fun1(br[0],br[1],br[2]))\n",
      "\n",
      "    bf_pred.append(fun2(br[0],br[1],br[2]))\n",
      "    bf_pred.append(fun2(br[2],br[0],br[1]))\n",
      "    bf_pred.append(fun2(br[0],br[1],br[0]))\n",
      "\n",
      "    bf_pred.append(fun3(br[0],br[1],br[2]))\n",
      "    bf_pred.append(fun3(br[1],br[2],br[0]))\n",
      "    bf_pred.append(fun3(br[2],br[0],br[1]))\n",
      "\n",
      "    bf_pred.append(fun4(br[0],br[1],br[2]))\n",
      "\n",
      "    bf_predall.loc[i] = bf_pred\n",
      "    \n",
      "pr_melt=pd.melt(pr_means,id_vars=['domain','condition'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# correlation between all elicited priors and best fit (flips)\n",
      "pr_melt=pd.melt(pr_means,id_vars=['domain','condition'])\n",
      "bf_melt=pd.melt(bf_predall,id_vars=['domain','condition'])\n",
      "a = pd.merge(bf_melt,pr_melt,on=['variable','domain','condition'])\n",
      "corr = a[\"value_x\"].corr(a[\"value_y\"])\n",
      "print corr\n",
      "print a.query('condition == 0').value_x.corr(a.query('condition == 0').value_y)\n",
      "print a.query('condition == 1').value_x.corr(a.query('condition == 1').value_y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.656490459903\n",
        "nan\n",
        "nan\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Seems that the frequency priors are more \"independent\" than the plausibility priors. I wonder if that actually translates into better model differentiation. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#plot (some of) that shit\n",
      "x = np.arange(len(bf_predall.columns.values[2::]))\n",
      "\n",
      "fig, ((ax, bx),(cx, dx), (ex, fx)) = plt.subplots(nrows=3, ncols=2)\n",
      "fig.set_size_inches(10,6)\n",
      "plt.setp(((ax, bx),(cx, dx), (ex, fx)), xticks=x+0.2, \n",
      "         xticklabels=('111','110','101','011','100','010','001','000'))\n",
      "\n",
      "\n",
      "#ax = plt.subplot(211)\n",
      "ax.bar(x+0.2, bf_predall.loc[0][2::], width=0.4,color='r',alpha=0.5)\n",
      "ax.bar(x-0.2, pr_means.iloc[0][2::],width=0.4,color='y',alpha=0.5)\n",
      "ax.set_ylim((0,0.200))\n",
      "\n",
      "#bx = plt.subplot(212)\n",
      "bx.bar(x+0.2, bf_predall.loc[1][2::], width=0.4,color='r',alpha=0.5)\n",
      "bx.bar(x-0.2, pr_means.iloc[1][2::],width=0.4,color='y',alpha=0.5)\n",
      "bx.set_ylim((0,0.200))\n",
      "\n",
      "#cx = plt.subplot(221)\n",
      "cx.bar(x+0.2, bf_predall.loc[2][2::], width=0.4,color='r',alpha=0.5)\n",
      "cx.bar(x-0.2, pr_means.iloc[2][2::],width=0.4,color='y',alpha=0.5)\n",
      "cx.set_ylim((0,0.200))\n",
      "\n",
      "#dx = plt.subplot(222)\n",
      "dx.bar(x+0.2, bf_predall.loc[3][2::], width=0.4,color='r',alpha=0.5)\n",
      "dx.bar(x-0.2, pr_means.iloc[3][2::],width=0.4,color='y',alpha=0.5)\n",
      "dx.set_ylim((0,0.200))\n",
      "\n",
      "#cx = plt.subplot(221)\n",
      "ex.bar(x+0.2, bf_predall.loc[4][2::], width=0.4,color='r',alpha=0.5)\n",
      "ex.bar(x-0.2, pr_means.iloc[4][2::],width=0.4,color='y',alpha=0.5)\n",
      "ex.set_ylim((0,0.200))\n",
      "\n",
      "#dx = plt.subplot(222)\n",
      "fx.bar(x+0.2, bf_predall.loc[5][2::], width=0.4,color='r',alpha=0.5)\n",
      "fx.bar(x-0.2, pr_means.iloc[5][2::],width=0.4,color='y',alpha=0.5)\n",
      "fx.set_ylim((0,0.200))\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAlUAAAFwCAYAAACRj46qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyub/A6cITh8Iawr+AAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x108228c10>"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Syllogism model with (mean) empirical priors"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "expname = 'prior-exp-mturk_means_n71'\n",
      "priorpath = ('/Users/mht/Documents/research/syllogism/data/03syllogism_prior_psychjs/')\n",
      "priorfile = priorpath + expname +'.csv'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "os.chdir(\"/Users/mht/Documents/research/syllogism/models\")\n",
      "from syll_model import syllogism_model\n",
      "\n",
      "n_obj, br, ndepth, mdepth, alphq, alphr = 6, 0, 0, 0, 1, 1\n",
      "serv, nvc, vc, vcord, exp, fig, lis, EPin = 0, 0, 4,'CA','AIEO', 'Full', 'lis', 1\n",
      "prrs, prrt = 'MC_EE_ec', 'causal'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "allpriors = ['lightbulb','tomatoplant','cracker', \\\n",
      "             'strawberry','painting','knife'] \n",
      "alltypes = ['plausibility','frequency']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for ap in allpriors:\n",
      "    for at in alltypes:\n",
      "        syllorder, model_data = syllogism_model(n_obj,br,ndepth,mdepth,alphq,alphr,\\\n",
      "                                            domain=ap,\\\n",
      "                                            priortype=at)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sampling and featurizing 6 lightbulbs plausibility\n",
        "6 = n balls"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "listening, reasoning, speaking... alpha1\n",
        "listening, reasoning, speaking... alpha0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "sampling and featurizing 6 lightbulbs frequency"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6 = n balls"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "listening, reasoning, speaking... alpha1\n",
        "listening, reasoning, speaking... alpha0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "sampling and featurizing 6 tomatoplants plausibility"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6 = n balls"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "listening, reasoning, speaking... alpha1\n",
        "listening, reasoning, speaking... alpha0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "sampling and featurizing 6 tomatoplants frequency"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6 = n balls"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "listening, reasoning, speaking... alpha1\n",
        "listening, reasoning, speaking... alpha0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "sampling and featurizing 6 crackers plausibility"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6 = n balls"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "listening, reasoning, speaking... alpha1\n",
        "listening, reasoning, speaking... alpha0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "sampling and featurizing 6 crackers frequency"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6 = n balls"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "listening, reasoning, speaking... alpha1\n",
        "listening, reasoning, speaking... alpha0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "sampling and featurizing 6 strawberrys plausibility"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6 = n balls"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "listening, reasoning, speaking... alpha1\n",
        "listening, reasoning, speaking... alpha0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "listening, reasoning, speaking... alpha1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "sampling and featurizing 6 paintings plausibility"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6 = n balls"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "listening, reasoning, speaking... alpha1\n",
        "listening, reasoning, speaking... alpha0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "sampling and featurizing 6 paintings frequency"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6 = n balls"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "listening, reasoning, speaking... alpha1\n",
        "listening, reasoning, speaking... alpha0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "sampling and featurizing 6 knifes plausibility"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6 = n balls"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "listening, reasoning, speaking... alpha1\n",
        "listening, reasoning, speaking... alpha0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "sampling and featurizing 6 knifes frequency"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6 = n balls"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "listening, reasoning, speaking... alpha1\n",
        "listening, reasoning, speaking... alpha0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### OED"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "sys.path.append('/Users/mht/Documents/research/oed_py/oed/')\n",
      "\n",
      "import oed\n",
      "import pmf\n",
      "import church\n",
      "\n",
      "import copy\n",
      "import csv\n",
      "\n",
      "import itertools \n",
      "\n",
      "fpath = '/Users/mht/Documents/research/syllogism/models/modeldata/'\n",
      "domains = ['lightbulb','tomatoplant','cracker','strawberry','painting','knife'] \n",
      "priors = ['plausibility','frequency']\n",
      "prior = priors[1]\n",
      "printout = True\n",
      "n_obj = 6\n",
      "fig = 'Full'\n",
      "best_fit_br = '0.50'\n",
      "ndepth = '0'\n",
      "alphq = '1'\n",
      "outfile = 'oed_'+prior+'_depth' + ndepth+'iidArgStr_emprArgStr_emprCLonly'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f0 = fpath+('LATTICE_4_%s/00/csv/lis_N0_M0_%s%s_qud1fig%s_AIEOc4CAEP1_n%d_base0.00_s100k_alphQ1_alphR1.csv'\\\n",
      "          % (prior,prior,domains[0],fig, n_obj))\n",
      "df = pd.read_csv(f0)\n",
      "experiments = df[\"# syll\"]\n",
      "responses = df.columns.values[5:9]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# define church programs\n",
      "# -- models is a PMF of the belief distribution for all the mdoels\n",
      "# -- the first arguments are the filename of each church program\n",
      "# -- the second arguments are the prior belief distribution of each church program (which is uniform in this example)\n",
      "\n",
      "mnames = ['argstr_iid','argstr_empr','clonly_empr']\n",
      "\n",
      "models = pmf.PMF(3)\n",
      "models[0] = pmf.P(mnames[0]+\".church\", 1.0)\n",
      "models[1] = pmf.P(mnames[1]+\".church\", 1.0)\n",
      "models[2] = pmf.P(mnames[2]+\".church\", 1.0)\n",
      "models.normalize()\n",
      "\n",
      "alldata = np.zeros((len(models),\n",
      "                    len(experiments),\n",
      "                    len(responses)*len(domains))) # domains (empirical) vs naive\n",
      "\n",
      "alldata.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 80,
       "text": [
        "(3, 64, 24)"
       ]
      }
     ],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load data into alldata\n",
      "# alldata[0] will be for model 1 ('empirical priors')\n",
      "# alldata[1] will be for model 2 ('naive [best fit, iid] priors')\n",
      "\n",
      "for m, mod in enumerate(mnames):\n",
      "    \n",
      "    for d, dom in enumerate(domains):\n",
      "\n",
      "        if dom is 'naive': \n",
      "           # dom = ''\n",
      "            br = best_fit_br\n",
      "            nsamp = 100\n",
      "        else: \n",
      "            #dom = '_'+dom\n",
      "            br = '0.00'\n",
      "            nsamp = 100\n",
      "\n",
      "        if mod[0:6]=='clonly': \n",
      "            f1 = fpath + ('LATTICE_4_%s/%s0/csv/lis_N%s_M0_CLonly_%s%s_qud1fig%s_AIEOc4CAEP1_n%d_base%s_s%dk.csv'\\\n",
      "                          % (prior,ndepth,ndepth,prior,dom,\\\n",
      "                             fig,n_obj,br,nsamp))\n",
      "        elif mod[-3::]=='iid':\n",
      "            f1 = fpath+('LATTICE_4/00/csv/lis_N0_M0_qud1figFull_AIEOc4CAEP1_n6_base0.25_s100k_alphQ1_alphR1.csv')\n",
      "        else: \n",
      "            f1 = fpath+('LATTICE_4_%s/%s0/csv/lis_N%s_M0_%s%s_qud1fig%s_AIEOc4CAEP1_n%d_base%s_s%dk_alphQ%s_alphR1.csv'\\\n",
      "          % (prior,ndepth,ndepth,prior,dom,fig,n_obj,br,nsamp,alphq))\n",
      "\n",
      "        alldata[m,:,d*4:d*4+4] = pd.read_csv(f1,usecols=responses)\n",
      "\n",
      "# define space of possible outputs\n",
      "# -- output_pmf is a PMF to store the resulting distributions from the church programs\n",
      "# -- the first arguments are the possible output values\n",
      "# -- the second arguments will be overwritten and do not matter\n",
      "output_pmf = pmf.PMF(len(responses)*len(domains))\n",
      "for i, x in enumerate(itertools.product(domains,responses)):\n",
      "    outlabel = x[0]+'_'+x[1]\n",
      "    output_pmf[i] = pmf.P(outlabel, 1.0)\n",
      "\n",
      "output_pmf.normalize() "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print mnames[0],mnames[1],np.corrcoef(np.ravel(alldata[0]),np.ravel(alldata[1]))[1,0]\n",
      "print mnames[0],mnames[2],np.corrcoef(np.ravel(alldata[0]),np.ravel(alldata[2]))[1,0]\n",
      "print mnames[1],mnames[2],np.corrcoef(np.ravel(alldata[1]),np.ravel(alldata[2]))[1,0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "argstr_iid argstr_empr 0.652292309027\n",
        "argstr_iid clonly_empr 0.34179798678\n",
        "argstr_empr clonly_empr 0.803101522689\n"
       ]
      }
     ],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# generate an array of output_pmfs for each church program\n",
      "outputs = [0]*len(models)\n",
      "for m in range(len(models)) :\n",
      "    outputs[m] = copy.deepcopy(output_pmf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "expected_kl = np.zeros((len(experiments)))\n",
      "# iterate over all possible inputs / syllogisms\n",
      "f = open(fpath+outfile+'.txt', 'w')\n",
      "\n",
      "for j,i in enumerate(experiments):\n",
      "\n",
      "    for m in range(len(models)) :\n",
      "        \n",
      "        for k, rsp in enumerate(itertools.product(domains,responses)):\n",
      "            outlabel = rsp[0]+'_'+rsp[1]\n",
      "            outputs[m].pmf[k] = pmf.P(outlabel,alldata[m,j,k])\n",
      "\n",
      "    # using the computed output distribution, compute and print the expected KL-divergence for each input\n",
      "    expected_kl[j] = oed.get_expected_kl(models, outputs)\n",
      "    f.write(i + ' ' + str(expected_kl[j]) + ' ' + str(outputs) + '\\n\\n')\n",
      "    \n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ekl = np.array([(experiments[i],kl) for i, kl in enumerate(expected_kl)])\n",
      "#    print experiments[i] + '   ' + str(kl)\n",
      "#print ekl\n",
      "ek_sort = ekl[np.argsort(ekl[:,1])]\n",
      "if printout: \n",
      "    f = open('/Users/mht/Documents/research/syllogism/data/03syllogism_prior_psychjs/'+outfile+'_sorted.txt', 'w')\n",
      "    \n",
      "    for k in ek_sort[::-1]:\n",
      "        f.write(k[0] + ' ' + k[1] +'\\n')\n",
      "\n",
      "    f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "allresp = [a[0]+'.'+a[1] for a in itertools.product(domains,responses)]\n",
      "# organize data into one data frame, wide format\n",
      "model_df = pd.DataFrame(columns=(['# syll','model'] + allresp))\n",
      "for a in range(len(alldata)):\n",
      "    d0 = pd.DataFrame(alldata[a],columns = allresp)\n",
      "    m_cat = pd.concat([experiments, d0],axis=1,ignore_index=False)\n",
      "    m_cat.insert(1,'model',mnames[a])\n",
      "    model_df = pd.concat([model_df,m_cat],axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_df.to_csv('/Users/mht/Documents/research/syllogism/data/03syllogism_prior_psychjs/3modeldata_'+outfile+'.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}