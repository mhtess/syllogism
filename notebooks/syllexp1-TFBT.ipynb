{
 "metadata": {
  "name": "",
  "signature": "sha256:7cbeb451b0f04592886d0f43eee0fae613779f58a14ac0f0f25a6320bbea9662"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Experiment 1: Bayesian data analysis"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`tfbt_run.py` loops through parameter values to compute model predictions for the \"family\" of models\n",
      "\n",
      "`syllmodel_given_data.py` has a number of functions to calculate (log) priors and (log) likelihoods"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "os.chdir('/Users/mht/Documents/research/syllogism/models/')\n",
      "import syllmodel_given_data as tfbt\n",
      "import pandas as pd\n",
      "from numpy import array, log\n",
      "from math import gamma, exp\n",
      "from scipy.special import gammaln\n",
      "from scipy.stats import poisson"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataf = '/Users/mht/Documents/research/syllogism/data/03syllogism_reasoning/syllbelief-exp-means_collapsed_sansOutliers.csv'\n",
      "data=pd.read_csv(dataf,usecols=['domain','syll','All','None','Some','Some_not'])\n",
      "modelpath = '/Users/mht/Documents/research/syllogism/models/modeldata/LATTICE_4_tfbt/'\n",
      "domains = ['cracker', 'knife', 'lightbulb', 'strawberry']\n",
      "responses = ['All','None','Some','Some_not']\n",
      "number_of_objects = range(4,11)\n",
      "syllogisms = ['AO2', 'EA3', 'IE1', 'OA1']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "log_posteriors = []\n",
      "corrs = []\n",
      "log_likelihoods = []"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for n_obj in number_of_objects:\n",
      "    model = pd.DataFrame(columns=['domain', 'syll', 'All', 'None', 'Some', 'Some_not'])\n",
      "    p_mgd = 0\n",
      "    l_mgd = 0\n",
      "    for dom in domains:\n",
      "        model_all = pd.read_csv(((modelpath+dom+'/00/csv/' \\\n",
      "            +'lis_N0_M0_tfbt%s_qud1figFull_AIEOc4CAEP1_n%d_base0.00'\\\n",
      "            +'_s100k_alphQ1_alphR1_bsmean.csv') % (dom,n_obj)),\n",
      "            usecols=['# syll','all.C-A','none.C-A','some.C-A','not-all.C-A'])\n",
      "\n",
      "        model_subset = model_all[model_all[\"# syll\"].isin(syllogisms)] # predictions only for syllogisms of interest (experiment)\n",
      "        model_subset.columns = ['syll','All','None','Some','Some_not'] # rename columns\n",
      "        model_subset.insert(0,'domain',dom) # insert domain column\n",
      "        model = model.append(model_subset)\n",
      "        model = model.replace(0,0.00001) # gamma (ln (0)) --> inf; is this okay?\n",
      "\n",
      "        for syllogism in syllogisms:\n",
      "            model_pred = model[((model.syll==syllogism) & (model.domain==dom))][responses].values[0]\n",
      "            obs_data = data[((data.syll==syllogism) & (data.domain==dom))][responses].values[0]\n",
      "            mgd = tfbt.model_given_data(model_pred, obs_data, 1, 4, n_obj)\n",
      "            lklhd = tfbt.log_dirichlet(1, obs_data, model_pred)\n",
      "            p_mgd = p_mgd + mgd\n",
      "            l_mgd = l_mgd + lklhd\n",
      "\n",
      "    log_posteriors.append(p_mgd) #record log posterior\n",
      "    log_likelihoods.append(l_mgd) #record log posterior\n",
      "\n",
      "\n",
      "    dm_joined = pd.merge(pd.melt(model, id_vars=['domain','syll']),\n",
      "             pd.melt(data,id_vars=['domain','syll']), \n",
      "             on=['variable','domain','syll'])\n",
      "    corrs.append(dm_joined[\"value_x\"].corr(dm_joined[\"value_y\"])) # record correlation\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "norm_lp = [lp/sum(log_posteriors) for lp in log_posteriors] # normalized, log posterior probabilities"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "log_posteriors"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "[-115.66590530458376,\n",
        " -120.96095711588131,\n",
        " -129.84889007234298,\n",
        " -141.66072140339983,\n",
        " -155.06159729406778,\n",
        " -171.74839923661489,\n",
        " -190.4729913926312]"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corrs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "[0.80596178145234942,\n",
        " 0.80898115454610253,\n",
        " 0.80664107715634914,\n",
        " 0.8030219021256374,\n",
        " 0.79809144746681304,\n",
        " 0.78877704658876324,\n",
        " 0.77750331402343442]"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "[k for k in log_likelihoods]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "[-89.539883130689645,\n",
        " -91.264638120959816,\n",
        " -93.665129347690865,\n",
        " -96.523108071780925,\n",
        " -98.833629073489774,\n",
        " -102.54554755657563,\n",
        " -106.60948800260546]"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## sctrach pad"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = pd.DataFrame(columns=['domain', 'syll', 'All', 'None', 'Some', 'Some_not'])\n",
      "p_mgd = 0\n",
      "for dom in domains:\n",
      "    model_all = pd.read_csv(((modelpath+dom+'/00/csv/' \\\n",
      "        +'lis_N0_M0_tfbt%s_qud1figFull_AIEOc4CAEP1_n%d_base0.00'\\\n",
      "        +'_s100k_alphQ1_alphR1_bsmean.csv') % (dom,n_obj)),\n",
      "        usecols=['# syll','all.C-A','none.C-A','some.C-A','not-all.C-A'])\n",
      "\n",
      "    model_subset = model_all[model_all[\"# syll\"].isin(syllogisms)] # predictions only for syllogisms of interest (experiment)\n",
      "    model_subset.columns = ['syll','All','None','Some','Some_not'] # rename columns\n",
      "    model_subset.insert(0,'domain',dom) # insert domain column\n",
      "    model = model.append(model_subset)\n",
      "    model = model.replace(0,0.00001) # gamma (ln (0)) --> inf; is this okay?\n",
      "\n",
      "    for syllogism in syllogisms:\n",
      "        model_pred = model[((model.syll==syllogism) & (model.domain==dom))][responses].values[0]\n",
      "        obs_data = data[((data.syll==syllogism) & (data.domain==dom))][responses].values[0]\n",
      "        mgd = tfbt.model_given_data(model_pred, obs_data, 1, 4, n_obj)\n",
      "        mgdunif = tfbt.log_dirichlet(1, obs_data, model_pred)\n",
      "        print mgd, mgdunif, syllogism"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-14.8795520197 -9.63808305786 AO2\n",
        "-14.9381834906 -9.6967145287 EA3\n",
        "-8.00566689398 -2.76419793211 IE1\n",
        "-6.66076657033 -1.41929760845 OA1\n",
        "-16.1405064127 -10.8990374508 AO2\n",
        "-20.1634825462 -14.9220135843 EA3\n",
        "-8.59894565225 -3.35747669038 IE1\n",
        "-6.7420931435 -1.50062418162 OA1\n",
        "-18.1966494134 -12.9551804515 AO2\n",
        "-17.0184784585 -11.7770094966 EA3\n",
        "-7.04151609351 -1.80004713163 IE1\n",
        "-9.29335645359 -4.05188749171 OA1\n",
        "-14.6994431476"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -9.45797418573 AO2\n",
        "-13.5047654144 -8.26329645257 EA3\n",
        "-6.83943675364 -1.59796779177 IE1\n",
        "-7.75014892864 -2.50867996677 OA1\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sum(model_pred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "1.0"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.special import gammaln\n",
      "from numpy import array, log, exp, prod\n",
      "from math import gamma"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "cracker AO2\n",
        "1.07769821241e-05\n",
        "cracker EA3\n",
        "1.56049298169e-05\n",
        "cracker IE1\n",
        "0.0633517982284\n",
        "cracker OA1\n",
        "0.0664646786016\n",
        "knife AO2\n",
        "7.16749049515e-06\n",
        "knife EA3\n",
        "3.49056008434e-06\n",
        "knife IE1\n",
        "0.0458685339908\n",
        "knife OA1\n",
        "0.0793140746599\n",
        "lightbulb AO2\n",
        "5.67026761439e-06\n",
        "lightbulb EA3\n",
        "4.64873580228e-06\n",
        "lightbulb IE1\n",
        "0.0765312648441\n",
        "lightbulb OA1\n",
        "0.0512381784062\n",
        "strawberry AO2\n",
        "1.3225265629e-05\n",
        "strawberry EA3\n",
        "4.27383500694e-05\n",
        "strawberry IE1\n",
        "0.0613157706758\n",
        "strawberry"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " OA1\n",
        "0.0253241010407\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dom = domains[0]\n",
      "syllogism = syllogisms[2]\n",
      "print syllogism\n",
      "model_pred = model[((model.syll==syllogism) & (model.domain==dom))][responses].values[0]\n",
      "obs_data = data[((data.syll==syllogism) & (data.domain==dom))][responses].values[0]\n",
      "print model_pred\n",
      "print obs_data\n",
      "print tfbt.log_dirichlet(1,obs_data,model_pred)\n",
      "print tfbt.model_given_data(model_pred, obs_data, 1, 4, n_obj)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "IE1\n",
        "[ 0.06688351  0.34331165  0.15668835  0.43311649]\n",
        "[ 0.08643608  0.33282845  0.17283133  0.40790414]\n",
        "-1.12617560114\n",
        "3.59705567369\n"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math\n",
      "import operator\n",
      "\n",
      "def dirichlet_pdf(x, alpha):\n",
      "  return (math.gamma(sum(alpha)) / \n",
      "          reduce(operator.mul, [math.gamma(a) for a in alpha]) *\n",
      "          reduce(operator.mul, [x[i]**(alpha[i]-1.0) for i in range(len(alpha))]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "exp(poisson.logpmf(4,4)+tfbt.log_dirichlet(1,obs_data,model_pred))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 78,
       "text": [
        "0.0633517982283899"
       ]
      }
     ],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tfbt.log_poisson(4,4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 68,
       "text": [
        "4.7232312748275085"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "log(reduce(operator.mul, [obs_data[i]**(model_pred[i]-1.0) for i in range(len(model_pred))]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 61,
       "text": [
        "4.9957569380610796"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tfbt.model_given_data(model_pred, obs_data, 1, 4, n_obj)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 62,
       "text": [
        "3.5970556736879824"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tfbt.model_given_data(model_pred, obs_data, 1, 4, n_obj)\n",
      "tfbt.log_poisson(4, 4)\n",
      "#exp(a)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "4.7232312748275085"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = tfbt.log_dirichlet(1, obs_data, model_pred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "exp(log(5))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 38,
       "text": [
        "4.999999999999999"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alphas = model_pred\n",
      "xs = obs_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xs, alphas = array(xs), array(alphas)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 104
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 105,
       "text": [
        "array([ 0.08876573,  0.21472653,  0.24503626,  0.45147147])"
       ]
      }
     ],
     "prompt_number": 105
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alphas"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 106,
       "text": [
        "array([ 0.        ,  0.34305088,  0.15694912,  0.5       ])"
       ]
      }
     ],
     "prompt_number": 106
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sum(gammaln(alphas))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 109,
       "text": [
        "inf"
       ]
      }
     ],
     "prompt_number": 109
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sum(gammaln(alphas))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 85,
       "text": [
        "array([        inf,  0.95545337,  1.78009754,  0.57236494])"
       ]
      }
     ],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "log(gamma(sum(alphas[0])))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 94,
       "text": [
        "0.0"
       ]
      }
     ],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sum(alphas)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 91,
       "text": [
        "array([ 0.        ,  0.34305088,  0.15694912,  0.5       ])"
       ]
      }
     ],
     "prompt_number": 91
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alphas[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 93,
       "text": [
        "array([ 0.        ,  0.34305088,  0.15694912,  0.5       ])"
       ]
      }
     ],
     "prompt_number": 93
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "obs_data[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 95,
       "text": [
        "array([ 0.08876573,  0.21472653,  0.24503626,  0.45147147])"
       ]
      }
     ],
     "prompt_number": 95
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}