%  after submission
%
% 
%
%
%
%
%
%
\documentclass{llncs} %
%\documentclass{article}
%\usepackage{natbib}
\usepackage{booktabs}
\usepackage{pslatex}
\usepackage{apacite}
\usepackage{url}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{color}
\usepackage{textcomp}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{wrapfig}
\usepackage{lipsum}

\definecolor{Red}{RGB}{255,0,0}
\newcommand{\red}[1]{\textcolor{Red}{#1}}  
\newcommand{\denote}[1]{\mbox{ $[\![ #1 ]\!]$}}

\newcommand{\subsubsubsection}[1]{{\em #1}}
\newcommand{\eref}[1]{(\ref{#1})}
\newcommand{\tableref}[1]{Table \ref{#1}}
\newcommand{\figref}[1]{Figure \ref{#1}}
\newcommand{\appref}[1]{Appendix \ref{#1}}
\newcommand{\sectionref}[1]{Section \ref{#1}}

\lstset{
  language=Scheme, % Andreas Stuhlmüller. Scheme listings. https://github.com/stuhlmueller/scheme-listings.git
  columns=fixed,
  tabsize=2,
  extendedchars=true,
  breaklines=true,
  frame=single,
%  numbers=left,
  numbersep=5pt,
    basicstyle=\scriptsize\ttfamily
%  rulesepcolor=\color{solarized@base03},
%  numberstyle=\tiny\color{solarized@base01},
%  keywordstyle=\color{solarized@green},
%  stringstyle=\color{solarized@cyan}\ttfamily,
%  identifierstyle=\color{blue},
%  commentstyle=\color{solarized@base01},
%  emphstyle=\color{solarized@red}
}

\title{Understanding \emph{belief bias} by measuring prior beliefs for a Bayesian model of syllogistic reasoning}

%\author{}
\author{{\large \bf Michael Henry Tessler} \\mtessler@stanford.edu}
%\institute{} 
\institute{Department of Psychology, Stanford University}
 
\begin{document}

\maketitle


\begin{abstract}
The phenomenon of \emph{belief bias} in syllogistic reasoning occurs when the a priori believability of a conclusion influences the intuitive acceptability of that conclusion. Prior beliefs about the world can be formalized into a probabilistic generative model of situations. \citeA{Tessler2014} proposed that this very idea can account for the range of acceptabilities of conclusions from categorical syllogisms with abstract content. Here, I generalize their model to accommodate syllogistic reasoning data where content effects are observed. I collect data about the prior plausibility of various properties co-occurring, and use this data to predict syllogistic reasoning behavior in a separate experiment. I compare models with different types of assumptions concerning the prior and discuss open questions for this approach. 
\end{abstract}

Your logic-chopping friend is in a room with a number of lamps and lightbulbs; you are in a different room and cannot see what she sees. She gives you the following logic puzzle:

\begin{quote}
All of the lightbulbs that are hot are bright.\\
Some of the lightbulbs that are bright are \emph{not} on.
\end{quote}

Are some of the hot lightbulbs \emph{not} on? Are any of the hot ones on?
\vspace{0.3cm}

Prior beliefs about the world guide our actions, thoughts, and reasoning in new situations. It can be helpful, for example, to know how fast a particular kind of animal can run, if you are also thinking about if that animal can eat you. Similarly, humans can use prior beliefs in a domain (e.g. life expectancies) to reason accurately about everyday contexts  (e.g. guessing how long someone will live; \citeNP{Griffiths2006}). Finally, it has been argued that prior beliefs influence the very meaning of words \cite{GoodLass2015}. It is odd then that so little formal theory has gone into understanding prior beliefs in classic reasoning tasks \cite<but, cf.>{Klauer2000, Dube2010}.

Bayesian approaches to cognitive science have a natural way of accounting for prior beliefs in reasoning. 
%\citeA{Tessler2014} argue that syllogistic reasoning can be understood through the broader lens of language understanding, formalized in a probabilistic model of pragmatic reasoning about syllogistic premises. They
 \citeA{Tessler2014} described a generative model of argument strength that uses a truth-functional semantics applied to idealized situations composed of objects with properties. 
 This model accounted for much of the variability in \citeA{Chater1999}'s meta-analysis data  of categorical syllogistic reasoning. 
That work further explored syllogistic reasoning by incorporating Gricean principles, formalized in the Rational Speech-Act (RSA) theory of language understanding \cite{Frank2012,Goodman2013}.
%}---and specifying the Question Under Discussion as the relationship between the conclusion terms (i.e. the QUD is the syllogistic conclusion). 
This pragmatic component was important in capturing important qualitative phenomena in syllogistic reasoning (e.g. the relative preference for the \emph{all X are Y} conclusion over the \emph{some X are Y} conclusion when both are logically valid).
This work was done with respect to meta-analysis data that differed largely in the materials used, and for which prior beliefs about the materials were not expected to have a substantial effect.
However, it is known that prior expectations about the categories and properties at stake in a syllogism influence the acceptability of a conclusion \cite{Evans83, Cherubini1998, Evans2001}.

Here, I generalize \citeA{Tessler2014}'s model of argument strength to capture qualitative phenomena associated with \emph{belief bias}. This is done by empirically measuring prior beliefs about real-world content, deriving model predictions based on those beliefs, and testing the probabilisitic model of argument strength against behavioral data obtained in a separate experiment of syllogistic reasoning. A secondary, primarily methodological concern is about the granularity of information needed to capture these syllogistic reasoning phenomena. 

%The extent to which beliefs influence reasoning depends on the a priori acceptability of the conclusion \cite{Evans1983}, of the premises \cite{Cherubini1998}, as well as the relative strength of the argument \cite{Evans2001}. The approach outlined in this paper is to account for the gradience in argument strength in terms of the prior distribution over properties in question; i.e., I explain relative argument strength and the influence of beliefs jointly.

%\subsection{Forward summary}

%In this paper, I address two questions: Does the prior distribution matter for syllogistic reasoning about real world content? Is it necessary to model dependencies in background knowledge? 

%The organization for the rest of the paper is as follows. First, I review the Bayesian model of argument strength by \citeA{Tessler2014} and propose an extension to account for reasoning about real-world content. I then collect data measuring prior expectations about the distributions of various properties co-occurring in 4 domains: frozen fruit, expired crackers, bright lightbulbs, and sharp knives. I also collect data about 8 syllogisms using each domain's content (32 items in total). I then compare the model to the data by integrating out the parameters of the reasoning model and comparing alternative models with increasingly relaxed assumptions about background knowledge. 

To foreshadow the results, empirically measured priors (Expt.~1) coupled with a Bayesian model of argument strength accounts for much of the syllogistic reasoning data (Expt.~2), including qualitative effects of content. The predictions of the model, which has no parameters, are as good as those of a model with a prior parametrized by 12 variables. The most likely values (conditioned on the data of Expt.~2) of these 12 variables correspond roughly with the marginal distributions of the priors elicited in Expt.~1. This interesting correspondence suggests the syllogistic reasoning task is too coarse-grained to disambiguate models of reasoning that rely on correlated properties from models where independence is assumed.


% \citeA{Evans1999} conducted a standard syllogistic reasoning study (syllogistic reasoning with only abstract terms) and found gradient endorsement rates for logically invalid syllogisms; this gradient can be interpreted as relatively weaker and stronger arguments. \citeA{Evans2001} replicated this finding and found that weaker syllogisms were more susceptible to positive belief bias (i.e. accepting a believable conclusion) and stronger syllogisms were more susceptible to negative belief belief (i.e. rejecting an unbelievable conclusion). This work suggests a gradient influence of prior beliefs on argument strength. 



%\section{Empirical work on syllogistic reasoning}
%
%Syllogistic reasoning lies at the intriguing intersection of logic and language. On the one hand, syllogisms are logical: Indeed, for about two millennia, they comprised the core of formal logic\footnote{By inventing the syllogistic argument, Aristotle incidentally invented \emph{the variable} as well. The fact that a logical form that can be instantiated by literally any content is what makes this bridge to our modern notion of a variable.}. On the other hand, syllogisms are a part of language: Aristotle's logic can be thought of as an early stab at natural language semantics, though there have been considerable improvements since (e.g. \citeA{Horn1989}). Syllogisms are an intriguing intermediate form: Abstract and logically consistent while approachable by any language user. And though as a formal reasoning tool, syllogisms are internally valid and complete, their reliance upon natural language makes them perfectly vulnerable to all of the uncertainty that comes with understanding natural language (for one perspective on uncertainty in language, see \citeA{GoodLass2015}).
%
%\subsection{The syllogistic space}
%
%The syllogism is a logical form: a two-sentence argument used to relate two properties (or terms: A, C) via a middle term (B). In categorical syllogisms (the focus of this paper), the relation between the terms is a quantifier acting on sets. Here is an example of a formal syllogistic argument.
%\begin{quote}
%Premise 1: All A are B\\
%Premise 2: Some B are C\\
%Conclusion: Some A are C
%\end{quote}
%The full space of syllogistic arguments (64 premise pairs in total) is derived by shuffling the ordering of the terms in a premise (``All A are B'' vs. ``All B are A'') and changing the quantifier (\emph{all, some, none, not all}). Most syllogisms are invalid, i.e. the conclusion (i.e. the relation between terms A \& C) is not true in every situation in which the premises are true. For example, the argument above is invalid. Participants, however, are perfectly comfortable drawing a conclusion. A recent meta-analysis of syllogistic reasoning showed that over the population, the ``false alarm'' rate for a invalid syllogisms ranged from 24\% to 88\%. For valid arguments, the accuracy for a \emph{logically valid conclusion} ranged from 1\% to 90\% \cite{Khemlani2012}. Such heterogeneity in accuracy for logical valid responses suggests a computational-level theory based on deductive validity is untenable. 

%\subsection{Prior beliefs in syllogistic reasoning}
%
%The divergence between human reasoning and deductive logic is probably why syllogistic reasoning has been a topic of interest for a long time \cite{Storring1908,Woodworth1935, Chapman1959, JL1978, Chater1999}. Many factors affect the acceptability of a syllogistic conclusion. One very prominent factor is the content of the syllogistic argument. For example, \citeA{Wilkins1928} observed that
%
%\begin{quote}
%No A are B\\
%No B are C\\
%Therefore, no A are C
%\end{quote}
%
%produced appreciably fewer endorsements than 
%
%\begin{quote}
%No apples are oranges\\
%No oranges are lemons\\
%Therefore, no apples are lemons
%\end{quote}
%
%In more targeted studies since, it's been consistently shown that the \emph{a priori} believability of the conclusion influences the acceptability of the conclusion. This was first characterized as an interaction between logic and belief \cite{Evans1983}. It may not be only the believability of the \emph{conclusion} that influences reasoning, however. \citeA{Cherubini1998} found the a priori believability of the \emph{premises}, too, is relevant factor in determining what conclusions to draw from an argument. 

%\citeA{Evans1983} demonstrated that the \emph{a priori} believability of the conclusion influences the acceptability of the conclusion, and that this influence was more pronounced for invalid rather than valid syllogisms. This characterization of this interplay between logic and belief has been debated \cite{Newstead1993, others}.  For example, when experimenters have included neutral materials for baseline comparisons, they find belief bias is primarily associated with \emph{rejecting unbelievable} conclusions particularly when the syllogism is invalid, leading some investigators to refer to it as ``belief debias'' \cite{Morley2004, Newstead1992}.

%The extent to which beliefs influence reasoning also seems to depend on the relative strength of the argument. \citeA{Evans1999} conducted a standard syllogistic reasoning study (syllogistic reasoning with only abstract terms) and found gradient endorsement rates for logically invalid syllogisms; this gradient can be interpreted as relatively weaker and stronger arguments. \citeA{Evans2001} replicated this finding and found that weaker syllogisms were more susceptible to positive belief bias (i.e. accepting a believable conclusion) and stronger syllogisms were more susceptible to negative belief belief (i.e. rejecting an unbelievable conclusion). This work suggests a gradient influence of prior beliefs on argument strength. 
%
%\subsection{Forward summary}
%
%In this paper, I address two questions: Does the prior distribution matter for syllogistic reasoning about real world content? Is it necessary to model dependencies in background knowledge? 
%
%The organization for the rest of the paper is as follows. First, I review the model by \citeA{Tessler2014} and propose an extension to account for reasoning about real-world content. I then collect data measuring the prior distributions of various properties co-occurring in 4 domains: frozen fruit, expired crackers, bright lightbulbs, and sharp knives. I also collect data about 8 syllogisms using each domain's content (32 items in total). I then compare the model to the data by integrating out the parameters of the computational model and comparing alternative models using Bayesian data analytic techniques. I explore the predictions of the inferred ``best model'' and discuss future predictions. 

% Next, I plug these priors into the Bayesian model of argument strength to generate predictions for all 64 syllogisms. I compare these predictions with predictions of a model of argument strength that uses i.i.d. priors. Critically, this model will not predict content effects. I compare the predictions for the two models using a newly developed technique for optimal experiment design (OED). In Experiment 1, I collect data from 4 syllogisms are that highly ranked in the OED analysis. I compare the models and show that that the empirically elicited prior beliefs as the prior distribution for the argument strength model is the better account of the data from Experiment 1. 
%
%I then go on to investigate the interaction of pragmatics with background knowledge. I run the same OED analysis on the full pragmatics model of \citeA{Tessler2014} that uses the empirically elicited prior beliefs versus one that used \emph{i.i.d.} priors. In Experiment 2, I collect data from 4 new syllogisms that are highly ranked in the OED analysis. I compare the models and show that a strong prediction of the full pragmatics model with background knowledge is \emph{not} born out. This leads to a reconsideration of the generative model of the situations. In particular, I reflect on the recent findings of \citeA{Degen2015} that listeners reconsider world knowledge when utterances are odd. I revisit the full pragmatics model with these findings in mind, and reanalyze the data from Experiment 1 and 2. I find that the pragmatics model that is sensitive to the \emph{a priori} plausibility of the syllogism given the empirically elicited prior beliefs matches the data from Experiments 1 \& 2 the best. I end with a discussion of the implications of this model for the belief bias literature broadly. 



\section{Bayesian argument strength in syllogistic reasoning}

A formal account of gradience in syllogistic reasoning was presented by \citeA{Tessler2014}. The computational model is a Bayesian model; as such, it is important to understand the implications of the prior for syllogistic reasoning. I review the model, highlighting along the way how I generalize the model to consider content effects.

\subsection{Ontology}

The model is based on an ontology of situations composed of objects with properties, similar to mental models \cite{JL1983}. 
%
A situation $s \in S$ is composed of $n$ objects: $s = \{o_1, o_2, ..., o_n\}$, each of which can have 3 properties:
$$
s = \{ \{A_{o_{1}}, B_{o_{1}} , C_{o_{1}}\},  \{A_{o_{2}}, B_{o_{2}} , C_{o_{2}}\}, ... , \{A_{o_{n}}, B_{o_{n}} , C_{o_{n}}\} \}
$$
%
%    \begin{lstlisting}
%    (define objects (list 'o1 'o2 ... 'on))
%    \end{lstlisting}
%

Properties $A$, $B$, and $C$ of these objects are stochastic
%but persistent\footnote{This is so a given object has the same value each time it is examined, even though that property-value is initially determined probabilistically} 
and assumed to be Boolean for simplicity. 
%
Properties \emph{across} objects are assumed to be independent and identically distributed \emph{(iid)}; hence, 
%\begin{align*}
%P(A_{o_{1}}, B_{o_{1}}, C_{o_{1}})			&					= P(A_{o_{i}}, B_{o_{i}}, C_{o_{i}}) \\
%			&					= P(a, b, c)
%\end{align*}
%and 
$$P(s) = \prod_{1\leq i\leq n} P(A_{o_{i}}, B_{o_{i}}, C_{o_{i}}) = (P(a, b, c)) ^ n $$%= (P(a) \cdot P(b) \cdot P(c)) ^n$$
%
To account for syllogistic reasoning in \citeA{Chater1999}'s meta-analysis of 5 studies, which differed with respect to the materials used, the model assumed no \emph{a priori} information about the meaning of the properties; thus, properties  \emph{within} objects were determined independently and identically (\emph{i.i.d.}): $P(A_{o_{i}}, B_{o_{i}}, C_{o_{i}}) = P(A_{o_{i}}) \cdot P(B_{o_{i}}) \cdot P(C_{o_{i}}) = (P(p))^3 $, with $p \sim \text{Bernoulli(}\theta\text{)}$.

%\begin{align*}
%\text{P(}A\text{)} \sim \text{Bernoulli(}br\text{)} \\ 
%\text{P(}B\text{)} \sim \text{Bernoulli(}br\text{)} \\
%\text{P(}C\text{)} \sim \text{Bernoulli(}br\text{)}
%\end{align*}
%
%\begin{align*}
%%A_{o_{i}}, B_{o_{i}},C_{o_{i}} \sim \text{Bernoulli(}\theta\text{)} 
%p \sim \text{Bernoulli(}\theta\text{)} \\
%B_{o_{i}} \sim \text{Bernoulli(}\theta\text{)} \\
%C_{o_{i}} \sim \text{Bernoulli(}\theta\text{)}
%\end{align*}
%
%\begin{lstlisting}
%(define A (mem (lambda (x) (flip br))))
%(define B (mem (lambda (x) (flip br))))
%(define C (mem (lambda (x) (flip br))))
%\end{lstlisting}
%Note that the operator \lstinline{mem} memoizes these functions, so that a given object has the same value each time it is examined within a given situation, even though it is initially determined probabilistically (via \lstinline{flip}\footnote{For clarity, \lstinline{(flip br)} is equivalent to Bernoulli ($br$).}). 
The number of objects in a situation $n$ is a parameter of the model, as is the base rate $\theta$ of properties. In fitting the model to the meta-analysis data, \citeA{Tessler2014} found $\theta \approx 0.25$, qualitatively consistent with the ``rarity assumption''---that properties are relatively rare of objects---first used by \citeA{Oaksford1994}. The best fitting $n$ was around 5, also consistent with the ``minimal model assumption'' of the Mental Models framework \cite{JL1983}.

%\begin{lstlisting}
%(define ABC (mem (lambda (x) 
%     (multinomial (list 'ABC 'AB_ 'A_C '_BC 'A__ '_B_ '__C '___) real-world-prior))))
%\end{lstlisting}


%\subsection{Model overview and previous findings}
%
%The Bayesian model has two structural aspects to it: first, there is the computation of argument strength. This is done by computing by $P(conclusion | premises)$ by way of the \emph{situations} described above. Argument strength was shown to capture much of the quantitative variance in the syllogistic reasoning meta-analysis data.
%
%The second structural component is pragmatic, recursive reasoning about the relevance of the premises for each conclusion. This works by considering not just the strength of the syllogistic argument at hand, but also the relative strengths of alternative syllogistic arguments that could have been given but weren't. This model component was shown to be sufficient to capture qualitative phenomena that the argument strength alone could not capture. In particular, this model highlighted where deviations from literal semantics interpretation would occur (e.g. the relative preference for an \emph{all} conclusion over a \emph{some} conclusion when both are logically valid). 
%
%In this paper, I am going to consider the role of prior beliefs by focusing of the first of these model components: the generative model of argument strength.

\subsection{A generative model of argument strength}

The generative model of situations can be turned into a generative model of syllogistic reasoning by providing a semantics for the quantifier sentences of a syllogism. The model uses the interpretation of quantifier sentences as truth-functional operators, consistent with standard practice in formal semantics. 

A quantifier utterance (e.g $u_{\textrm{all \emph{A} are \emph{B}}}$) maps two properties (e.g. \emph{A} and \emph{B}) to a truth value by consulting the properties of the objects in the situation $s$ and applying the usual literal meaning. For instance:
\begin{align*}
\denote{u_{\textrm{no  \emph{A} are \emph{B}}}}= \{s \in S : \| o_A \cap o_B \| = 0\}\\ 
\denote{u_{\textrm{some  \emph{A} are \emph{B}}}}= \{s \in S: \| o_A \cap o_B \|> 0\}\\
\denote{u_{\textrm{all  \emph{A} are \emph{B}}}}= \{s \in S: \| o_A \cap o_B \| = n\}\\
\denote{u_{\textrm{not all  \emph{A} are \emph{B}}}}= \{s \in S: \| o_A \cap o_B \|< n\}
\end{align*}
%
where $o_A = \{o_i | A_{o_{i}} = 1\} $ and $o_B = \{o_i | B_{o_{i}} = 1\} $ represent the objects in a situation that have the properties $A$ and $B$, respectively.
Thus, the quantifier utterances pick out the situations $s$ where the truth-functional meaning of the utterance is satisfied. 
%
%
%\begin{lstlisting}
%(define all (lambda (A B) 
%    (all-true (map (lambda (x) (if (A x) (B x) true)) objects))))
%\end{lstlisting}
%
%The function \lstinline{map} applies the given function ---\lstinline{(lambda ...)}--- to each element of the list \lstinline{objects}. The helper function \lstinline{all-true} simply checks that all elements of a list are true, i.e. that all the \emph{As} are indeed \emph{Bs}. In a similar way, \lstinline{some}, \lstinline{none}, \lstinline{not-all} are defined to have their standard meanings. 
%

Truth-functional meanings of quantifier expressions are useful here because an expression which assigns a Boolean value to a situation can be used for probabilisitic conditioning. That is, these quantifier expressions can be used to update a prior belief distribution over situations into a posterior belief distribution: 
$$P(s \mid u_1, u_2) \propto P(s)\cdot \delta_{\denote{u_1}(s)} \cdot \delta_{\denote{u_2}(s)} $$
where $u_1, u_2$ are the two quantifier-utterances corresponding to the premises of a syllogism (e.g. $u_{\textrm{all  \emph{A} are \emph{B}}}, u_{\textrm{some  \emph{B} are not \emph{C}}}$).

For syllogistic reasoning, we are interested not in the posterior distribution over situations \emph{per se}, but the distribution on true conclusions that these situations entail: $P(u_3 \mid s)$, where $u_3$ is a quantifier-utterance corresponding to the conclusion of a syllogism (e.g. $u_{\textrm{some  \emph{A} are \emph{C}}}$). Hence,

$$
P(u_3 \mid u_1, u_2) \propto P(u_3\mid s) \cdot P(s \mid u_1, u_2)
$$
%or
%$$
%P(conclusion \mid premises) \propto P(conclusion\mid situation) \cdot P(situation \mid premises)
%$$



%In Church this looks like:
%\begin{lstlisting}
%(query
% (define objects (list 'o1 'o2 ... 'on))
% . . . define A,B,C . . .
% . . . define all, some, no, not-all . . .
% (define true-conclusions (filter (lambda (conclusion) (conclusion A C))
% 								 all-conclusions))
%
% true-conclusions
% 
% (condition	(and (premise-one A B)
%      			(premise-two B C))))
%\end{lstlisting}
%
%The first arguments to a query function comprise a generative model: the background knowledge with which a reasoning agent is endowed. Definitions for which a prior is stipulated (e.g. \lstinline{A, B, C} i.e, the situation in terms of the properties) denote aspects of the world over which the agent has uncertainty. The second argument, called the \emph{query expression}, is what the agent wants to know. The final argument, called the \emph{conditioner}, is the information with which the agent updates her beliefs; it is what she knows. 


This model, thus, returns a posterior distribution over conclusions conditioned on the premises of a syllogism being true.


The Bayesian model has a natural way of accounting for the influence of prior beliefs in reasoning. Indeed, beliefs simply specify a prior distribution over situations. In particular, the assumption that properties in a situation are independent and identically distributed \emph{(i.i.d.)} must be relaxed if we are to consider real-world content. I generalize the model by considering that properties can have correlations; the representation of expectations about the presence or absence of properties will be generalized from one marginal distribution---$P(p)=P(a)=P(b)=P(c)$---to the joint distribution: $P(a, b, c)$.

%$$
%\{A, B, C\} \sim \text{Discrete(}\alpha\text{)}
%$$


The model was written in the probabilistic programming language WebPPL\footnote{A fully-specified version of this model can be accessed at: \url{http://forestdb.org/models/syllogisms-esslli2015.html}}\cite{dippl}. For background and details on this form of model representation, see \url{http://probmods.org}.


%\begin{eqnarray}
%&&P_{argument-strength}(c|p)\propto \delta_{\denote{p}(x)} \cdot P(c|x)  \cdot P(x)  \label{eq:L0}\\ % not sure about this
%&&P_{experimenter}(p|c) \propto \mathrm{exp}({\lambda \cdot \ln P_{argument-strength}(c|p))}  \label{eq:S1}\\ 
%&&P_{pragmatic-reasoner}(c|p)\propto P_{experimenter}(p|c)\cdot P(c|x)  \cdot P(x)  \label{eq:L1}
%\end{eqnarray}
%
%Here $\denote{p}: X \rightarrow \text{Boolean}$ is a truth-function specifying the literal meaning of each set of premises. This is derived from the 
%usual literal semantics of the 4 syllogistic quantifiers applied to the situations of objects of properties. 
%
%$\denote{p_{\textrm{all of the As are Bs}}}=\forall{x}: A(x) \Rightarrow B(x)$
%
%$\denote{p_{\textrm{some of the As are Bs}}}= \exists{x}: A(x) \Rightarrow B(x)$
%
%$\denote{p_{\textrm{some of the As are not Bs}}}= \exists{x}: A(x) \Rightarrow \neg{B(x)}$
%
%$\denote{p_{\textrm{none of the As are Bs}}}= \forall{x}: A(x) \Rightarrow \neg{B(x)}$
%
%$P(x) = P(a,b,c)$ specifies the prior distribution over situations. For TG, the properties \emph{a, b, c} were assumed to be i.i.d. and hence, $P(x) = P(a, b, c) = P(a)\cdot P(b)\cdot P(c) = P(br)^3$, where \emph{br} was the base rate of properties parameter, which was fit to the data. Here, $P(x) = P(a, b, c)$ which will be measured empirically (Experiment 1). It will be used to make predictions about $P(c|p)$ to model the syllogistic reasoning data (Experiment 2). It is important to consider the joint distribution of properties and not just their respective marginal probabilities because it's likely there will be important correlations among the properties of real-world content.


%
\section{Experiment 1: Measuring $P(a, b, c)$ for real-world content}
\label{prelicit}

Bayesian models of reasoning and language typically measure the relevant prior distribution for a given task in order to generate predictions. For the model of syllogistic reasoning presented by \citeA{Tessler2014}, the natural prior to measure is the distribution over the presence and absence of the properties mentioned in the syllogism.
I constructed content domains to intuitively cover a range of probabilities.

%To achieve reliable estimates of $P(a, b, c)$, I selected causal domains  strong intuitions about causal domains. The 4 causal domains divided into two structural forms: common cause and common effect, in order to increase the variability of the domains. 

\subsubsection{Design}

I recruited 70 participants on Amazon's Mechanical Turk to rate the likelihood of various combinations of properties co-occurring. Participants were paid \$0.80 for their work.

To assess the reliability of the elicitation task, I ran the experiment using two different dependent measures as a between-subjects variable. 
Each participant was randomly assigned to either the ``frequency'' or the ``plausibility'' dependent measure condition (described below). 
Within each of these conditions, participants completed the judgment task for 4 content domains\footnote{The experiment in full can be accessed at: \url{http://stanford.edu/~mtessler/experiments/syllogism-belief-priors/prior-exp.html}}.

\subsubsection{Procedure \& Materials}

I selected property domains based on model simulations using qualitatively different priors (elicited from people in my lab). 
These preliminary simulations suggested that domains with causal structure led to the biggest differences between content domains (possibly due to the probability estimates being more reliable for causal domains). 
Table \ref{tab:domains} shows the properties used.

The prompts for the ``plausibility'' condition read: \emph{Imagine an X (e.g. a lightbulb). How likely is it that it is \_\_\_?} 
The prompts for the ``frequency'' condition read: \emph{Imagine 100 Xs (e.g. lightbulbs). About how many of them are \_\_\_?}
Below these prompts were listed the 8 possible combinations of the presence and absence of 3 properties (e.g. \emph{is on}, \emph{is bright}, and \emph{is hot}). Next to each set of properties, was a slider bar.
In the plausibility condition, the slider bar ranged from ``Impossible'' to ``Certain'', with intermediate arrows pointing to the left and right indicating ``less likely'' and ``more likely''. In the frequency condition, the slider bar ranged from ``0'' to ``100'', with intermediate arrows pointing to the left and right indicated ``fewer'' and ``more''. 


\begin{table}
\centering
\tabcolsep=0.11cm
\begin{tabular}{ |c|c|c|c|c|c }
%\small
\hline
\multicolumn{5}{ |c| }{Experiment 1 Domains} \\
\hline
Noun & Causal relation & Property A & Property B & Property C  \\ \hline
%\multirow{4}{*}{Defenders} & LB & Lucus Radebe \\
crackers & common effect & are soggy & are past expiration date & have lots of flavor  \\ \hline
knives & common effect & are sharp & are rusty & cut well  \\ \hline
lightbulbs & common cause & are on & are bright & are hot  \\ \hline
strawberries & common cause & are in the freezer & are soft & are warm  \\ \hline
\end{tabular}
\caption{Content domains used in experiments.}
\label{tab:domains}
\end{table}


\subsubsection{Data analysis and results}

Participants' responses were normalized within each domain so that the ratings for the 8 property combinations made a well-formed probability distribution (i.e. they added up to 1). I then took the mean rating for each of the 8 property combinations in each of the 4 domains, to arrive at mean empirical priors for all 4 domains. These were used as the empirical $P(a,b,c)$ for the Bayesian model. 

The experiment elicited unique priors for each domain (see Figure \ref{fig:priors}). The data elicited with different dependent measures were highly correlated ($r_{pearson} = 0.78; \\ r_{spearman} = 0.85$). Though the correlation between the prior data elicited by different dependent measures is good, the data set as a whole was substantially more reliable (95\% bootstrapped CI for $r_{split-half} = [0.95, 0.98]$), suggesting meaningful differences between the two measurements. At the same time, model predictions based on the different dependent measures were also substantially more reliable ($r_{pearson} = 0.95$). This suggests that the prior elicitation task captured the relevant variance for the syllogistic reasoning model. For simplicity, I later present the predictions of the reasoning model based on collapsing the prior elicitation ratings across dependent measures, though predictions based on either dependent measure alone are not meaningfully different.


\begin{figure}
\centering
    \includegraphics[width=\columnwidth]{figures/priors.pdf}
    \caption{Mean elicited priors collapsed across dependent measure (see text for details). Error bars denote 95\% confidence intervals. X-axis shows presence or absence of each property, the ordering of which can be found in Table \ref{tab:domains}. For example, the tallest bar in the cracker domain (001) is a cracker which isn't soggy, isn't past expiration date, and has lots of flavors.}
  \label{fig:priors}
\end{figure}






%$P(\delta_{\denote{c}(x)})$ is used because the model of argument strength isn't given a conclusion, but rather \emph{generates} a conclusion according to the prior distribution over situations. $P(\delta_{\denote{c}(x)})$ ensure that a conclusion wihich is true of the 


%For concreteness, assume that the number of objects in a situation is 4. The relevant number of objects that satisfy the a premise will depend on that particular premise. For example, \emph{All of the grey elephants are herbivores} is true if all of the elephants that are grey in the particular situation are also herbivores\footnote{N.B. I use the ``of the'' construction to make clear that I am describing a particular situation of elephants and not elephants in general.}. The model is given some number of elephants: in our example, 4. The model then samples properties \emph{grey, herbivore} according to the joint prior distribution of these properties $P(x) = P(g,h)$. Depending on the prior probabilities of $g$, a given situation may have 0, 1, 2, 3, or 4 grey elephants. The premise that \emph{All of the grey elephants are herbivores} is evaluated with respect to the number of grey elephants in that situation. If there are 3 grey elephants, then $\denote{\emph{All of the grey elephants are herbivores}]}: \forall{x}, g(x) \Rightarrow h(x)$

%and $S = \{s_0, s_1, s_2, \dots, s_{4}\}$, where the subscript indicates the number of objects (e.g., marbles) that exhibit an effect (e.g., sinking). 
%Further assume that the set of utterances \emph{All/None/Some of the marbles sank} is denoted $U = \{u_{\textrm{all}}, u_{\textrm{none}}, u_{\textrm{some}}\}$ and each has its usual literal meaning: 
%%$\denote{u_{\textrm{none}}}: s=0$,  
%%$\denote{u_{\textrm{some}}}: s>0$,
%%$\denote{u_{\textrm{all}}}: s=15$.
%$\denote{u_{\textrm{none}}}= \{s_i | i = 0\}$,  
%$\denote{u_{\textrm{some}}}= \{s_i | i > 0\}$,
%$\denote{u_{\textrm{all}}}= \{s_i | i = 15\}$.



\section{Experiment 2: Syllogistic reasoning about real world content}


%In a preliminary experiment, I recruited 70 participants from Amazon's Mechanical Turk to judge the likelihood of various combinations of properties co-occurring. 
%I selected property domains based on model simulations using qualitatively different priors (elicited from people in my lab). These preliminary simulations suggested that domains with causal structure led to the biggest differences between predictions of alternative models of theoretical interest (introduced more fully in Section \ref{sec:models}). Table \ref{tab:domains} shows the properties used.
%The resulting empirical priors from that preliminary experiment are shown in the \ref{fig:priors}. 




In this experiment, I tested if the real world content from Experiment 1 influenced the conclusions drawn from categorical syllogisms. 

\subsubsection{Design}

I recruited 254 participants from Amazon's Mechanical Turk. All participants were required to have a 95\% approval rating for their previous work on the web service. Participants were paid \$0.60 for their work. Each syllogism was paired with each domain used in Experiment 1. A total of 8 syllogisms were used, resulting in 32 unique \{syllogism, domain\} pairs.

\subsubsection{Procedures \& Materials}

Each participant completed 4 syllogisms. On each experimental trial, participants were presented with the syllogism (e.g. \emph{Some of the lightbulbs that are bright are on. None of the lightbulbs that are hot are bright.}) and each possible conclusion (e.g. \emph{\{All, Some, Not all, None\} of the lightbulbs that are hot are on.}) and asked \emph{Does it follow that: X}, for each conclusion. Radio buttons with the options ``Doesn't follow'' and ``Follows'' were provided. Below that was a vertically-oriented slider bar with endpoints labeled ``Certain'' and ``Don't know'' to measure confidence. Participants were required to mark each conclusion before continuing to the next trial\footnote{The experiment in full can be viewed at \url{http://stanford.edu/~mtessler/experiments/syllogism-belief/syllbelief-exp2.html}}.


%\begin{quotation}
%If you think the conclusion follows from the argument, indicate so. Adjust the position of the slider bar to reflect your confidence in your response.
%\end{quotation}


\subsubsection{Results}

Shown in Figure \ref{fig:syllogismXdomain} (lighter bars) are a subset of the results of the experiment. Content effects can be observed by comparing panels within a row (i.e. comparing across columns). For example, for the \emph{some / none} syllogism (top row), the proportion of responses endorsing  ``Some of the lightbulbs that are hot are on'' is appreciably higher than the proportion endorsing ``Some of the crackers that have lots of flavor are soggy'' ( 2nd row, columns 1 \& 3; \emph{some} conclusion). Effects of reasoning (i.e. of syllogism) can be observed by comparing panels within a column (i.e comparing down rows). For example, ``Some of the crackers that have lots of flavor are soggy'' is a substantially more endorsed conclusion if the premises are: ``All of the crackers that are past expiration date are soggy. Some of the crackers that have lots of flavor are past expiration date.'' (4th column, rows 1 \& 2; \emph{some} conclusion). 


\begin{figure}
\centering
    \includegraphics[width=\columnwidth]{figures/bars_bw.pdf}
    \caption{Reasoning patterns and predictions for 3 (of the 8) syllogisms in the experiment. Human reasoning data is in the darkest shade. The lighter shade is the 12-parameter (``independent'') model. The medium shade is the 0-parameter (``empirical prior'') model. All syllogisms shown here were of the form B-A / C-B and the conclusions were of the form C-A (e.g. First row: All B are A, Some C are B). Reasoning effects can be seen by comparing rows within a column. Content effects can be seen by comparing columns within a row.}
  \label{fig:syllogismXdomain}
\end{figure}




\section{Bayesian analysis of Bayesian reasoning models}
\label{sec:models}

%I compared the predictions of the TG model of argument strength using the priors elicited in the preliminary experiment to the syllogistic reasoning data. 

In this section, I explore 4 different models of argument strength that vary in their independence assumptions in the prior\footnote{For all of the models I consider, properties are assumed to be independent \emph{across} objects (e.g. $o_1$ having property A does not influence $o_2$'s chance of having property A). It is the assumption of independence \emph{within} objects that is explored in this paper.}. The first model---the ``abstract'' model---uses a single base-rate parameter in its prior\footnote{This is the model of argument strength used by \citeA{Tessler2014} to model meta-analysis data.}; this model assumes properties are \emph{i.i.d.} both within domains and across domains. The second model---the ``within-\emph{i.i.d.}'' model---is the simplest parametrized model that can predict content effects; it is identical to the first model except in that the base-rate parameter can vary across domains (but not within a domain; hence it is \emph{i.i.d.} within but not across domains). This model has 4 parameters (one base-rate for each domain). The third model---the ``fully independent'' model---assumes only that properties of an object are independent (not necessarily identically distributed); it uses a different base-rate parameter for each property within and across domains. This model has 12 parameters (3 properties per domain and 4 domains in total). The final model is a model that uses the empirically elicited priors from Expt.~1; this model has no free variables parametrizing the prior over properties. 

One parameter is shared by all models. This is the number of objects in a situation $n$, which controls the size of the worlds reasoned over. A preliminary analysis revealed that results were highly consistent for $n \geq 4$ and so I use $n=4$ for all simulations.  

I analyze the models by putting uninformative priors ($\theta \thicksim \textrm{Uniform}(0,1)$) on the base-rate parameter(s) and conditioning on the observed experimental data. 
In addition, for all models I include a single data analytic ``guessing'' parameter $\phi \thicksim \textrm{Uniform}(0,1)$ to account for response noise. This noise parameter is important to accommodate data points that deviate largely from what the reasoning model predicts\footnote{In some cases, this parameter is actually \emph{necessary} to analyze the data. This is the case with logically impossible conclusions (e.g. \emph{All A are B // All B are C} $\therefore$ \emph{No A are C}); in this case, the reasoning model gives this conclusion probability 0 (i.e. \emph{logically impossible} means probability 0). If, for whatever reason, the experimental data includes this conclusion as a response, the data analysis model will crash because that particular data point is expected to have probability 0. The guessing parameter lets us accommodate any data point. 
This is done by postulating that with $\phi$ probability, the participant selects a conclusion at random. I put a distribution over the probability and infer this value from the experimental data. 
}. 

%There are two parameters to the model. The first is an optimality or rationality parameter. TG takes the probabilities to represent actual persons in a communicative setting, and so conclusions or premises are selected from these distributions according to a Luce choice, or softmax, decision rule with a parameter $\lambda$ that denotes the degree to which utterances are chosen optimally \cite{Luce1959}. This is one of the parameters of the model. 
%
%I put a uniform prior over the optimality parameter $\lambda \thicksim U(0,5)$.

Inference for the combined Bayesian data analysis of the Bayesian reasoning model was done via the Metropolis-Hastings algorithm implemented in the probabilistic programming language WebPPL \cite{dippl}. Models were analyzed independently, and MCMC chains were run for 10,000 samples.

\subsection{Posteriors over model parameters}

%Base rate parameters had a uniform prior distribution over them: $br \thicksim U(0,1)$. 
 The posterior value for $\phi$, the guessing variable, was near 0.25 for all models; this analysis attributes about a quarter of the responses to noise. Note that this estimate of noise is with respect to the reasoning model. In other words, it is an estimate of the proportion of responses better explained by random guessing than by the reasoning model. If the posterior predictive distribution of the model predicts the data well, $\phi$ would be an accurate measure of the response noise in the syllogistic reasoning task. Alternatively, $\phi$ could also include aspects of the data set that these particular reasoning models do not predict well.
 
 One hypothesis about the base rate parameters of the parametrized-prior models is that the parameter values that account best for the reasoning data are lower-order representations of the empirically-elicited prior. 
 To test this, I compared the posterior distributions over the base rate parameters of the 12-parameter, ``fully independent'' model to the marginal distributions of the empirical prior data (Figure \ref{fig:postbr}). 
 For the properties corresponding the conclusion terms of the syllogism (properties A \& C), the inferred base-rates based on the 12-parameter model are qualitatively consistent with the marginal distributions from Experiment 1. 
 For example, the most likely base rates for property A for the cracker and strawberry domains are definitively smaller than those of the knife and lightbulb domains (Figure \ref{fig:postbr}, column 1, rows 1 \& 4 vs. rows 2 \& 3). 
 As well, the most likely base rate for property C of the strawberry domain is smaller than the other 3 domains. 
 The inferred base rates from the 12-parameter model have the most uncertainty about property B, possibly because B is only indirectly related to the responses, which are statements about properties A \& C. 
 Overall, this is suggestive evidence that the parametrized model of argument strength is using base rates corresponding to those of the marginal distributions over properties elicited in Expt.~1.

\begin{figure}
\centering
    \includegraphics[width=\columnwidth]{figures/posterior_brs.pdf}
    \caption{Marginal posterior distributions over the base rates of properties in the 12-parameter, fully independent model. 95\% CIs for the marginal distributions derived from the empirical priors elicited in Experiment 1 are shown at the top of each plot. Qualitative consistencies between the two suggest the base rates inferred from the reasoning data resemble lower-order statistics (the marginal distributions) of the richer joint-distributions shown in Figure \ref{fig:priors}.}
  \label{fig:postbr}
\end{figure}





\subsection{Posterior predictives}

\begin{table}[h]
\centering
\begin{tabular}{@{}|c|c|c|c|@{}}
Model       & free parameters for priors & other free parameters & correlation with data \\
\midrule
abstract    & 1                          & 1                     & 0.81                  \\
within-\emph{iid}         & 4                          & 1                     & 0.86                  \\
fully independent & 12                         & 1                     & 0.90                  \\
empirical   & 0                          & 1                     & 0.87                 
\end{tabular}
\caption{Modeling results.}
\label{tab:results}
\end{table}



The posterior predictive distribution marginalizes over the inferred parameter values to produce predictions about what the data should look like given the posited reasoning model and the observed data. This is akin to fitting the parameters and is an important step in model validation as it shows what data is actually predicted by the model. All of the models did considerably well in accounting for the variance in the syllogistic reasoning data. Table \ref{tab:results} shows the model--data correlations for each of the models. Figure \ref{fig:scatterplot} shows the fit for the empirical prior model.


\begin{figure}
\centering
    \includegraphics[width=0.7\columnwidth]{figures/scatterplot_bw.pdf}
    \caption{Data vs. (empirical prior) Model plot. The model provides a good overall fit ($r=0.87$) to the 128 data points (32 syllogism, domain pairs X 4 conclusions each). The posterior predictions bottom out around 0.07. This is the work of the ``guessing'' parameter $\phi$.}
  \label{fig:scatterplot}
\end{figure}


Figure \ref{fig:syllogismXdomain} shows predictions for the empirical prior model (darker shade) together with the experimental data (lighter shade) for 3 example syllogisms. 
The model based on the empirical prior shows effects of content. 
For example, the knives and lightbulbs domains show lower endorsements for the \emph{not all} conclusion relative to the crackers and strawberries domains (and the reverse can be observed for the \emph{all} conclusion), consistent with participants' reasoning behavior (Figure \ref{fig:syllogismXdomain}, row 1: columns 2 \& 3 vs. 1 \& 4, \emph{not all} conclusion). 
%
In addition, the model shows effects of reasoning. For example, the endorsement for the \emph{some} conclusion is much higher for the \emph{all / some} premises than for the \emph{some / none} premises, also consistent with the experimental data (Figure \ref{fig:syllogismXdomain}, column 3: rows 1 vs. 2, \emph{some} conclusion). 
Further, an interaction between content and reasoning can be observed by comparing the lightbulb domain to the knife domain for those same syllogisms (columns 3 vs. 2 X rows 1 vs. 2). In the knife domain, the experimental data shows the effects of the syllogism are much weaker (the light bars are not very different from one another). The model predictions are also very similar for these two syllogisms in the knife domain.
%


Finally, it's worth drawing attention to the bottom row of Figure \ref{fig:syllogismXdomain}, the \emph{all / all} syllogism. This is a valid syllogism (a maximally strong argument) with two logically valid conclusions: \emph{all} and \emph{some}. Participants show a consistent preference for the \emph{all} conclusion over the \emph{some} conclusion, consistent with many other studies of syllogistic reasoning \cite{Khemlani2012}. It's interesting that this asymmetry is robust across the different content domains. The model predicts consistent responses across the content domains because the syllogistic argument is so strong. However, it has no way to capture the asymmetry between \emph{all} and \emph{some} because it is using only a truth-functional semantics (\emph{all} entails \emph{some}). 
\citeA{Tessler2014} predicted this asymmetry by extending to the model to take into account pragmatic reasoning.
%
I leave for future work the incorporation of pragmatic reasoning with syllogistic arguments about real-world content. 

%To address the relevance of background knowledge in syllogistic reasoning, I performed a Bayesian model comparison between two models of argument strength: one with empirical priors and one completely abstract priors. The model without the empirical priors has an additional single parameter representing the base rate of properties  $br \thicksim \beta(1,1)$.
%
%I put a uniform prior over the two models. Inference was done via the Metropolis-Hastings algorithm implemented in the probabilistic programming language WebPPL \cite{dippl}. The posterior probability of the model uses the empirical prior was \red{X}. This suggests that it's highly likely that incorporating structured background knowledge into the model of syllogistic is necessary to capture human reasoning patterns.

%To address the question of whether or not pragmatic (or, recursive) reasoning is still a necessary component of the model after accounting for background knowledge in the appropriate way, I compared the model of argument strength with the empirical prior with the model of pragmatic syllogistic reasoning with the empirical prior. 
%
%I put a uniform prior over the two models. The posterior probability of the model that takes does pragmatic reasoning over an empirical prior was 0.984. This suggests that it's highly likely that this is a better model of the data than the model of argument strength. 

%\subsection{Posterior predictives}
%
%The model of syllogistic reasoning that uses the empirical priors was the most likely model in this space of models given this data. T
%
%The overall correlation between the posterior predictive and the human data was \red{$r = ?$} (Figure \ref{fig:scatterplot}). The model captures many of the qualitative patterns in the reasoning data, as well (Figure \ref{fig:syllogismXdomain}). 

%For example, with premises ``All B are A, All C are B'', participants reliably have a preference for ``All C are A'' over the equally valid ``Some C are A''. 
%
%This cannot be accounted for by the model of argument strength since it uses literal semantics only. The pragmatic model, however, can capture this phenomenon, which is relatively invariant to the content effects.




\section{Discussion}

I have demonstrated that a model of syllogistic reasoning with a rich prior distribution can account for the flexibility of interpretation of a syllogistic argument with real world content. The phenomenon of ``belief bias'' can be viewed in this framework as a natural extension of the notion of ``argument strength''. Arguments vary in strength depending on the prior distribution of the properties in question. 


This modeling work reveals that the empirical prior model predicts the data well. Using Bayesian data analytic techniques, I observed that the 4-parameter ``within-\emph{iid}'' model and the 12-parameter ``fully independent'' model can also accommodate the content effects well. I say the models \emph{accomodate} the data because their predictions are dependent on the particular parameter settings inferred \emph{from that data}. The empirical prior model, by contrast, predicts the data with no parameter fitting. Additionally, it's likely that performing a formal, Bayesian model comparison between these models would favor the empirical prior model due to Bayes' Occam's Razor. However, it is interesting to consider the implications of these modeling results as they stand. 

The 4-parameter ``within-\emph{iid}'' model is the simplest model that could possibly account for content effects. What this model posits is that there is some difference in the base rates of properties in these four different domains. In terms of cognition, this might mean that our artificial domains (e.g. knives that could be sharp, rusty, and/or that cut well) call to mind a general intuition about the base rate of these properties, and that this general base rate enters into the computation of argument strength. The posterior over base rate parameters for this model is consistent with this explanation: base rates for domains with properties that tended to co-occur (e.g. the lightbulbs domain) were relatively high while those for domains with properties that tended \emph{not} to co-occur (e.g. the crackers domain) were low.
The 12-parameter ``fully independent'' model also accommodates the data well. This model posits that properties in a given domain are independent but differ in their base rates. Correlations between properties need not be tracked explicitly. 

An alternative explanation for the ubiquitous good fits is that the experiment itself is confounded. 
The 8 syllogisms used in my experiment might not be the best syllogisms to distinguish models with subtly different independence assumptions about the priors over properties. 
I found that the most likely base rate parameter values for the parametrized prior models given the data from Expt.~2 were those that roughly corresponded to the marginal distributions of properties from Expt.~1. 
Both models (parametrized priors and empirical priors) modeled the data equally well, suggesting that these experiments were not well suited to disambiguate them.
An even more radical proposal is that categorical syllogistic reasoning \emph{in general} is not the best kind of experiment to distinguish these models. 
In categorical syllogisms, there are only 3 logical possibilities for conclusions entailed by situations: \emph{all}, \emph{some and not all}, or \emph{none}. 
It's possible that these models would make different predictions if we allowed more possible responses, e.g. \emph{most} and \emph{few}, exact numbers.

Finally, it is worth noting that classical reasoning experiments such as the one explored here use language to communicate information for participants to reason over. Basic communicative principles, however, are often ignored in the scientist's analysis of behavior. \citeA{Tessler2014} formalized basic communicative principles in their probabilistic pragmatics model of syllogistic reasoning, as an extension of the Rational Speech-Act theory of language understanding. I leave for future work the interplay between pragmatics and prior beliefs in the syllogistic domain. 



%This work highlights the importance of taking into account these communicative principles as well how prior beliefs are integrated into the reasoning process. Recent work has demonstrated how violations of these communicative principles can result in behavior inconsistent with rational models of communication \cite{Degen2015submitted}. Further work will investigate how and where rational integration of prior beliefs breaks 

%\subsection{Wonky worlds?}
%\section{Conclusion}

\bibliographystyle{apacite}
\small{
\bibliography{belief}}

\end{document}
