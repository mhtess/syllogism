\documentclass[floatsintext, doc]{apa6}
%\bibliography{references}
\usepackage{apacite}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{xspace}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{tikz}
%\usepackage[sc,osf]{mathpazo}
%\linespread{1.12}
\usepackage{booktabs}
\usepackage{centernot}

% these packages are needed to insert results 
% obtained from R into the LaTeX document
\usepackage{pgfplotstable}
\usepackage{csvsimple}
\usepackage{siunitx}

% set the name of the folder in which the CSV files with 
% information from R is stored
\newcommand{\datafoldername}{csv_to_tex}


%\makeatletter
%    \let\@internalcite\cite
%    \def\cite{\def\citeauthoryear##1##2{##1, ##2}\@internalcite}
%    \def\shortcite{\def\citeauthoryear##1{##2}\@internalcite}
%    \def\@biblabel#1{\def\citeauthoryear##1##2{##1, ##2}[#1]\hfill}
%\makeatother


% the following code defines the convenience functions
% as described in the main text below

% rlgetvalue returns whatever is the in cell of the CSV file
% be it string or number; it does not format anything
\newcommand{\rlgetvalue}[4]{\csvreader[filter strcmp={\mykey}{#3},
             late after line = {{,}\ }, late after last line = {{}}]
            {\datafoldername/#1}{#2=\mykey,#4=\myvalue}{\myvalue}}

% rlgetvariable is a shortcut for a specific CSV file (myvars.csv) in which
% individual variables that do not belong to a larger chunk can be stored
\newcommand{\rlgetvariable}[1]{\csvreader[]{\datafoldername/myvars.csv}{#1=\myvar}{\myvar}\xspace}

% rlnum format a decimal number
\newcommand{\rlnum}[2]{\num[output-decimal-marker={.},
                             exponent-product = \cdot,
                             round-mode=places,
                             round-precision=#2,
                             group-digits=false]{#1}}

\newcommand{\rlnumsci}[2]{\num[output-decimal-marker={.},
                          scientific-notation = true,
                             exponent-product = \cdot,
                             round-mode=places,
                             round-precision=#2,
                             group-digits=false]{#1}}

\newcommand{\rlgetnum}[5]{\csvreader[filter strcmp={\mykey}{#3},
             late after line = {{,}\ }, late after last line = {{}}]
            {\datafoldername/#1}{#2=\mykey,#4=\myvalue}{\rlnum{\myvalue}{#5}}}

\newcommand{\rlgetnumsci}[5]{\csvreader[filter strcmp={\mykey}{#3},
             late after line = {{,}\ }, late after last line = {{}}]
            {\datafoldername/#1}{#2=\mykey,#4=\myvalue}{\rlnumsci{\myvalue}{#5}}}



\makeatletter
\patchcmd{\epigraph}{\@epitext{#1}}{\itshape\@epitext{#1}}{}{}
\makeatother \def\signed
#1{{\leavevmode\unskip\nobreak\hfil\penalty50\hskip2em
\hbox{}\nobreak\hfil#1% \parfillskip=0pt \finalhyphendemerits=0
\endgraf}} \newsavebox\mybox 

\newenvironment{aquote}[1]
{\savebox\mybox{#1}\begin{quote}} {\signed{\usebox\mybox}\end{quote}}

%\newcommand{\HRule}{\rule{\linewidth}{0.2mm}}



\title{Probabilistic Pragmatics in Syllogistic Reasoning}
\shorttitle{Pragmatics in Syllogistic Reasoning}

\author{Michael Henry Tessler\textsuperscript{1}\textsuperscript{,2}, Joshua B. Tenenbaum\textsuperscript{1}~\& Noah D. Goodman\textsuperscript{2}}
\date{}
  
\affiliation{
\vspace{0.5cm}
\textsuperscript{1} Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology \\
\textsuperscript{2} Department of Psychology, Stanford University
}
%\authorsnames[{1,2},1,2]{Michael Henry Tessler, Joshua B. Tenenbaum, Noah D. Goodman}
%\authorsaffiliations{{Department of Brain and Cognitive Sciences, MIT}, {Department of Psychology, Stanford University}}

\date{}

\usepackage{xcolor}
\usepackage{bbm}

\newcommand{\denote}[1]{\mbox{ $[\![ #1 ]\!]$}}
\newcommand*\diff{\mathop{}\!\mathrm{d}}
\definecolor{Red}{RGB}{255,0,0}
\definecolor{Green}{RGB}{10,200,100}
\definecolor{Blue}{RGB}{10,100,200}

\newcommand{\mht}[1]{{\textcolor{Blue}{[mht: #1]}}}
\newcommand{\ndg}[1]{{\textcolor{Green}{[ndg: #1]}}}
\newcommand{\red}[1]{{\textcolor{Red}{#1}}}

\authornote{Corresponding author: Michael Henry Tessler,  Department of Brain and Cognitive Sciences, Building 46, Room 3027,	Massachusetts Institute of Technology, 77 Massachusetts Avenue, Cambridge, MA 02139-4307, USA; tessler@mit.edu}

\abstract{
Syllogistic reasoning lies at the intriguing intersection of natural and formal reasoning, of language and logic. 
Syllogisms comprise a formal system of reasoning yet make use of natural language quantifiers (e.g., \emph{all}, \emph{some}), and invite natural language conclusions. 
The conclusions people tend to draw from syllogisms deviate substantially from a purely logical perspective. 
Is natural language to blame?
%How can we make sense of the interplay between logic and language? 
\mht{from old abstract:: 
We develop a computational-level theory that considers reasoning over concrete situations, constructed probabilistically by sampling. The base model can be enriched to consider the pragmatics of natural language arguments. The model predictions are compared with behavioral data from a recent meta-analysis. The flexibility of the model is then explored in a data set of syllogisms using the generalized quantifiers most and few. We conclude by relating our model to two extant theories of syllogistic reasoning – Mental Models and Probability Heuristics.}}


\begin{document}
\maketitle


\begin{aquote}{\textbf{Walter J. Ong}, \emph{Orality and Literacy} (1982)}The syllogism is like a text: fixed, boxed-off, isolated... The riddle [by contrast] belongs in the oral world. To solve a riddle, canniness is needed: one draws on knowledge, often deeply subconscious, beyond the words themselves in the riddle. \end{aquote}

%\HRule

\section{Introduction}


Imagine that your friend tells you: ``Everyone in my office has the flu and, you know, some people with this flu are out for weeks.''
You might respond: ``I hope your officemates are not out for weeks and I hope you don’t get sick either.''
The form of this exchange resembles a syllogism: a two-sentence argument used to relate two properties (or terms: A, C) via a middle term (B). 
Fit into a formal syllogistic form, this argument would read:

\begin{enumerate}
\item \emph{All} officemates are out with the flu (All As are Bs)
\item \emph{Some} people out with the flu are out for weeks (Some Bs are Cs) 
\item Therefore, \emph{some} officemates are out for weeks (Some As are Cs)
\end{enumerate}


The relations used in classical Aristotelean syllogisms are quantifiers: \emph{all}, \emph{some}, \emph{some .... are not}, and \emph{none}. 
The logical space defined by classical syllogisms is comprised of all combinations of quantifiers and term orders for the premises: \textsc{quantifier} \textsc{A} -- \textsc{B} vs. \textsc{quantifier} \textsc{B} -- \textsc{A}.
In total, each premise can be appear with one of the four quantifiers and two term orders and there are two premises yielding:  $4$ quantifiers  $\times 2$ term orderings $\times 2$ premises = 64 syllogisms.
Only 27 of the 64 unique syllogistic premises yield a logically valid conclusion (i.e., a conclusion that is true in every situation in which the premises are true).
For logically invalid syllogisms, the appropriate logical response is to say \emph{nothing follows} from the premises (or, \emph{no valid conclusion}), yet participants readily endorse substantive conclusions for logically invalid syllogisms. 
For example, the syllogism above is not logically valid.  (Consider that it could be only non-officemates with the flu that are out for weeks. In that case, the premises would be true and the conclusion false.)
%In fact, within the confines of the classical syllogism, there is no conclusion about the relation between A \& C that is true in every situation in which the premises are true. 
The conclusion above seems reasonable, however, and roughly 70\% of participants will assert that the \emph{Some As are Cs} conclusion follows from the premises  \cite{Khemlani2012}.
Even for valid arguments, the accuracy of producing valid conclusions ranges from 90\% to 1\%: people do not seem to find drawing deductively valid conclusions particularly straightforward.

%Faced with such an argument, however, people are perfectly comfortable drawing some conclusion. 
%A meta-analysis of syllogistic reasoning showed that over the population, the proper production of no valid conclusion responses for invalid arguments ranged from 76\% to 12\%. 

Many theories of syllogistic reasoning take deduction as a given and try to explain reasoning errors as a matter of noise during cognition. 
Errors, then, may arise from improper use of deductive rules \cite{rips1994, geurts2003reasoning} or biased construction of logical models \cite{JL1984, Newstead1992}. 
Many other kinds of reasoning, however, can be well-explained as probabilistic inference under uncertainty \cite{tenenbaum2006theory}. 
Probability theory provides a natural description of a world in which you don’t know exactly how many people are in your office are going to get the flu.

A separate dimension of theories of human reasoning concerns the extent to which principles of natural language — semantics and pragmatics — are necessary for understanding reasoning tasks. 
Natural language semantics plays a role in many such theories of reasoning \cite{JL1978, Khemlani2012, geurts2003reasoning}, though how issues of informativeness or relevance impact syllogistic reasoning either remain unclear \cite{Roberts2001} or are posited in an ad-hoc manner \cite{Chater1999}. 

In this paper, we explore the idea that the formalism of probabilistic pragmatics can provide insight into how people reason with syllogisms.
We present a model in the Rational Speech Act framework (Frank \& Goodman, 2012; Goodman \& Frank, 2016) that reasons about multiple quantifier sentences to produce a distribution over conclusions that follow from those sentences. We present three sets of results, highlighting the influence of different components of the model on human reasoning: (1) the influence of prior beliefs; (2) flexibility in natural language semantics, incorporating generalized quantifiers (e.g., “most” and “few”); and (3) pragmatic rea- soning. Previous approaches to the pragmatics of syllogistic reasoning have reduced the interpretations of syllogistic arguments to the interpretations of the individual premises or quantifiers used in those premises \cite{Roberts2001}. For example, premises involving the quantifier “some” may be interpreted as implying some but not all. But that sort of reasoning will not produce the conclusion in the syllogism above. Instead, what is needed is a richer scope of pragmatic reasoning: Reasoning about why about the speaker constructed the argument as a whole. We formalize this notion as a Question Under Discussion (C. Roberts, 2004) in which a listener reasons about the most likely conclusion (i.e., A–C relation) given the premises heard. We find that this formulation of pragmatic reasoning is able to break critical symmetries that would result from logical reasoning (Figure 1). An early version of this model was presented by Tessler and Goodman (2014).


%Cognitive theories of human reasoning turn along the critical dimension of whether the core ideal of reasoning is deductive validity or probabilistic support. 
%
%
%This cartoon illustrates a critical dimension along which cognitive theories of reason- ing differ: whether the core and ideal of reasoning is deduc- tive validity or probabilistic support. 
%
%
%An important extension to baseline CPT frameworks concerns incorporating pragmatics and language-like properties (such as compositionality) and representations in probabilistic inference. The probabilistic programming language (PPL) / probabilistic language of thought (PLoT) can more naturally apply to richer forms of reasoning, including everyday reasoning under uncertainty (e.g., Goodman et al., 2015). Furthermore, enriching these models with an understanding of natural language pragmatics can explain apparent fallacies in classical reasoning tasks (e.g., Tessler \& Goodman, 2014). Assuming a communicative context to a task involving language allows a reasoner in a PPL/PLoT model to incorporate the goals of a speaker (e.g., assuming the speaker intends to be informative), so providing a rational perspective on reasoning fallacies. We will also consider the way resource limitations guide practical models in PPL.
%
%
%
%
%By formalizing syllogistic reasoning as a probabilistic pragmatics problem, there is a natural way to account for influence of background knowledge in the form of the prior distribution on possible situations. We construct domains where we expect correlations between properties (e.g., knives – being sharp – cut well) and investigate syllogistic reasoning over these content domains. By measuring the prior probability of the eight possible combinations of binary features, we are able to generate predictions for syllogistic reasoning problems that are influenced by this kind of prior knowledge. Such influence of background knowledge on reasoning, known as belief bias in the syllogistic reasoning domain, has been of interest to psychologists for quite some time (e.g., Evans, Handley, \& Pollard, 1983; Dube, Rotello, \& Heit, 2010). We formalize this “bias” as rational belief updating given prior knowledge and find that the pragmatics model is too influenced by these kind of prior beliefs (Figure 2).


\section{Computational Model}

%\section{Bayesian argument strength in syllogistic reasoning}

Syllogistic reasoning involves two language understanding tasks: interpreting the premises of the syllogism and producing a conclusion.
Each of these components could involve some kind of pragmatic reasoning.
Our model uses recursive Bayesian reasoning that grounds out in a literal listener model who updates their beliefs about the state of the world given the literal (logical) meaning of the utterances. 
We walk through our ontology of the state space and the literal meanings before describing the different models of premise interpretation and conclusion production. 


\subsection{Ontology and semantics}

The model is based on an ontology of situations represented by Venn diagrams corresponding to all possible logical relations between the sets of three properties: A, B, C. 

\begin{figure}[h]
\centering
\begin{tikzpicture}[fill=gray]
% left hand
%\scope
%\clip (-2,-2) rectangle (2,2)
%      (1,0) circle (1);
%\fill (0,0) circle (1);
%\endscope
% right hand
%\scope
%\clip (-2,-2) rectangle (2,2)
%      (0,0) circle (1);
%\fill (1,0) circle (1);
%\endscope
% outline
\draw (0,0) circle (1) (-0.5,0.25)  node [text=black,above] {$A$}
      (1,0) circle (1) (1.5, 0.25)  node [text=black,above] {$B$}
      (0.5,-1) circle (1) (0.5,-1.25)  node [text=black,below] {$C$}
      (-1.5,-2.25) rectangle (2.5,1.25) node [text=black,above] {};
\end{tikzpicture}
\label{fig:venn}
\caption{A state is represented by Boolean values over the regions of a Venn diagram, corresponding to the presence or absence of unique object types.}
\end{figure}

Each Venn diagram contains eight regions $i \in R$, corresponding to the presence or absence of each of the three properties: $\{\{A,B,C\},$ $\{A,B,\neg C\},$ $\{A,\neg B,C\},$ $\{\neg A, B, C\},$ $\{A, \neg B, \neg C\},...\}$. (For simplicity, when possible, we will refer to regions by the properties that are present, omitting the absent properties; for example, $\{A, B, \neg C\}$ will be referred to as $AB$.)
These regions can be thought of as unique object types (e.g., an object defined by having properties $A$ and $B$ but not $C$.\footnote{This diagram representation is analogous to a mental model in the style of \citeA{johnson1983mental} composed of object tokens (e.g., some objects which have properties $A$ or $B$, etc.) but where only unique object tokens are represented (e.g., there cannot be two objects which have the same set of properties).}
The empty region (or, the object type which has neither of the three properties: $\{\neg A, \neg B, \neg C\}$) does not impact the truth conditions of the quantifier sentences used in syllogisms, and hence, we omit this region and model only seven regions.
Then, a situation (Venn diagram) $s \in S$ is composed of the set of object types (regions) that are present (e.g., $\{AB, BC, A\}$ is one possible state).
The set of unique states has size $2^7 = 128$.
%, though we exclude the state where all eight regions are empty (i.e., the state where there are no As, Bs, and Cs, but also no things that are not As, Bs, or Cs).

Our model probabilistically generates states $s \in S$ by sampling a Bernoulli random variable for each of the $i \in R$ regions. 

$$P(s) = \prod_{i \in R} P(A_{i}, B_{i}, C_{i}) $$%= (P(a) \cdot P(b) \cdot P(c)) ^n$$

%\subsection{Semantics}
The classical syllogisms are comprised by two premise arguments where each premise relates two properties via a quantifier. 
The quantifiers in classical syllogism are \emph{all}, \emph{some}, \emph{none}, and \emph{not all}.\footnote{
These quantifiers are typically presented in sentences such that \emph{none} is rendered as \emph{no} (e.g., No As are Bs) and \emph{not all} is rendered as \emph{some \_\_ are not} (e.g., Some As are not Bs).
}
We use the classic logical semantics of these quantifiers described in Table \ref{tab:sem}.
\mht{CHECK THIS:
We assume the statements involving \emph{all} and \emph{none} describe situations in which there exist objects that have the property, sometimes referred to as the ``existential presupposition'' (e.g., \emph{All A are B} is false if there are no As). 
}
%: \emph{All As are Bs} entails that $\nexists (A \& \neg B)$;  \emph{Some As are Bs} entails that $\exists (A \& B)$; \emph{Some As are not Bs} entails that $\exists (A \& \neg B)$; \emph{No As are Bs} entails that $\nexists (A \& B)$.


% Please add the following required packages to your document preamble:
%\begin{table}[]
%\centering
%\begin{tabular}{@{}lll@{}}
%\toprule
%Example syllogistic sentence & Consistent State & Inconsistent state \\ \midrule
%All As are Bs                & \{AB, ABC\}      & \{A, ABC\}         \\
%Some As are Bs               & \{A, AB\}        & \{A, AC\}          \\
%Some As are not Bs           & \{A, AB\}        & \{AB, ABC\}        \\
%No As are Bs                 & \{A, AC\}        & \{A, AB\}          \\ \bottomrule
%\end{tabular}
%\caption{cap}
%\end{table}


% Please add the following required packages to your document preamble:
% \usepackage{booktabs}
\begin{table}[]
\begin{tabular}{@{}llll@{}}
\toprule
Example syllogistic sentence & Literal Meaning                                                                       & Consistent State & Inconsistent state \\ \midrule
All As are Bs                                      & $\forall i \in R: A(i) \implies B(i) $ & \{AB, ABC\}                           & \{A, ABC\}                              \\
Some As are Bs                                     & $\exists i \in R: A(i) \implies B(i) $ & \{A, AB\}                             & \{A, AC\}                               \\
Some As are not Bs                                 & $\exists i \in R: A(i)  \centernot \implies B(i) $ & \{A, AB\}                             & \{AB, ABC\}                             \\
No As are Bs                                       & $\forall i \in R: A(i) \centernot \implies B(i) $  & \{A, AC\}                             & \{A, AB\} \\ \bottomrule
\end{tabular}
\caption{Literal meanings of example syllogistic sentences with examples of states that are consistent with the literal meanings and inconsistent with the literal meanings.}
\label{tab:sem}
\end{table}

\subsection{Interpreting the premises}

Given a representation and assignment of prior probabilities to different states (Venn diagrams), we now introduce probabilistic listener models that update their beliefs about the states given the premises of the syllogism. 
This interpretation process can occur at the level of a literal listener (who updates beliefs based on the truth-conditional meaning of the premises) or a pragmatic listener who interprets the premises by reasoning about why a speaker chose to produce the premises that she did. 

\subsubsection{Literal interpretation of premises}

All our recursive reasoning modeling components ground out in a model of literal interpretation.
This model component is a Bayesian literal listener $L_0$ which updates its prior beliefs about the state via the literal, truth conditional meaning of the utterance (shown in Table \ref{tab:sem}):

\begin{equation}
L_0(s \mid u ) \propto P(s)\cdot \mathcal{L}(u, s) 
\label{eq:L0}
\end{equation}
\noindent where $\mathcal{L}(u, s)$ is the lexicon that encodes the literal meanings of the quantified utterances used in syllogisms. 
These meanings can resolve to deterministic outcomes (e.g., $\mathcal{L}(u, s) = 1$ if the utterance $u$ is true of $s$, and 0 otherwise). 
In practice, however, we assume a small amount of noise $\phi$ in the semantics such that $\mathcal{L}(u, s) = 1$ with probability proportional to $1-\phi$ and if the utterance $u$ is true of $s$.
In other words, we assume a continuously valued semantics such that $\mathcal{L}(u, s) \in [0, 1] \subset \mathbb{R}$ as introduced by \citeA{degen2020redundancy}.

The model of literal interpretation can be used to update the prior distribution on states (Venn diagrams) into a posterior distribution given the meaning of the premises of the syllogism. 
For the interpretation of a syllogism, $u$ is composed of two utterances (the two syllogistic sentences): $u_1$ and $u_2$. 
Belief updating proceeds by assuming both utterances are true: 
\begin{equation}
L_0(s \mid u_1,  u_2) \propto P(s)\cdot \mathcal{L}(u_1, s) \cdot \mathcal{L}(u_2, s) 
\label{eq:L0premises}
\end{equation}

Equation \ref{eq:L0premises} defines a probability distribution over states (Venn diagrams) given the premises of the syllogism. 
Logically valid syllogisms given rise to a distribution over states where a quantifier relationship between the conclusion terms of the syllogism are true in all possible states given the premises. 
For example, in the logically valid syllogism  \emph{All As are Bs}, \emph{All Bs are Cs} (the ``Barbara'' syllogism), the relationship \emph{All As are Cs} is true in every possible state in which the premises are true; in particular, the region \emph{ABC} (an object which has all three properties) is true in every possible state (Figure \ref{fig:AAvenns}).
On the other hand, the premises of logically invalid syllogisms tend to give rise to many possible states in which no particular syllogistic conclusion is true in every state; some conclusions are true in more states, however, than other conclusions.
For example, in the logically invalid \emph{No As are Bs}, \emph{Some Bs are Cs}, the conclusion \emph{All As are Cs} is logically possible though is true in fewer states than \emph{No As are Cs} (Figure \ref{fig:EIvenns}).


\begin{figure}[t]
\centering
\includegraphics[width = \textwidth]{figs/diagrams_allAB_allBC.pdf}
\caption{Set of Venn diagrams (states) literally compatible with the premises of the logically valid syllogism: \emph{All As are Bs}, \emph{All Bs are Cs}. The conclusion relation \emph{All As are Cs} is true in every compatible state.}
\label{fig:AAvenns}
\end{figure}



\begin{figure}[b!]
\centering
\includegraphics[width = \textwidth]{figs/diagrams_noneAB_someBC.pdf}
\caption{Set of Venn diagrams (states) literally compatible with the premises of the logically invalid syllogism: \emph{No As are Bs}, \emph{Some Bs are Cs}. No syllogistic conclusion is true in every compatible state.}
\label{fig:EIvenns}
\end{figure}


\subsubsection{Pragmatic interpretation of premises}

Understanding language often involves reasoning not only about the literal meaning of what was said but about why an interlocutor (the speaker) would bother to say what they said. 
We can formalize this reasoning through a series of Bayesian models that recursively reason about one another, as developed in the Rational Speech Act (RSA) framework \cite{Frank2012a, goodman2016pragmatic, scontras2018probabilistic}.
Concretely, we describe a pragmatic listener $L_1$ who reasons about a speaker $S_1$ who produces utterances in order to convey information to the literal listener (Equation \ref{eq:L0premises}):

\begin{align}
L_1(s \mid u_1,  u_2)& \propto  P(s)\cdot S_1(u_1, u_2 \mid s)  \label{eq:L1} \\ 
S_1(u_1, u_2 \mid s) &\propto  \exp [ \alpha_1 \cdot \ln L_0(s \mid u_1,  u_2)]  \label{eq:S1}
\end{align}

The definition of the pragmatic listener (Equation \ref{eq:L1}) mirrors that of the literal listener (Equation \ref{eq:L0}) except in that the likelihood is defined as the probability that a speaker $S_1$ would produce utterances $u_1$ and $u_2$ given a state $s$.
Following standard practice in RSA modeling, the speaker is a soft-max rational agent (with degree of rationality $\alpha_1$) who produces utterances in order to convey information about the state $s$ to the literal listener.
The normalization in Equation \ref{eq:S1} implies a normalization over a set of alternative utterances (i.e., the set of sentences that the speaker can produce (but doesn't). 
\mht{OPEN QUESTION being explored with modeling... what alternative utterances to use for the speaker:}
Here we assume that the alternative set is all syllogisms with the same ordering of terms (i.e., syllogisms of the same \emph{figure}). For example, if the speaker says \emph{All As are Bs. All Bs are Cs.}, the alternative set is the set of syllogisms of the form \emph{Q As are Bs}. \emph{Q Bs are Cs.} where $Q \in \{all, some, \emph{not all}, none\}$. 

\subsection{Producing a conclusion}

The second component of a syllogistic reasoning model is a model of conclusion production. 
That is, given an a set of beliefs about the likely state of affairs (Venn diagrams), what conclusion should be drawn?
We formalize two models of conclusion production.
The first is a literal speaker, who selects conclusions that are likely to be true given the speaker's beliefs about the state. 
The second is a pragmatic speaker, who selects a conclusion that would best align a naive listener's beliefs about the state with the beliefs of the speaker.
Since these models produce a distribution over conclusions, we label these models as reasoner models $R$, so as to not confuse them with the speaker models $S$ that are used as part of the recursion in the pragmatic interpretation of premises.
%The pragmatic production of a conclusion is a model of a speaker who tries to produce the most informative utterance (conclusion) to convey information to a naive listener. 

\subsubsection{Space of conclusions}

The syllogistic reasoning task presents participants with a set of options for the quantifier relationship between the two terms of the syllogisms that are not described explicitly in relation to each other in the premises (i.e., the terms \emph{A} and \emph{C} if the premises are of the form \emph{A -- B}, \emph{B -- C}.). 
Particular tasks differ in the set of options that are given to participants, but the maximal includes the four quantifiers  (\emph{all}, \emph{some}, \emph{not all}, \emph{none}) crossed with the two orderings of the terms of the conclusion (i.e., \emph{A -- C} or \emph{C -- A}).
Thus, there are eight contentful conclusion options. 

A ninth unique option, however, is also available: the option that \emph{nothing follows} (sometimes described \emph{no valid conclusion}). 
The \emph{nothing follows} conclusion is the logically correct answer for the logically invalid syllogisms and is produced to variable extents in both logically valid and invalid syllogisms \cite{Khemlani2012}.
While the semantics of the quantifier conclusions are quite clear, the proper treatment of the \emph{nothing follows} conclusion is not obvious. 
Extant theories treat this option indirectly, either as a byproduct or last resort of a reasoning process, when it is treated at all \cite{ragni2019does, riesterer2020modeling}.
We approach the question of the meaning of \emph{nothing follows} from a language production standpoint, where the statement is tantamount to not saying anything at all. 
Therefore, we model the \emph{nothing follows} statement as one that is true in every possible state of affairs, and hence does not update a listener's beliefs about the state. 
% From a language production perspective, however, the


\subsubsection{Literal production of conclusions}

% In a classical reasoning model, these 
% lexical meanings such that
% Our pragmatics model begins with submodal that performs a literal interpretation of the premises. 
% The model computes a 
Given a belief updating model based on the premises of a syllogism $L$ (either literal $L_0$ or pragmatic $L_1$), we can define a literal production model $R_0$ that uses the listener $L$'s posterior distribution on states to determine what conclusion is likely to be true given the premises. 
This model $R_0$ can be viewed as one that is sampling a state from the listener's posterior distribution on states and randomly choosing among the conclusions that are literally true of that state. 

%The strength of a syllogistic argument (two premises) for a conclusion is a real-valued number between 0 and 1 given by the $P(u_c \mid u_1, u_2)$, where $u_1$ and $u_2$ are the two premises of the syllogism.

\begin{equation}
R_0(u_3 \mid u_1, u_2) \propto \sum_s \mathcal{L}(u_3, s) \cdot L(s \mid u_1, u_2) \label{eq:R0}
\end{equation}

\subsubsection{Informative production of conclusions}

Just as with our submodel of premise interpretation, we can define a reasoner model who selects conclusions in order to convey information to a naive listener (who has not heard either premises or conclusion). 
Since the reasoner does not know the state (but only has beliefs about the state given the premises of the syllogism), we operationalize the informational utility of a conclusion by how well it would align the listener's beliefs with those of the reasoner. 
Formally, we use the information-theoretic measure of Kullback-Leibler (KL) divergence as the measure of alignment of the naive listener and reasoner's belief distributions. 
Again, this formalization is agnostic as to how we compute the reasoner's state distribution (whether it be via a literal or a pragmatic interpretation of the premises), and so we denote the reasoner's distribution as $R$.

\begin{align}
  \label{eq:KL-divergence}
  \text{KL}({R \mid \mid L_0}(u)) = - \sum_{s} R(s) \ \log \frac{R(s)}{{L_{0}}(s \mid u)}
\end{align}

\noindent Then, the reasoner model that selects conclusions an informative manner is given by: 

\begin{equation}
R_1(u_3 \mid u_1,  u_2) \propto  \exp [ \alpha_2 \cdot \text{KL}({R_1(s) \mid \mid L_0}(s \mid u)) ]  \label{eq:R1}
\end{equation}

\noindent where $L_0(s \mid u)$ is the literal listener model defined in Equation \ref{eq:L0}. 
%prior distribution over situations with the literal meanings of the quantified statements: 






%Using KL-divergence, we can then state a more general definition of utterance utilities, to
%replace \eqref{U}:
%\begin{align}
%  \label{eq:Utils-KL-based}
%  U_{S_1}(u; s) = \text{KL}(P_{S_{1}\text{-}Bel} \mid \mid P_{L_{0}\text{-}Bel}(u)) - C(u)
%\end{align}


\section{Modeling the Ragni et al. (2016) data set}

We test our model using a dataset published by \citeA{ragni2019does}. The data set consists of the results of the results of web experiment in which participants ($n = 139$) provided conclusions to all 64 syllogisms. In the experiment, participants completed all syllogistic reasoning problems after a brief training phase. Participants responded by selecting one of the nine possible responses for the conclusion of the syllogism.


\begin{enumerate}
\item describe BDA, parameters, priors
\end{enumerate}


\section{Experiments}

\section{Discussion}


\newpage

\bibliographystyle{apacite}
\bibliography{syllogism}

\end{document}
